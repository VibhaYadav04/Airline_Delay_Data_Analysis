[2025-10-03 20:36:50] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-03 20:36:50] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-03 20:36:50] INFO  SparkContext - Java version 11.0.27
[2025-10-03 20:36:50] INFO  ResourceUtils - ==============================================================
[2025-10-03 20:36:50] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-03 20:36:50] INFO  ResourceUtils - ==============================================================
[2025-10-03 20:36:50] INFO  SparkContext - Submitted application: Airline Data Ingestion
[2025-10-03 20:36:50] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-03 20:36:50] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-03 20:36:50] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-03 20:36:50] INFO  SecurityManager - Changing view acls to: USER
[2025-10-03 20:36:50] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-03 20:36:50] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-03 20:36:50] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-03 20:36:50] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-03 20:36:51] INFO  Utils - Successfully started service 'sparkDriver' on port 60850.
[2025-10-03 20:36:51] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-03 20:36:51] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-03 20:36:51] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-03 20:36:51] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-03 20:36:51] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-03 20:36:51] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-7873e580-92e0-4d40-8a40-955f0cc3ab66
[2025-10-03 20:36:51] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-03 20:36:52] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-03 20:36:52] INFO  log - Logging initialized @3241ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-03 20:36:52] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-03 20:36:52] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-03 20:36:52] INFO  Server - Started @3383ms
[2025-10-03 20:36:52] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 20:36:52] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@244418a{/,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-03 20:36:52] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-03 20:36:52] INFO  Executor - Java version 11.0.27
[2025-10-03 20:36:52] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-03 20:36:52] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3d90eeb3 for default.
[2025-10-03 20:36:52] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60897.
[2025-10-03 20:36:52] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:60897
[2025-10-03 20:36:52] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-03 20:36:52] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 60897, None)
[2025-10-03 20:36:52] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:60897 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 60897, None)
[2025-10-03 20:36:52] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 60897, None)
[2025-10-03 20:36:52] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 60897, None)
[2025-10-03 20:36:52] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@244418a{/,null,STOPPED,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@30db5536{/jobs,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@136ccbfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@61874b9d{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f2d014a{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@a7cf42f{/stages,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@28e0e464{/stages/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b7c80c6{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7499eac7{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@b9d018b{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79eeff87{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@8bd076a{/storage,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1378eea2{/storage/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66522ead{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@e91b4f4{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58ae402b{/environment,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43ac0a68{/environment/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3728a578{/executors,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de0641b{/executors/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a464fa3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ccb85d6{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@259b85d6{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@488f3dd1{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7bc58891{/static,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@566f1852{/,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e4389ed{/api,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7edb6fca{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@716185fe{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@234c5e41{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  DataIngestion - Loading CSV file: data/input/Airline_Delay_Cause.csv
[2025-10-03 20:36:52] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-03 20:36:52] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@432af457{/SQL,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@519c6fcc{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@713a35c5{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@11787b64{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-03 20:36:52] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6b321262{/static/sql,null,AVAILABLE,@Spark}
[2025-10-03 20:36:53] INFO  InMemoryFileIndex - It took 29 ms to list leaf files for 1 paths.
[2025-10-03 20:36:53] INFO  InMemoryFileIndex - It took 1 ms to list leaf files for 1 paths.
[2025-10-03 20:36:55] INFO  FileSourceStrategy - Pushed Filters: 
[2025-10-03 20:36:55] INFO  FileSourceStrategy - Post-Scan Filters: (length(trim(value#0, None)) > 0)
[2025-10-03 20:36:56] INFO  CodeGenerator - Code generated in 190.9409 ms
[2025-10-03 20:36:56] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 198.8 KiB, free 2.2 GiB)
[2025-10-03 20:36:56] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
[2025-10-03 20:36:56] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on DESKTOP-618L1DH:60897 (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:56] INFO  SparkContext - Created broadcast 0 from csv at DataIngestion.java:66
[2025-10-03 20:36:56] INFO  FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-10-03 20:36:56] INFO  SparkContext - Starting job: csv at DataIngestion.java:66
[2025-10-03 20:36:56] INFO  DAGScheduler - Got job 0 (csv at DataIngestion.java:66) with 1 output partitions
[2025-10-03 20:36:56] INFO  DAGScheduler - Final stage: ResultStage 0 (csv at DataIngestion.java:66)
[2025-10-03 20:36:56] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:36:56] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:36:56] INFO  DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at DataIngestion.java:66), which has no missing parents
[2025-10-03 20:36:56] INFO  MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 2.2 GiB)
[2025-10-03 20:36:56] INFO  MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 2.2 GiB)
[2025-10-03 20:36:56] INFO  BlockManagerInfo - Added broadcast_1_piece0 in memory on DESKTOP-618L1DH:60897 (size: 6.4 KiB, free: 2.2 GiB)
[2025-10-03 20:36:56] INFO  SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:36:56] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at DataIngestion.java:66) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:36:56] INFO  TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
[2025-10-03 20:36:56] INFO  TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9699 bytes) 
[2025-10-03 20:36:56] INFO  Executor - Running task 0.0 in stage 0.0 (TID 0)
[2025-10-03 20:36:57] INFO  CodeGenerator - Code generated in 14.7932 ms
[2025-10-03 20:36:57] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/Airline_Delay_Cause.csv, range: 0-4194304, partition values: [empty row]
[2025-10-03 20:36:57] INFO  CodeGenerator - Code generated in 14.259 ms
[2025-10-03 20:36:57] INFO  Executor - Finished task 0.0 in stage 0.0 (TID 0). 1783 bytes result sent to driver
[2025-10-03 20:36:57] INFO  TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 359 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:36:57] INFO  TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[2025-10-03 20:36:57] INFO  DAGScheduler - ResultStage 0 (csv at DataIngestion.java:66) finished in 0.488 s
[2025-10-03 20:36:57] INFO  DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:36:57] INFO  TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
[2025-10-03 20:36:57] INFO  DAGScheduler - Job 0 finished: csv at DataIngestion.java:66, took 0.530352 s
[2025-10-03 20:36:57] INFO  CodeGenerator - Code generated in 9.4738 ms
[2025-10-03 20:36:57] INFO  FileSourceStrategy - Pushed Filters: 
[2025-10-03 20:36:57] INFO  FileSourceStrategy - Post-Scan Filters: 
[2025-10-03 20:36:57] INFO  MemoryStore - Block broadcast_2 stored as values in memory (estimated size 198.8 KiB, free 2.2 GiB)
[2025-10-03 20:36:57] INFO  MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
[2025-10-03 20:36:57] INFO  BlockManagerInfo - Added broadcast_2_piece0 in memory on DESKTOP-618L1DH:60897 (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:57] INFO  SparkContext - Created broadcast 2 from csv at DataIngestion.java:66
[2025-10-03 20:36:57] INFO  FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-10-03 20:36:57] INFO  SparkContext - Starting job: csv at DataIngestion.java:66
[2025-10-03 20:36:57] INFO  DAGScheduler - Got job 1 (csv at DataIngestion.java:66) with 3 output partitions
[2025-10-03 20:36:57] INFO  DAGScheduler - Final stage: ResultStage 1 (csv at DataIngestion.java:66)
[2025-10-03 20:36:57] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:36:57] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:36:57] INFO  DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at DataIngestion.java:66), which has no missing parents
[2025-10-03 20:36:57] INFO  MemoryStore - Block broadcast_3 stored as values in memory (estimated size 27.8 KiB, free 2.2 GiB)
[2025-10-03 20:36:57] INFO  MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 2.2 GiB)
[2025-10-03 20:36:57] INFO  BlockManagerInfo - Added broadcast_3_piece0 in memory on DESKTOP-618L1DH:60897 (size: 12.8 KiB, free: 2.2 GiB)
[2025-10-03 20:36:57] INFO  SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:36:57] INFO  DAGScheduler - Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at DataIngestion.java:66) (first 15 tasks are for partitions Vector(0, 1, 2))
[2025-10-03 20:36:57] INFO  TaskSchedulerImpl - Adding task set 1.0 with 3 tasks resource profile 0
[2025-10-03 20:36:57] INFO  TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9699 bytes) 
[2025-10-03 20:36:57] INFO  TaskSetManager - Starting task 1.0 in stage 1.0 (TID 2) (DESKTOP-618L1DH, executor driver, partition 1, PROCESS_LOCAL, 9699 bytes) 
[2025-10-03 20:36:57] INFO  TaskSetManager - Starting task 2.0 in stage 1.0 (TID 3) (DESKTOP-618L1DH, executor driver, partition 2, PROCESS_LOCAL, 9699 bytes) 
[2025-10-03 20:36:57] INFO  Executor - Running task 0.0 in stage 1.0 (TID 1)
[2025-10-03 20:36:57] INFO  Executor - Running task 2.0 in stage 1.0 (TID 3)
[2025-10-03 20:36:57] INFO  Executor - Running task 1.0 in stage 1.0 (TID 2)
[2025-10-03 20:36:57] INFO  CodeGenerator - Code generated in 9.4508 ms
[2025-10-03 20:36:57] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/Airline_Delay_Cause.csv, range: 4194304-8388608, partition values: [empty row]
[2025-10-03 20:36:57] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/Airline_Delay_Cause.csv, range: 0-4194304, partition values: [empty row]
[2025-10-03 20:36:57] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/Airline_Delay_Cause.csv, range: 8388608-9187478, partition values: [empty row]
[2025-10-03 20:36:57] INFO  BlockManagerInfo - Removed broadcast_0_piece0 on DESKTOP-618L1DH:60897 in memory (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:57] INFO  BlockManagerInfo - Removed broadcast_1_piece0 on DESKTOP-618L1DH:60897 in memory (size: 6.4 KiB, free: 2.2 GiB)
[2025-10-03 20:36:57] INFO  Executor - Finished task 2.0 in stage 1.0 (TID 3). 1802 bytes result sent to driver
[2025-10-03 20:36:57] INFO  TaskSetManager - Finished task 2.0 in stage 1.0 (TID 3) in 369 ms on DESKTOP-618L1DH (executor driver) (1/3)
[2025-10-03 20:36:58] INFO  Executor - Finished task 1.0 in stage 1.0 (TID 2). 1759 bytes result sent to driver
[2025-10-03 20:36:58] INFO  TaskSetManager - Finished task 1.0 in stage 1.0 (TID 2) in 525 ms on DESKTOP-618L1DH (executor driver) (2/3)
[2025-10-03 20:36:58] INFO  Executor - Finished task 0.0 in stage 1.0 (TID 1). 1802 bytes result sent to driver
[2025-10-03 20:36:58] INFO  TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 534 ms on DESKTOP-618L1DH (executor driver) (3/3)
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[2025-10-03 20:36:58] INFO  DAGScheduler - ResultStage 1 (csv at DataIngestion.java:66) finished in 0.580 s
[2025-10-03 20:36:58] INFO  DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
[2025-10-03 20:36:58] INFO  DAGScheduler - Job 1 finished: csv at DataIngestion.java:66, took 0.592620 s
[2025-10-03 20:36:58] INFO  DataIngestion - Loading CSV file: data/input/carrier_lookup.csv
[2025-10-03 20:36:58] INFO  InMemoryFileIndex - It took 1 ms to list leaf files for 1 paths.
[2025-10-03 20:36:58] INFO  InMemoryFileIndex - It took 2 ms to list leaf files for 1 paths.
[2025-10-03 20:36:58] INFO  FileSourceStrategy - Pushed Filters: 
[2025-10-03 20:36:58] INFO  FileSourceStrategy - Post-Scan Filters: (length(trim(value#59, None)) > 0)
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_4 stored as values in memory (estimated size 198.8 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  BlockManagerInfo - Added broadcast_4_piece0 in memory on DESKTOP-618L1DH:60897 (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:58] INFO  SparkContext - Created broadcast 4 from csv at DataIngestion.java:66
[2025-10-03 20:36:58] INFO  FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-10-03 20:36:58] INFO  SparkContext - Starting job: csv at DataIngestion.java:66
[2025-10-03 20:36:58] INFO  DAGScheduler - Got job 2 (csv at DataIngestion.java:66) with 1 output partitions
[2025-10-03 20:36:58] INFO  DAGScheduler - Final stage: ResultStage 2 (csv at DataIngestion.java:66)
[2025-10-03 20:36:58] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:36:58] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:36:58] INFO  DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[13] at csv at DataIngestion.java:66), which has no missing parents
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_5 stored as values in memory (estimated size 13.5 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  BlockManagerInfo - Added broadcast_5_piece0 in memory on DESKTOP-618L1DH:60897 (size: 6.4 KiB, free: 2.2 GiB)
[2025-10-03 20:36:58] INFO  SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:36:58] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at csv at DataIngestion.java:66) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
[2025-10-03 20:36:58] INFO  TaskSetManager - Starting task 0.0 in stage 2.0 (TID 4) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9694 bytes) 
[2025-10-03 20:36:58] INFO  Executor - Running task 0.0 in stage 2.0 (TID 4)
[2025-10-03 20:36:58] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/carrier_lookup.csv, range: 0-754, partition values: [empty row]
[2025-10-03 20:36:58] INFO  Executor - Finished task 0.0 in stage 2.0 (TID 4). 1546 bytes result sent to driver
[2025-10-03 20:36:58] INFO  TaskSetManager - Finished task 0.0 in stage 2.0 (TID 4) in 17 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[2025-10-03 20:36:58] INFO  DAGScheduler - ResultStage 2 (csv at DataIngestion.java:66) finished in 0.030 s
[2025-10-03 20:36:58] INFO  DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
[2025-10-03 20:36:58] INFO  DAGScheduler - Job 2 finished: csv at DataIngestion.java:66, took 0.038196 s
[2025-10-03 20:36:58] INFO  FileSourceStrategy - Pushed Filters: 
[2025-10-03 20:36:58] INFO  FileSourceStrategy - Post-Scan Filters: 
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_6 stored as values in memory (estimated size 198.8 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  BlockManagerInfo - Added broadcast_6_piece0 in memory on DESKTOP-618L1DH:60897 (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:58] INFO  SparkContext - Created broadcast 6 from csv at DataIngestion.java:66
[2025-10-03 20:36:58] INFO  FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-10-03 20:36:58] INFO  SparkContext - Starting job: csv at DataIngestion.java:66
[2025-10-03 20:36:58] INFO  DAGScheduler - Got job 3 (csv at DataIngestion.java:66) with 1 output partitions
[2025-10-03 20:36:58] INFO  DAGScheduler - Final stage: ResultStage 3 (csv at DataIngestion.java:66)
[2025-10-03 20:36:58] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:36:58] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:36:58] INFO  DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[19] at csv at DataIngestion.java:66), which has no missing parents
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_7 stored as values in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.6 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  BlockManagerInfo - Added broadcast_7_piece0 in memory on DESKTOP-618L1DH:60897 (size: 12.6 KiB, free: 2.2 GiB)
[2025-10-03 20:36:58] INFO  SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:36:58] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at csv at DataIngestion.java:66) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
[2025-10-03 20:36:58] INFO  TaskSetManager - Starting task 0.0 in stage 3.0 (TID 5) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9694 bytes) 
[2025-10-03 20:36:58] INFO  Executor - Running task 0.0 in stage 3.0 (TID 5)
[2025-10-03 20:36:58] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/carrier_lookup.csv, range: 0-754, partition values: [empty row]
[2025-10-03 20:36:58] INFO  Executor - Finished task 0.0 in stage 3.0 (TID 5). 1517 bytes result sent to driver
[2025-10-03 20:36:58] INFO  TaskSetManager - Finished task 0.0 in stage 3.0 (TID 5) in 33 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[2025-10-03 20:36:58] INFO  DAGScheduler - ResultStage 3 (csv at DataIngestion.java:66) finished in 0.053 s
[2025-10-03 20:36:58] INFO  DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
[2025-10-03 20:36:58] INFO  DAGScheduler - Job 3 finished: csv at DataIngestion.java:66, took 0.062240 s
[2025-10-03 20:36:58] INFO  DataIngestion - Loading CSV file: data/input/airports.csv
[2025-10-03 20:36:58] INFO  InMemoryFileIndex - It took 2 ms to list leaf files for 1 paths.
[2025-10-03 20:36:58] INFO  InMemoryFileIndex - It took 2 ms to list leaf files for 1 paths.
[2025-10-03 20:36:58] INFO  FileSourceStrategy - Pushed Filters: 
[2025-10-03 20:36:58] INFO  FileSourceStrategy - Post-Scan Filters: (length(trim(value#80, None)) > 0)
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_8 stored as values in memory (estimated size 198.8 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  BlockManagerInfo - Added broadcast_8_piece0 in memory on DESKTOP-618L1DH:60897 (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:58] INFO  SparkContext - Created broadcast 8 from csv at DataIngestion.java:66
[2025-10-03 20:36:58] INFO  FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-10-03 20:36:58] INFO  SparkContext - Starting job: csv at DataIngestion.java:66
[2025-10-03 20:36:58] INFO  DAGScheduler - Got job 4 (csv at DataIngestion.java:66) with 1 output partitions
[2025-10-03 20:36:58] INFO  DAGScheduler - Final stage: ResultStage 4 (csv at DataIngestion.java:66)
[2025-10-03 20:36:58] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:36:58] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:36:58] INFO  DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[23] at csv at DataIngestion.java:66), which has no missing parents
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_9 stored as values in memory (estimated size 13.5 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  BlockManagerInfo - Added broadcast_9_piece0 in memory on DESKTOP-618L1DH:60897 (size: 6.4 KiB, free: 2.2 GiB)
[2025-10-03 20:36:58] INFO  SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:36:58] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at csv at DataIngestion.java:66) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
[2025-10-03 20:36:58] INFO  TaskSetManager - Starting task 0.0 in stage 4.0 (TID 6) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9688 bytes) 
[2025-10-03 20:36:58] INFO  Executor - Running task 0.0 in stage 4.0 (TID 6)
[2025-10-03 20:36:58] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/airports.csv, range: 0-71857, partition values: [empty row]
[2025-10-03 20:36:58] INFO  Executor - Finished task 0.0 in stage 4.0 (TID 6). 1558 bytes result sent to driver
[2025-10-03 20:36:58] INFO  TaskSetManager - Finished task 0.0 in stage 4.0 (TID 6) in 18 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[2025-10-03 20:36:58] INFO  DAGScheduler - ResultStage 4 (csv at DataIngestion.java:66) finished in 0.039 s
[2025-10-03 20:36:58] INFO  DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
[2025-10-03 20:36:58] INFO  DAGScheduler - Job 4 finished: csv at DataIngestion.java:66, took 0.050484 s
[2025-10-03 20:36:58] INFO  FileSourceStrategy - Pushed Filters: 
[2025-10-03 20:36:58] INFO  FileSourceStrategy - Post-Scan Filters: 
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_10 stored as values in memory (estimated size 198.8 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  BlockManagerInfo - Added broadcast_10_piece0 in memory on DESKTOP-618L1DH:60897 (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:58] INFO  SparkContext - Created broadcast 10 from csv at DataIngestion.java:66
[2025-10-03 20:36:58] INFO  FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-10-03 20:36:58] INFO  SparkContext - Starting job: csv at DataIngestion.java:66
[2025-10-03 20:36:58] INFO  DAGScheduler - Got job 5 (csv at DataIngestion.java:66) with 1 output partitions
[2025-10-03 20:36:58] INFO  DAGScheduler - Final stage: ResultStage 5 (csv at DataIngestion.java:66)
[2025-10-03 20:36:58] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:36:58] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:36:58] INFO  DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[29] at csv at DataIngestion.java:66), which has no missing parents
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_11 stored as values in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 12.6 KiB, free 2.2 GiB)
[2025-10-03 20:36:58] INFO  BlockManagerInfo - Added broadcast_11_piece0 in memory on DESKTOP-618L1DH:60897 (size: 12.6 KiB, free: 2.2 GiB)
[2025-10-03 20:36:58] INFO  SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:36:58] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at csv at DataIngestion.java:66) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
[2025-10-03 20:36:58] INFO  TaskSetManager - Starting task 0.0 in stage 5.0 (TID 7) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9688 bytes) 
[2025-10-03 20:36:58] INFO  Executor - Running task 0.0 in stage 5.0 (TID 7)
[2025-10-03 20:36:58] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/airports.csv, range: 0-71857, partition values: [empty row]
[2025-10-03 20:36:58] INFO  Executor - Finished task 0.0 in stage 5.0 (TID 7). 1522 bytes result sent to driver
[2025-10-03 20:36:58] INFO  TaskSetManager - Finished task 0.0 in stage 5.0 (TID 7) in 44 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[2025-10-03 20:36:58] INFO  DAGScheduler - ResultStage 5 (csv at DataIngestion.java:66) finished in 0.063 s
[2025-10-03 20:36:58] INFO  DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:36:58] INFO  TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
[2025-10-03 20:36:58] INFO  DAGScheduler - Job 5 finished: csv at DataIngestion.java:66, took 0.075936 s
[2025-10-03 20:36:58] INFO  DataIngestion - Validating numeric column schema...
[2025-10-03 20:36:58] INFO  DataIngestion - Saving parquet: data/output/bronze/raw_dataset
[2025-10-03 20:36:58] INFO  FileSourceStrategy - Pushed Filters: 
[2025-10-03 20:36:58] INFO  FileSourceStrategy - Post-Scan Filters: 
[2025-10-03 20:36:58] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:36:59] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:36:59] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:36:59] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:36:59] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:36:59] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:36:59] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:36:59] INFO  BlockManagerInfo - Removed broadcast_11_piece0 on DESKTOP-618L1DH:60897 in memory (size: 12.6 KiB, free: 2.2 GiB)
[2025-10-03 20:36:59] INFO  BlockManagerInfo - Removed broadcast_8_piece0 on DESKTOP-618L1DH:60897 in memory (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:59] INFO  MemoryStore - Block broadcast_12 stored as values in memory (estimated size 198.7 KiB, free 2.2 GiB)
[2025-10-03 20:36:59] INFO  BlockManagerInfo - Removed broadcast_3_piece0 on DESKTOP-618L1DH:60897 in memory (size: 12.8 KiB, free: 2.2 GiB)
[2025-10-03 20:36:59] INFO  BlockManagerInfo - Removed broadcast_5_piece0 on DESKTOP-618L1DH:60897 in memory (size: 6.4 KiB, free: 2.2 GiB)
[2025-10-03 20:36:59] INFO  MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
[2025-10-03 20:36:59] INFO  BlockManagerInfo - Added broadcast_12_piece0 in memory on DESKTOP-618L1DH:60897 (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:59] INFO  BlockManagerInfo - Removed broadcast_7_piece0 on DESKTOP-618L1DH:60897 in memory (size: 12.6 KiB, free: 2.2 GiB)
[2025-10-03 20:36:59] INFO  SparkContext - Created broadcast 12 from save at DataIngestion.java:85
[2025-10-03 20:36:59] INFO  BlockManagerInfo - Removed broadcast_4_piece0 on DESKTOP-618L1DH:60897 in memory (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:59] INFO  FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-10-03 20:36:59] INFO  BlockManagerInfo - Removed broadcast_6_piece0 on DESKTOP-618L1DH:60897 in memory (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:59] INFO  BlockManagerInfo - Removed broadcast_2_piece0 on DESKTOP-618L1DH:60897 in memory (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:59] INFO  BlockManagerInfo - Removed broadcast_10_piece0 on DESKTOP-618L1DH:60897 in memory (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:36:59] INFO  BlockManagerInfo - Removed broadcast_9_piece0 on DESKTOP-618L1DH:60897 in memory (size: 6.4 KiB, free: 2.2 GiB)
[2025-10-03 20:36:59] INFO  SparkContext - Starting job: save at DataIngestion.java:85
[2025-10-03 20:36:59] INFO  DAGScheduler - Got job 6 (save at DataIngestion.java:85) with 1 output partitions
[2025-10-03 20:36:59] INFO  DAGScheduler - Final stage: ResultStage 6 (save at DataIngestion.java:85)
[2025-10-03 20:36:59] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:36:59] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:36:59] INFO  DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[33] at save at DataIngestion.java:85), which has no missing parents
[2025-10-03 20:36:59] INFO  MemoryStore - Block broadcast_13 stored as values in memory (estimated size 217.2 KiB, free 2.2 GiB)
[2025-10-03 20:36:59] INFO  MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 78.1 KiB, free 2.2 GiB)
[2025-10-03 20:36:59] INFO  BlockManagerInfo - Added broadcast_13_piece0 in memory on DESKTOP-618L1DH:60897 (size: 78.1 KiB, free: 2.2 GiB)
[2025-10-03 20:36:59] INFO  SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:36:59] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[33] at save at DataIngestion.java:85) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:36:59] INFO  TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
[2025-10-03 20:36:59] INFO  TaskSetManager - Starting task 0.0 in stage 6.0 (TID 8) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 10094 bytes) 
[2025-10-03 20:36:59] INFO  Executor - Running task 0.0 in stage 6.0 (TID 8)
[2025-10-03 20:36:59] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:36:59] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:36:59] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:36:59] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:36:59] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:36:59] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:36:59] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:36:59] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:36:59] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-03 20:36:59] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "year",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "month",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "airport",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "airport_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_flights",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_del15",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "weather_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "nas_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "security_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "late_aircraft_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_cancelled",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_diverted",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "weather_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "nas_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "security_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "late_aircraft_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 year;
  optional int32 month;
  optional binary carrier (STRING);
  optional binary carrier_name (STRING);
  optional binary airport (STRING);
  optional binary airport_name (STRING);
  optional double arr_flights;
  optional double arr_del15;
  optional double carrier_ct;
  optional double weather_ct;
  optional double nas_ct;
  optional double security_ct;
  optional double late_aircraft_ct;
  optional double arr_cancelled;
  optional double arr_diverted;
  optional double arr_delay;
  optional double carrier_delay;
  optional double weather_delay;
  optional double nas_delay;
  optional double security_delay;
  optional double late_aircraft_delay;
}

       
[2025-10-03 20:36:59] INFO  CodecPool - Got brand-new compressor [.snappy]
[2025-10-03 20:36:59] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/Airline_Delay_Cause.csv, range: 0-4194304, partition values: [empty row]
[2025-10-03 20:36:59] INFO  CodeGenerator - Code generated in 31.2326 ms
[2025-10-03 20:37:00] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/Airline_Delay_Cause.csv, range: 4194304-8388608, partition values: [empty row]
[2025-10-03 20:37:00] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/Airline_Delay_Cause.csv, range: 8388608-9187478, partition values: [empty row]
[2025-10-03 20:37:00] INFO  FileOutputCommitter - Saved output of task 'attempt_20251003203659454473651469072180_0006_m_000000_8' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/bronze/raw_dataset/_temporary/0/task_20251003203659454473651469072180_0006_m_000000
[2025-10-03 20:37:00] INFO  SparkHadoopMapRedUtil - attempt_20251003203659454473651469072180_0006_m_000000_8: Committed. Elapsed time: 2 ms.
[2025-10-03 20:37:00] INFO  Executor - Finished task 0.0 in stage 6.0 (TID 8). 2545 bytes result sent to driver
[2025-10-03 20:37:00] INFO  TaskSetManager - Finished task 0.0 in stage 6.0 (TID 8) in 1368 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:37:00] INFO  TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[2025-10-03 20:37:00] INFO  DAGScheduler - ResultStage 6 (save at DataIngestion.java:85) finished in 1.421 s
[2025-10-03 20:37:00] INFO  DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:37:00] INFO  TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
[2025-10-03 20:37:00] INFO  DAGScheduler - Job 6 finished: save at DataIngestion.java:85, took 1.432705 s
[2025-10-03 20:37:00] INFO  FileFormatWriter - Start to commit write Job a686f0ad-ae53-4e86-b487-72f53771425f.
[2025-10-03 20:37:00] INFO  FileFormatWriter - Write Job a686f0ad-ae53-4e86-b487-72f53771425f committed. Elapsed time: 38 ms.
[2025-10-03 20:37:00] INFO  FileFormatWriter - Finished processing stats for write job a686f0ad-ae53-4e86-b487-72f53771425f.
[2025-10-03 20:37:00] INFO  DataIngestion - Overwriting data to table bronze.raw_dataset
[2025-10-03 20:37:01] INFO  FileSourceStrategy - Pushed Filters: 
[2025-10-03 20:37:01] INFO  FileSourceStrategy - Post-Scan Filters: 
[2025-10-03 20:37:01] WARN  SparkStringUtils - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2025-10-03 20:37:01] INFO  MemoryStore - Block broadcast_14 stored as values in memory (estimated size 198.7 KiB, free 2.2 GiB)
[2025-10-03 20:37:01] INFO  MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
[2025-10-03 20:37:01] INFO  BlockManagerInfo - Added broadcast_14_piece0 in memory on DESKTOP-618L1DH:60897 (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:37:01] INFO  SparkContext - Created broadcast 14 from save at DataIngestion.java:96
[2025-10-03 20:37:01] INFO  FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-10-03 20:37:01] INFO  SparkContext - Starting job: save at DataIngestion.java:96
[2025-10-03 20:37:01] INFO  DAGScheduler - Got job 7 (save at DataIngestion.java:96) with 3 output partitions
[2025-10-03 20:37:01] INFO  DAGScheduler - Final stage: ResultStage 7 (save at DataIngestion.java:96)
[2025-10-03 20:37:01] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:37:01] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:37:01] INFO  DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[38] at save at DataIngestion.java:96), which has no missing parents
[2025-10-03 20:37:01] INFO  MemoryStore - Block broadcast_15 stored as values in memory (estimated size 35.9 KiB, free 2.2 GiB)
[2025-10-03 20:37:01] INFO  MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 2.2 GiB)
[2025-10-03 20:37:01] INFO  BlockManagerInfo - Added broadcast_15_piece0 in memory on DESKTOP-618L1DH:60897 (size: 15.7 KiB, free: 2.2 GiB)
[2025-10-03 20:37:01] INFO  SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:37:01] INFO  DAGScheduler - Submitting 3 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at save at DataIngestion.java:96) (first 15 tasks are for partitions Vector(0, 1, 2))
[2025-10-03 20:37:01] INFO  TaskSchedulerImpl - Adding task set 7.0 with 3 tasks resource profile 0
[2025-10-03 20:37:01] INFO  TaskSetManager - Starting task 0.0 in stage 7.0 (TID 9) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9699 bytes) 
[2025-10-03 20:37:01] INFO  TaskSetManager - Starting task 1.0 in stage 7.0 (TID 10) (DESKTOP-618L1DH, executor driver, partition 1, PROCESS_LOCAL, 9699 bytes) 
[2025-10-03 20:37:01] INFO  TaskSetManager - Starting task 2.0 in stage 7.0 (TID 11) (DESKTOP-618L1DH, executor driver, partition 2, PROCESS_LOCAL, 9699 bytes) 
[2025-10-03 20:37:01] INFO  Executor - Running task 2.0 in stage 7.0 (TID 11)
[2025-10-03 20:37:01] INFO  Executor - Running task 0.0 in stage 7.0 (TID 9)
[2025-10-03 20:37:01] INFO  Executor - Running task 1.0 in stage 7.0 (TID 10)
[2025-10-03 20:37:01] INFO  CodeGenerator - Code generated in 61.7906 ms
[2025-10-03 20:37:01] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/Airline_Delay_Cause.csv, range: 8388608-9187478, partition values: [empty row]
[2025-10-03 20:37:01] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/Airline_Delay_Cause.csv, range: 4194304-8388608, partition values: [empty row]
[2025-10-03 20:37:01] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/Airline_Delay_Cause.csv, range: 0-4194304, partition values: [empty row]
[2025-10-03 20:37:01] INFO  BlockManagerInfo - Removed broadcast_12_piece0 on DESKTOP-618L1DH:60897 in memory (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:37:01] INFO  BlockManagerInfo - Removed broadcast_13_piece0 on DESKTOP-618L1DH:60897 in memory (size: 78.1 KiB, free: 2.2 GiB)
[2025-10-03 20:37:03] INFO  Executor - Finished task 2.0 in stage 7.0 (TID 11). 1567 bytes result sent to driver
[2025-10-03 20:37:03] INFO  TaskSetManager - Finished task 2.0 in stage 7.0 (TID 11) in 2408 ms on DESKTOP-618L1DH (executor driver) (1/3)
[2025-10-03 20:37:12] INFO  Executor - Finished task 1.0 in stage 7.0 (TID 10). 1524 bytes result sent to driver
[2025-10-03 20:37:12] INFO  TaskSetManager - Finished task 1.0 in stage 7.0 (TID 10) in 11133 ms on DESKTOP-618L1DH (executor driver) (2/3)
[2025-10-03 20:37:12] INFO  Executor - Finished task 0.0 in stage 7.0 (TID 9). 1524 bytes result sent to driver
[2025-10-03 20:37:12] INFO  TaskSetManager - Finished task 0.0 in stage 7.0 (TID 9) in 11345 ms on DESKTOP-618L1DH (executor driver) (3/3)
[2025-10-03 20:37:12] INFO  TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
[2025-10-03 20:37:12] INFO  DAGScheduler - ResultStage 7 (save at DataIngestion.java:96) finished in 11.395 s
[2025-10-03 20:37:12] INFO  DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:37:12] INFO  TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
[2025-10-03 20:37:12] INFO  DAGScheduler - Job 7 finished: save at DataIngestion.java:96, took 11.408087 s
[2025-10-03 20:37:12] INFO  DataIngestion - Saving parquet: data/output/bronze/carrier_lookup
[2025-10-03 20:37:12] INFO  FileSourceStrategy - Pushed Filters: 
[2025-10-03 20:37:12] INFO  FileSourceStrategy - Post-Scan Filters: 
[2025-10-03 20:37:12] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:37:12] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:37:12] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:37:12] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:37:12] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:37:12] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:37:12] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:37:12] INFO  MemoryStore - Block broadcast_16 stored as values in memory (estimated size 198.7 KiB, free 2.2 GiB)
[2025-10-03 20:37:12] INFO  MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
[2025-10-03 20:37:12] INFO  BlockManagerInfo - Added broadcast_16_piece0 in memory on DESKTOP-618L1DH:60897 (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:37:12] INFO  SparkContext - Created broadcast 16 from save at DataIngestion.java:85
[2025-10-03 20:37:12] INFO  FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-10-03 20:37:12] INFO  SparkContext - Starting job: save at DataIngestion.java:85
[2025-10-03 20:37:12] INFO  DAGScheduler - Got job 8 (save at DataIngestion.java:85) with 1 output partitions
[2025-10-03 20:37:12] INFO  DAGScheduler - Final stage: ResultStage 8 (save at DataIngestion.java:85)
[2025-10-03 20:37:12] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:37:12] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:37:12] INFO  DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[42] at save at DataIngestion.java:85), which has no missing parents
[2025-10-03 20:37:12] INFO  MemoryStore - Block broadcast_17 stored as values in memory (estimated size 212.5 KiB, free 2.2 GiB)
[2025-10-03 20:37:12] INFO  MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 2.2 GiB)
[2025-10-03 20:37:12] INFO  BlockManagerInfo - Added broadcast_17_piece0 in memory on DESKTOP-618L1DH:60897 (size: 76.9 KiB, free: 2.2 GiB)
[2025-10-03 20:37:12] INFO  SparkContext - Created broadcast 17 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:37:12] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[42] at save at DataIngestion.java:85) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:37:12] INFO  TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
[2025-10-03 20:37:12] INFO  TaskSetManager - Starting task 0.0 in stage 8.0 (TID 12) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9923 bytes) 
[2025-10-03 20:37:12] INFO  Executor - Running task 0.0 in stage 8.0 (TID 12)
[2025-10-03 20:37:12] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:37:12] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:37:12] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:37:12] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:37:12] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:37:12] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:37:12] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:37:12] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:37:12] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-03 20:37:12] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "carrier",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary carrier (STRING);
  optional binary carrier_name (STRING);
}

       
[2025-10-03 20:37:13] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/carrier_lookup.csv, range: 0-754, partition values: [empty row]
[2025-10-03 20:37:13] INFO  CodeGenerator - Code generated in 11.2137 ms
[2025-10-03 20:37:13] INFO  FileOutputCommitter - Saved output of task 'attempt_202510032037127918541224780246005_0008_m_000000_12' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/bronze/carrier_lookup/_temporary/0/task_202510032037127918541224780246005_0008_m_000000
[2025-10-03 20:37:13] INFO  SparkHadoopMapRedUtil - attempt_202510032037127918541224780246005_0008_m_000000_12: Committed. Elapsed time: 4 ms.
[2025-10-03 20:37:13] INFO  Executor - Finished task 0.0 in stage 8.0 (TID 12). 2459 bytes result sent to driver
[2025-10-03 20:37:13] INFO  TaskSetManager - Finished task 0.0 in stage 8.0 (TID 12) in 92 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:37:13] INFO  TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[2025-10-03 20:37:13] INFO  DAGScheduler - ResultStage 8 (save at DataIngestion.java:85) finished in 0.116 s
[2025-10-03 20:37:13] INFO  DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:37:13] INFO  TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
[2025-10-03 20:37:13] INFO  DAGScheduler - Job 8 finished: save at DataIngestion.java:85, took 0.120426 s
[2025-10-03 20:37:13] INFO  FileFormatWriter - Start to commit write Job a11c39f7-fb21-4672-81d8-a9f14eb573f9.
[2025-10-03 20:37:13] INFO  FileFormatWriter - Write Job a11c39f7-fb21-4672-81d8-a9f14eb573f9 committed. Elapsed time: 17 ms.
[2025-10-03 20:37:13] INFO  FileFormatWriter - Finished processing stats for write job a11c39f7-fb21-4672-81d8-a9f14eb573f9.
[2025-10-03 20:37:13] INFO  DataIngestion - Overwriting data to table bronze.carrier_lookup
[2025-10-03 20:37:13] INFO  FileSourceStrategy - Pushed Filters: 
[2025-10-03 20:37:13] INFO  FileSourceStrategy - Post-Scan Filters: 
[2025-10-03 20:37:13] INFO  MemoryStore - Block broadcast_18 stored as values in memory (estimated size 198.7 KiB, free 2.2 GiB)
[2025-10-03 20:37:13] INFO  MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
[2025-10-03 20:37:13] INFO  BlockManagerInfo - Added broadcast_18_piece0 in memory on DESKTOP-618L1DH:60897 (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:37:13] INFO  SparkContext - Created broadcast 18 from save at DataIngestion.java:96
[2025-10-03 20:37:13] INFO  FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-10-03 20:37:13] INFO  SparkContext - Starting job: save at DataIngestion.java:96
[2025-10-03 20:37:13] INFO  DAGScheduler - Got job 9 (save at DataIngestion.java:96) with 1 output partitions
[2025-10-03 20:37:13] INFO  DAGScheduler - Final stage: ResultStage 9 (save at DataIngestion.java:96)
[2025-10-03 20:37:13] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:37:13] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:37:13] INFO  DAGScheduler - Submitting ResultStage 9 (MapPartitionsRDD[47] at save at DataIngestion.java:96), which has no missing parents
[2025-10-03 20:37:13] INFO  MemoryStore - Block broadcast_19 stored as values in memory (estimated size 27.9 KiB, free 2.2 GiB)
[2025-10-03 20:37:13] INFO  MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 13.3 KiB, free 2.2 GiB)
[2025-10-03 20:37:13] INFO  BlockManagerInfo - Added broadcast_19_piece0 in memory on DESKTOP-618L1DH:60897 (size: 13.3 KiB, free: 2.2 GiB)
[2025-10-03 20:37:13] INFO  SparkContext - Created broadcast 19 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:37:13] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[47] at save at DataIngestion.java:96) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:37:13] INFO  TaskSchedulerImpl - Adding task set 9.0 with 1 tasks resource profile 0
[2025-10-03 20:37:13] INFO  TaskSetManager - Starting task 0.0 in stage 9.0 (TID 13) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9694 bytes) 
[2025-10-03 20:37:13] INFO  Executor - Running task 0.0 in stage 9.0 (TID 13)
[2025-10-03 20:37:13] INFO  CodeGenerator - Code generated in 13.9386 ms
[2025-10-03 20:37:13] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/carrier_lookup.csv, range: 0-754, partition values: [empty row]
[2025-10-03 20:37:13] INFO  Executor - Finished task 0.0 in stage 9.0 (TID 13). 1481 bytes result sent to driver
[2025-10-03 20:37:13] INFO  TaskSetManager - Finished task 0.0 in stage 9.0 (TID 13) in 103 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:37:13] INFO  TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
[2025-10-03 20:37:13] INFO  DAGScheduler - ResultStage 9 (save at DataIngestion.java:96) finished in 0.120 s
[2025-10-03 20:37:13] INFO  DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:37:13] INFO  TaskSchedulerImpl - Killing all running tasks in stage 9: Stage finished
[2025-10-03 20:37:13] INFO  DAGScheduler - Job 9 finished: save at DataIngestion.java:96, took 0.124342 s
[2025-10-03 20:37:13] INFO  DataIngestion - Saving parquet: data/output/bronze/airport_lookup
[2025-10-03 20:37:13] INFO  FileSourceStrategy - Pushed Filters: 
[2025-10-03 20:37:13] INFO  FileSourceStrategy - Post-Scan Filters: 
[2025-10-03 20:37:13] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:37:13] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:37:13] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:37:13] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:37:13] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:37:13] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:37:13] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:37:13] INFO  MemoryStore - Block broadcast_20 stored as values in memory (estimated size 198.7 KiB, free 2.2 GiB)
[2025-10-03 20:37:13] INFO  MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
[2025-10-03 20:37:13] INFO  BlockManagerInfo - Added broadcast_20_piece0 in memory on DESKTOP-618L1DH:60897 (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:37:13] INFO  SparkContext - Created broadcast 20 from save at DataIngestion.java:85
[2025-10-03 20:37:13] INFO  FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-10-03 20:37:13] INFO  SparkContext - Starting job: save at DataIngestion.java:85
[2025-10-03 20:37:13] INFO  DAGScheduler - Got job 10 (save at DataIngestion.java:85) with 1 output partitions
[2025-10-03 20:37:13] INFO  DAGScheduler - Final stage: ResultStage 10 (save at DataIngestion.java:85)
[2025-10-03 20:37:13] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:37:13] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:37:13] INFO  DAGScheduler - Submitting ResultStage 10 (MapPartitionsRDD[51] at save at DataIngestion.java:85), which has no missing parents
[2025-10-03 20:37:13] INFO  MemoryStore - Block broadcast_21 stored as values in memory (estimated size 212.8 KiB, free 2.2 GiB)
[2025-10-03 20:37:13] INFO  MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 2.2 GiB)
[2025-10-03 20:37:13] INFO  BlockManagerInfo - Added broadcast_21_piece0 in memory on DESKTOP-618L1DH:60897 (size: 76.9 KiB, free: 2.2 GiB)
[2025-10-03 20:37:13] INFO  SparkContext - Created broadcast 21 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:37:13] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[51] at save at DataIngestion.java:85) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:37:13] INFO  TaskSchedulerImpl - Adding task set 10.0 with 1 tasks resource profile 0
[2025-10-03 20:37:13] INFO  TaskSetManager - Starting task 0.0 in stage 10.0 (TID 14) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9917 bytes) 
[2025-10-03 20:37:13] INFO  Executor - Running task 0.0 in stage 10.0 (TID 14)
[2025-10-03 20:37:13] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:37:13] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:37:13] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:37:13] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:37:13] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:37:13] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:37:13] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:37:13] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:37:13] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-03 20:37:13] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "iso_country",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "iata_code",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary iso_country (STRING);
  optional binary name (STRING);
  optional binary iata_code (STRING);
}

       
[2025-10-03 20:37:13] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/airports.csv, range: 0-71857, partition values: [empty row]
[2025-10-03 20:37:13] INFO  CodeGenerator - Code generated in 11.3916 ms
[2025-10-03 20:37:13] INFO  FileOutputCommitter - Saved output of task 'attempt_202510032037135363042004756649243_0010_m_000000_14' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/bronze/airport_lookup/_temporary/0/task_202510032037135363042004756649243_0010_m_000000
[2025-10-03 20:37:13] INFO  SparkHadoopMapRedUtil - attempt_202510032037135363042004756649243_0010_m_000000_14: Committed. Elapsed time: 3 ms.
[2025-10-03 20:37:13] INFO  Executor - Finished task 0.0 in stage 10.0 (TID 14). 2459 bytes result sent to driver
[2025-10-03 20:37:13] INFO  TaskSetManager - Finished task 0.0 in stage 10.0 (TID 14) in 111 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:37:13] INFO  TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool 
[2025-10-03 20:37:13] INFO  DAGScheduler - ResultStage 10 (save at DataIngestion.java:85) finished in 0.154 s
[2025-10-03 20:37:13] INFO  DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:37:13] INFO  TaskSchedulerImpl - Killing all running tasks in stage 10: Stage finished
[2025-10-03 20:37:13] INFO  DAGScheduler - Job 10 finished: save at DataIngestion.java:85, took 0.158559 s
[2025-10-03 20:37:13] INFO  FileFormatWriter - Start to commit write Job a57dadf8-ea02-4089-9173-6ade32466871.
[2025-10-03 20:37:13] INFO  FileFormatWriter - Write Job a57dadf8-ea02-4089-9173-6ade32466871 committed. Elapsed time: 12 ms.
[2025-10-03 20:37:13] INFO  FileFormatWriter - Finished processing stats for write job a57dadf8-ea02-4089-9173-6ade32466871.
[2025-10-03 20:37:13] INFO  DataIngestion - Overwriting data to table bronze.airport_lookup
[2025-10-03 20:37:13] INFO  FileSourceStrategy - Pushed Filters: 
[2025-10-03 20:37:13] INFO  FileSourceStrategy - Post-Scan Filters: 
[2025-10-03 20:37:13] INFO  MemoryStore - Block broadcast_22 stored as values in memory (estimated size 198.7 KiB, free 2.2 GiB)
[2025-10-03 20:37:13] INFO  MemoryStore - Block broadcast_22_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
[2025-10-03 20:37:13] INFO  BlockManagerInfo - Added broadcast_22_piece0 in memory on DESKTOP-618L1DH:60897 (size: 34.2 KiB, free: 2.2 GiB)
[2025-10-03 20:37:13] INFO  SparkContext - Created broadcast 22 from save at DataIngestion.java:96
[2025-10-03 20:37:13] INFO  FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-10-03 20:37:13] INFO  SparkContext - Starting job: save at DataIngestion.java:96
[2025-10-03 20:37:13] INFO  DAGScheduler - Got job 11 (save at DataIngestion.java:96) with 1 output partitions
[2025-10-03 20:37:13] INFO  DAGScheduler - Final stage: ResultStage 11 (save at DataIngestion.java:96)
[2025-10-03 20:37:13] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:37:13] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:37:13] INFO  DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[56] at save at DataIngestion.java:96), which has no missing parents
[2025-10-03 20:37:13] INFO  MemoryStore - Block broadcast_23 stored as values in memory (estimated size 28.1 KiB, free 2.2 GiB)
[2025-10-03 20:37:13] INFO  MemoryStore - Block broadcast_23_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 2.2 GiB)
[2025-10-03 20:37:13] INFO  BlockManagerInfo - Added broadcast_23_piece0 in memory on DESKTOP-618L1DH:60897 (size: 13.4 KiB, free: 2.2 GiB)
[2025-10-03 20:37:13] INFO  SparkContext - Created broadcast 23 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:37:13] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[56] at save at DataIngestion.java:96) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:37:13] INFO  TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
[2025-10-03 20:37:13] INFO  TaskSetManager - Starting task 0.0 in stage 11.0 (TID 15) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9688 bytes) 
[2025-10-03 20:37:13] INFO  Executor - Running task 0.0 in stage 11.0 (TID 15)
[2025-10-03 20:37:13] INFO  CodeGenerator - Code generated in 12.2594 ms
[2025-10-03 20:37:13] INFO  FileScanRDD - Reading File path: file:///C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/input/airports.csv, range: 0-71857, partition values: [empty row]
[2025-10-03 20:37:14] INFO  Executor - Finished task 0.0 in stage 11.0 (TID 15). 1438 bytes result sent to driver
[2025-10-03 20:37:14] INFO  TaskSetManager - Finished task 0.0 in stage 11.0 (TID 15) in 1023 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:37:14] INFO  TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
[2025-10-03 20:37:14] INFO  DAGScheduler - ResultStage 11 (save at DataIngestion.java:96) finished in 1.042 s
[2025-10-03 20:37:14] INFO  DAGScheduler - Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:37:14] INFO  TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
[2025-10-03 20:37:14] INFO  DAGScheduler - Job 11 finished: save at DataIngestion.java:96, took 1.047678 s
[2025-10-03 20:37:14] INFO  DataIngestion - Data ingestion completed. Bronze layer stored at data/output/bronze/ and database bronze
[2025-10-03 20:37:14] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-03 20:37:14] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 20:37:14] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-03 20:37:14] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-03 20:37:14] INFO  MemoryStore - MemoryStore cleared
[2025-10-03 20:37:14] INFO  BlockManager - BlockManager stopped
[2025-10-03 20:37:14] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-03 20:37:14] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-03 20:37:14] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-03 20:37:14] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-03 20:37:14] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-e2f32c17-5f24-4d58-a771-a72b4ecaf921
[2025-10-03 20:38:00] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-03 20:38:00] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-03 20:38:00] INFO  SparkContext - Java version 11.0.27
[2025-10-03 20:38:00] INFO  ResourceUtils - ==============================================================
[2025-10-03 20:38:00] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-03 20:38:00] INFO  ResourceUtils - ==============================================================
[2025-10-03 20:38:00] INFO  SparkContext - Submitted application: Airline Delay Data Cleaning
[2025-10-03 20:38:00] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-03 20:38:00] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-03 20:38:00] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-03 20:38:00] INFO  SecurityManager - Changing view acls to: USER
[2025-10-03 20:38:00] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-03 20:38:00] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-03 20:38:00] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-03 20:38:00] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-03 20:38:01] INFO  Utils - Successfully started service 'sparkDriver' on port 65201.
[2025-10-03 20:38:01] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-03 20:38:01] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-03 20:38:01] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-03 20:38:01] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-03 20:38:01] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-03 20:38:01] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-b825438b-b1bb-4ac9-a1ab-ad40f15aac91
[2025-10-03 20:38:01] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-03 20:38:01] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-03 20:38:01] INFO  log - Logging initialized @3362ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-03 20:38:01] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-03 20:38:01] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-03 20:38:01] INFO  Server - Started @3523ms
[2025-10-03 20:38:01] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 20:38:01] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-03 20:38:01] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@244418a{/,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-03 20:38:02] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-03 20:38:02] INFO  Executor - Java version 11.0.27
[2025-10-03 20:38:02] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-03 20:38:02] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3d90eeb3 for default.
[2025-10-03 20:38:02] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65248.
[2025-10-03 20:38:02] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:65248
[2025-10-03 20:38:02] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-03 20:38:02] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 65248, None)
[2025-10-03 20:38:02] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:65248 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 65248, None)
[2025-10-03 20:38:02] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 65248, None)
[2025-10-03 20:38:02] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 65248, None)
[2025-10-03 20:38:02] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@244418a{/,null,STOPPED,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@30db5536{/jobs,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@136ccbfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@61874b9d{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f2d014a{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@a7cf42f{/stages,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@28e0e464{/stages/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b7c80c6{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7499eac7{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@b9d018b{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79eeff87{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@8bd076a{/storage,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1378eea2{/storage/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66522ead{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@e91b4f4{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58ae402b{/environment,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43ac0a68{/environment/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3728a578{/executors,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de0641b{/executors/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a464fa3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ccb85d6{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@259b85d6{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@488f3dd1{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7bc58891{/static,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@566f1852{/,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e4389ed{/api,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7edb6fca{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@716185fe{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@234c5e41{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  DataCleaning - Loading from DB Table: bronze.raw_dataset
[2025-10-03 20:38:02] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-03 20:38:02] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@432af457{/SQL,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@519c6fcc{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@713a35c5{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@11787b64{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:02] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6b321262{/static/sql,null,AVAILABLE,@Spark}
[2025-10-03 20:38:05] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_dataset
[2025-10-03 20:38:06] INFO  CodeGenerator - Code generated in 344.9602 ms
[2025-10-03 20:38:06] INFO  DAGScheduler - Registering RDD 2 (save at DataCleaning.java:132) as input to shuffle 0
[2025-10-03 20:38:06] INFO  DAGScheduler - Got map stage job 0 (save at DataCleaning.java:132) with 1 output partitions
[2025-10-03 20:38:06] INFO  DAGScheduler - Final stage: ShuffleMapStage 0 (save at DataCleaning.java:132)
[2025-10-03 20:38:06] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:38:06] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:38:06] INFO  DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at DataCleaning.java:132), which has no missing parents
[2025-10-03 20:38:07] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 75.7 KiB, free 2.2 GiB)
[2025-10-03 20:38:07] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-03 20:38:07] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on DESKTOP-618L1DH:65248 (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-03 20:38:07] INFO  SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:38:07] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at DataCleaning.java:132) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:38:07] INFO  TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
[2025-10-03 20:38:07] INFO  TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:38:07] INFO  Executor - Running task 0.0 in stage 0.0 (TID 0)
[2025-10-03 20:38:07] INFO  CodeGenerator - Code generated in 84.0796 ms
[2025-10-03 20:38:07] INFO  CodeGenerator - Code generated in 23.8583 ms
[2025-10-03 20:38:07] INFO  CodeGenerator - Code generated in 7.6569 ms
[2025-10-03 20:38:07] INFO  CodeGenerator - Code generated in 15.5056 ms
[2025-10-03 20:38:08] INFO  JDBCRDD - closed connection
[2025-10-03 20:38:08] INFO  Executor - Finished task 0.0 in stage 0.0 (TID 0). 2593 bytes result sent to driver
[2025-10-03 20:38:08] INFO  TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1721 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:38:08] INFO  TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[2025-10-03 20:38:08] INFO  DAGScheduler - ShuffleMapStage 0 (save at DataCleaning.java:132) finished in 1.976 s
[2025-10-03 20:38:08] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:38:08] INFO  DAGScheduler - running: Set()
[2025-10-03 20:38:08] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:38:08] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:38:08] INFO  ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:38:09] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:09] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:38:09] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:38:09] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:09] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:38:09] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:38:09] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:09] INFO  CodeGenerator - Code generated in 61.0372 ms
[2025-10-03 20:38:09] INFO  SparkContext - Starting job: save at DataCleaning.java:132
[2025-10-03 20:38:09] INFO  DAGScheduler - Got job 1 (save at DataCleaning.java:132) with 1 output partitions
[2025-10-03 20:38:09] INFO  DAGScheduler - Final stage: ResultStage 2 (save at DataCleaning.java:132)
[2025-10-03 20:38:09] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
[2025-10-03 20:38:09] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:38:09] INFO  DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[6] at save at DataCleaning.java:132), which has no missing parents
[2025-10-03 20:38:09] INFO  MemoryStore - Block broadcast_1 stored as values in memory (estimated size 288.9 KiB, free 2.2 GiB)
[2025-10-03 20:38:09] INFO  MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 102.8 KiB, free 2.2 GiB)
[2025-10-03 20:38:09] INFO  BlockManagerInfo - Added broadcast_1_piece0 in memory on DESKTOP-618L1DH:65248 (size: 102.8 KiB, free: 2.2 GiB)
[2025-10-03 20:38:09] INFO  SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:38:09] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at save at DataCleaning.java:132) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:38:09] INFO  TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
[2025-10-03 20:38:09] INFO  TaskSetManager - Starting task 0.0 in stage 2.0 (TID 1) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9387 bytes) 
[2025-10-03 20:38:09] INFO  Executor - Running task 0.0 in stage 2.0 (TID 1)
[2025-10-03 20:38:09] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:38:09] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:38:09] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:09] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:38:09] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:38:09] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:09] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:38:09] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:38:09] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-03 20:38:09] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "year",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "month",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "airport",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "isSigned" : false,
      "scale" : 0
    }
  }, {
    "name" : "airport_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_flights",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_del15",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "weather_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "nas_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "security_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "late_aircraft_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_cancelled",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_diverted",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "weather_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "nas_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "security_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "late_aircraft_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 year;
  optional int32 month;
  optional binary carrier (STRING);
  optional binary carrier_name (STRING);
  optional binary airport (STRING);
  optional binary airport_name (STRING);
  optional int32 arr_flights;
  optional double arr_del15;
  optional double carrier_ct;
  optional double weather_ct;
  optional double nas_ct;
  optional double security_ct;
  optional double late_aircraft_ct;
  optional double arr_cancelled;
  optional double arr_diverted;
  optional double arr_delay;
  optional double carrier_delay;
  optional double weather_delay;
  optional double nas_delay;
  optional double security_delay;
  optional double late_aircraft_delay;
  optional int32 date (DATE);
}

       
[2025-10-03 20:38:09] INFO  CodecPool - Got brand-new compressor [.snappy]
[2025-10-03 20:38:09] INFO  ShuffleBlockFetcherIterator - Getting 1 (1052.4 KiB) non-empty blocks including 1 (1052.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:09] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 12 ms
[2025-10-03 20:38:09] INFO  CodeGenerator - Code generated in 48.3926 ms
[2025-10-03 20:38:10] INFO  ShuffleBlockFetcherIterator - Getting 1 (1053.2 KiB) non-empty blocks including 1 (1053.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:10] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:38:10] INFO  ShuffleBlockFetcherIterator - Getting 1 (1035.9 KiB) non-empty blocks including 1 (1035.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:10] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:38:10] INFO  ShuffleBlockFetcherIterator - Getting 1 (1031.9 KiB) non-empty blocks including 1 (1031.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:10] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:38:10] INFO  ShuffleBlockFetcherIterator - Getting 1 (1637.5 KiB) non-empty blocks including 1 (1637.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:10] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 9 ms
[2025-10-03 20:38:11] INFO  FileOutputCommitter - Saved output of task 'attempt_202510032038095542273131046936883_0002_m_000000_1' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/silver/cleaned_dataset/_temporary/0/task_202510032038095542273131046936883_0002_m_000000
[2025-10-03 20:38:11] INFO  SparkHadoopMapRedUtil - attempt_202510032038095542273131046936883_0002_m_000000_1: Committed. Elapsed time: 2 ms.
[2025-10-03 20:38:11] INFO  Executor - Finished task 0.0 in stage 2.0 (TID 1). 6005 bytes result sent to driver
[2025-10-03 20:38:11] INFO  TaskSetManager - Finished task 0.0 in stage 2.0 (TID 1) in 1763 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:38:11] INFO  TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[2025-10-03 20:38:11] INFO  DAGScheduler - ResultStage 2 (save at DataCleaning.java:132) finished in 1.849 s
[2025-10-03 20:38:11] INFO  DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:38:11] INFO  TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
[2025-10-03 20:38:11] INFO  DAGScheduler - Job 1 finished: save at DataCleaning.java:132, took 1.865732 s
[2025-10-03 20:38:11] INFO  FileFormatWriter - Start to commit write Job 26f39ba6-181b-4692-a422-e9467fd4ddc6.
[2025-10-03 20:38:11] INFO  FileFormatWriter - Write Job 26f39ba6-181b-4692-a422-e9467fd4ddc6 committed. Elapsed time: 31 ms.
[2025-10-03 20:38:11] INFO  FileFormatWriter - Finished processing stats for write job 26f39ba6-181b-4692-a422-e9467fd4ddc6.
[2025-10-03 20:38:11] INFO  DataCleaning - Overwriting DB Table: silver.cleaned_dataset
[2025-10-03 20:38:11] WARN  SparkStringUtils - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2025-10-03 20:38:11] INFO  DAGScheduler - Registering RDD 9 (save at DataCleaning.java:143) as input to shuffle 1
[2025-10-03 20:38:11] INFO  DAGScheduler - Got map stage job 2 (save at DataCleaning.java:143) with 1 output partitions
[2025-10-03 20:38:11] INFO  DAGScheduler - Final stage: ShuffleMapStage 3 (save at DataCleaning.java:143)
[2025-10-03 20:38:11] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:38:11] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:38:11] INFO  DAGScheduler - Submitting ShuffleMapStage 3 (MapPartitionsRDD[9] at save at DataCleaning.java:143), which has no missing parents
[2025-10-03 20:38:11] INFO  MemoryStore - Block broadcast_2 stored as values in memory (estimated size 75.7 KiB, free 2.2 GiB)
[2025-10-03 20:38:11] INFO  MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-03 20:38:11] INFO  BlockManagerInfo - Added broadcast_2_piece0 in memory on DESKTOP-618L1DH:65248 (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-03 20:38:11] INFO  SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:38:11] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[9] at save at DataCleaning.java:143) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:38:11] INFO  TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
[2025-10-03 20:38:11] INFO  TaskSetManager - Starting task 0.0 in stage 3.0 (TID 2) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:38:11] INFO  Executor - Running task 0.0 in stage 3.0 (TID 2)
[2025-10-03 20:38:11] INFO  BlockManagerInfo - Removed broadcast_1_piece0 on DESKTOP-618L1DH:65248 in memory (size: 102.8 KiB, free: 2.2 GiB)
[2025-10-03 20:38:12] INFO  JDBCRDD - closed connection
[2025-10-03 20:38:12] INFO  Executor - Finished task 0.0 in stage 3.0 (TID 2). 2507 bytes result sent to driver
[2025-10-03 20:38:12] INFO  TaskSetManager - Finished task 0.0 in stage 3.0 (TID 2) in 786 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:38:12] INFO  TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[2025-10-03 20:38:12] INFO  DAGScheduler - ShuffleMapStage 3 (save at DataCleaning.java:143) finished in 0.797 s
[2025-10-03 20:38:12] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:38:12] INFO  DAGScheduler - running: Set()
[2025-10-03 20:38:12] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:38:12] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:38:12] INFO  ShufflePartitionsUtil - For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:38:12] INFO  SparkContext - Starting job: save at DataCleaning.java:143
[2025-10-03 20:38:12] INFO  DAGScheduler - Got job 3 (save at DataCleaning.java:143) with 5 output partitions
[2025-10-03 20:38:12] INFO  DAGScheduler - Final stage: ResultStage 5 (save at DataCleaning.java:143)
[2025-10-03 20:38:12] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 4)
[2025-10-03 20:38:12] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:38:12] INFO  DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[14] at save at DataCleaning.java:143), which has no missing parents
[2025-10-03 20:38:12] INFO  MemoryStore - Block broadcast_3 stored as values in memory (estimated size 95.5 KiB, free 2.2 GiB)
[2025-10-03 20:38:12] INFO  MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 2.2 GiB)
[2025-10-03 20:38:12] INFO  BlockManagerInfo - Added broadcast_3_piece0 in memory on DESKTOP-618L1DH:65248 (size: 34.8 KiB, free: 2.2 GiB)
[2025-10-03 20:38:12] INFO  SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:38:12] INFO  DAGScheduler - Submitting 5 missing tasks from ResultStage 5 (MapPartitionsRDD[14] at save at DataCleaning.java:143) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
[2025-10-03 20:38:12] INFO  TaskSchedulerImpl - Adding task set 5.0 with 5 tasks resource profile 0
[2025-10-03 20:38:12] INFO  TaskSetManager - Starting task 0.0 in stage 5.0 (TID 3) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:38:12] INFO  TaskSetManager - Starting task 1.0 in stage 5.0 (TID 4) (DESKTOP-618L1DH, executor driver, partition 1, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:38:12] INFO  TaskSetManager - Starting task 2.0 in stage 5.0 (TID 5) (DESKTOP-618L1DH, executor driver, partition 2, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:38:12] INFO  TaskSetManager - Starting task 3.0 in stage 5.0 (TID 6) (DESKTOP-618L1DH, executor driver, partition 3, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:38:12] INFO  TaskSetManager - Starting task 4.0 in stage 5.0 (TID 7) (DESKTOP-618L1DH, executor driver, partition 4, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:38:12] INFO  Executor - Running task 0.0 in stage 5.0 (TID 3)
[2025-10-03 20:38:12] INFO  Executor - Running task 2.0 in stage 5.0 (TID 5)
[2025-10-03 20:38:12] INFO  Executor - Running task 1.0 in stage 5.0 (TID 4)
[2025-10-03 20:38:12] INFO  Executor - Running task 4.0 in stage 5.0 (TID 7)
[2025-10-03 20:38:12] INFO  Executor - Running task 3.0 in stage 5.0 (TID 6)
[2025-10-03 20:38:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (1637.5 KiB) non-empty blocks including 1 (1637.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (1035.9 KiB) non-empty blocks including 1 (1035.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (1053.2 KiB) non-empty blocks including 1 (1053.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (1031.9 KiB) non-empty blocks including 1 (1031.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-03 20:38:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-03 20:38:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 4 ms
[2025-10-03 20:38:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-03 20:38:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (1052.4 KiB) non-empty blocks including 1 (1052.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:38:13] INFO  CodeGenerator - Code generated in 22.2714 ms
[2025-10-03 20:38:17] INFO  Executor - Finished task 3.0 in stage 5.0 (TID 6). 4794 bytes result sent to driver
[2025-10-03 20:38:17] INFO  TaskSetManager - Finished task 3.0 in stage 5.0 (TID 6) in 4862 ms on DESKTOP-618L1DH (executor driver) (1/5)
[2025-10-03 20:38:17] INFO  Executor - Finished task 2.0 in stage 5.0 (TID 5). 4751 bytes result sent to driver
[2025-10-03 20:38:17] INFO  TaskSetManager - Finished task 2.0 in stage 5.0 (TID 5) in 4881 ms on DESKTOP-618L1DH (executor driver) (2/5)
[2025-10-03 20:38:17] INFO  Executor - Finished task 0.0 in stage 5.0 (TID 3). 4751 bytes result sent to driver
[2025-10-03 20:38:17] INFO  TaskSetManager - Finished task 0.0 in stage 5.0 (TID 3) in 4991 ms on DESKTOP-618L1DH (executor driver) (3/5)
[2025-10-03 20:38:17] INFO  Executor - Finished task 1.0 in stage 5.0 (TID 4). 4751 bytes result sent to driver
[2025-10-03 20:38:17] INFO  TaskSetManager - Finished task 1.0 in stage 5.0 (TID 4) in 5016 ms on DESKTOP-618L1DH (executor driver) (4/5)
[2025-10-03 20:38:20] INFO  Executor - Finished task 4.0 in stage 5.0 (TID 7). 4751 bytes result sent to driver
[2025-10-03 20:38:20] INFO  TaskSetManager - Finished task 4.0 in stage 5.0 (TID 7) in 7699 ms on DESKTOP-618L1DH (executor driver) (5/5)
[2025-10-03 20:38:20] INFO  TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[2025-10-03 20:38:20] INFO  DAGScheduler - ResultStage 5 (save at DataCleaning.java:143) finished in 7.731 s
[2025-10-03 20:38:20] INFO  DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:38:20] INFO  TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
[2025-10-03 20:38:20] INFO  DAGScheduler - Job 3 finished: save at DataCleaning.java:143, took 7.744616 s
[2025-10-03 20:38:20] INFO  DAGScheduler - Registering RDD 17 (count at DataCleaning.java:41) as input to shuffle 2
[2025-10-03 20:38:20] INFO  DAGScheduler - Got map stage job 4 (count at DataCleaning.java:41) with 1 output partitions
[2025-10-03 20:38:20] INFO  DAGScheduler - Final stage: ShuffleMapStage 6 (count at DataCleaning.java:41)
[2025-10-03 20:38:20] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:38:20] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:38:20] INFO  DAGScheduler - Submitting ShuffleMapStage 6 (MapPartitionsRDD[17] at count at DataCleaning.java:41), which has no missing parents
[2025-10-03 20:38:20] INFO  MemoryStore - Block broadcast_4 stored as values in memory (estimated size 75.7 KiB, free 2.2 GiB)
[2025-10-03 20:38:20] INFO  MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-03 20:38:20] INFO  BlockManagerInfo - Added broadcast_4_piece0 in memory on DESKTOP-618L1DH:65248 (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-03 20:38:20] INFO  SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:38:20] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[17] at count at DataCleaning.java:41) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:38:20] INFO  TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
[2025-10-03 20:38:20] INFO  TaskSetManager - Starting task 0.0 in stage 6.0 (TID 8) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:38:20] INFO  Executor - Running task 0.0 in stage 6.0 (TID 8)
[2025-10-03 20:38:20] INFO  JDBCRDD - closed connection
[2025-10-03 20:38:21] INFO  Executor - Finished task 0.0 in stage 6.0 (TID 8). 2593 bytes result sent to driver
[2025-10-03 20:38:21] INFO  TaskSetManager - Finished task 0.0 in stage 6.0 (TID 8) in 749 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:38:21] INFO  TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[2025-10-03 20:38:21] INFO  DAGScheduler - ShuffleMapStage 6 (count at DataCleaning.java:41) finished in 0.761 s
[2025-10-03 20:38:21] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:38:21] INFO  DAGScheduler - running: Set()
[2025-10-03 20:38:21] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:38:21] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:38:21] INFO  ShufflePartitionsUtil - For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:38:21] INFO  BlockManagerInfo - Removed broadcast_3_piece0 on DESKTOP-618L1DH:65248 in memory (size: 34.8 KiB, free: 2.2 GiB)
[2025-10-03 20:38:21] INFO  BlockManagerInfo - Removed broadcast_2_piece0 on DESKTOP-618L1DH:65248 in memory (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-03 20:38:21] INFO  BlockManagerInfo - Removed broadcast_0_piece0 on DESKTOP-618L1DH:65248 in memory (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-03 20:38:21] INFO  CodeGenerator - Code generated in 57.1399 ms
[2025-10-03 20:38:21] INFO  DAGScheduler - Registering RDD 20 (count at DataCleaning.java:41) as input to shuffle 3
[2025-10-03 20:38:21] INFO  DAGScheduler - Got map stage job 5 (count at DataCleaning.java:41) with 5 output partitions
[2025-10-03 20:38:21] INFO  DAGScheduler - Final stage: ShuffleMapStage 8 (count at DataCleaning.java:41)
[2025-10-03 20:38:21] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 7)
[2025-10-03 20:38:21] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:38:21] INFO  DAGScheduler - Submitting ShuffleMapStage 8 (MapPartitionsRDD[20] at count at DataCleaning.java:41), which has no missing parents
[2025-10-03 20:38:21] INFO  MemoryStore - Block broadcast_5 stored as values in memory (estimated size 76.1 KiB, free 2.2 GiB)
[2025-10-03 20:38:21] INFO  MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.1 KiB, free 2.2 GiB)
[2025-10-03 20:38:21] INFO  BlockManagerInfo - Added broadcast_5_piece0 in memory on DESKTOP-618L1DH:65248 (size: 29.1 KiB, free: 2.2 GiB)
[2025-10-03 20:38:21] INFO  SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:38:21] INFO  DAGScheduler - Submitting 5 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[20] at count at DataCleaning.java:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
[2025-10-03 20:38:21] INFO  TaskSchedulerImpl - Adding task set 8.0 with 5 tasks resource profile 0
[2025-10-03 20:38:21] INFO  TaskSetManager - Starting task 0.0 in stage 8.0 (TID 9) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-03 20:38:21] INFO  TaskSetManager - Starting task 1.0 in stage 8.0 (TID 10) (DESKTOP-618L1DH, executor driver, partition 1, NODE_LOCAL, 8988 bytes) 
[2025-10-03 20:38:21] INFO  TaskSetManager - Starting task 2.0 in stage 8.0 (TID 11) (DESKTOP-618L1DH, executor driver, partition 2, NODE_LOCAL, 8988 bytes) 
[2025-10-03 20:38:21] INFO  TaskSetManager - Starting task 3.0 in stage 8.0 (TID 12) (DESKTOP-618L1DH, executor driver, partition 3, NODE_LOCAL, 8988 bytes) 
[2025-10-03 20:38:21] INFO  TaskSetManager - Starting task 4.0 in stage 8.0 (TID 13) (DESKTOP-618L1DH, executor driver, partition 4, NODE_LOCAL, 8988 bytes) 
[2025-10-03 20:38:21] INFO  Executor - Running task 2.0 in stage 8.0 (TID 11)
[2025-10-03 20:38:21] INFO  Executor - Running task 1.0 in stage 8.0 (TID 10)
[2025-10-03 20:38:21] INFO  Executor - Running task 3.0 in stage 8.0 (TID 12)
[2025-10-03 20:38:21] INFO  Executor - Running task 0.0 in stage 8.0 (TID 9)
[2025-10-03 20:38:21] INFO  Executor - Running task 4.0 in stage 8.0 (TID 13)
[2025-10-03 20:38:21] INFO  ShuffleBlockFetcherIterator - Getting 1 (1637.5 KiB) non-empty blocks including 1 (1637.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:21] INFO  ShuffleBlockFetcherIterator - Getting 1 (1031.9 KiB) non-empty blocks including 1 (1031.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:21] INFO  ShuffleBlockFetcherIterator - Getting 1 (1052.4 KiB) non-empty blocks including 1 (1052.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:21] INFO  ShuffleBlockFetcherIterator - Getting 1 (1053.2 KiB) non-empty blocks including 1 (1053.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:21] INFO  ShuffleBlockFetcherIterator - Getting 1 (1035.9 KiB) non-empty blocks including 1 (1035.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:21] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:38:21] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:38:21] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:38:21] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:38:21] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:38:21] INFO  CodeGenerator - Code generated in 40.608 ms
[2025-10-03 20:38:21] INFO  Executor - Finished task 0.0 in stage 8.0 (TID 9). 5380 bytes result sent to driver
[2025-10-03 20:38:21] INFO  TaskSetManager - Finished task 0.0 in stage 8.0 (TID 9) in 198 ms on DESKTOP-618L1DH (executor driver) (1/5)
[2025-10-03 20:38:21] INFO  Executor - Finished task 2.0 in stage 8.0 (TID 11). 5380 bytes result sent to driver
[2025-10-03 20:38:21] INFO  TaskSetManager - Finished task 2.0 in stage 8.0 (TID 11) in 201 ms on DESKTOP-618L1DH (executor driver) (2/5)
[2025-10-03 20:38:21] INFO  Executor - Finished task 1.0 in stage 8.0 (TID 10). 5380 bytes result sent to driver
[2025-10-03 20:38:21] INFO  TaskSetManager - Finished task 1.0 in stage 8.0 (TID 10) in 207 ms on DESKTOP-618L1DH (executor driver) (3/5)
[2025-10-03 20:38:21] INFO  Executor - Finished task 3.0 in stage 8.0 (TID 12). 5380 bytes result sent to driver
[2025-10-03 20:38:21] INFO  TaskSetManager - Finished task 3.0 in stage 8.0 (TID 12) in 211 ms on DESKTOP-618L1DH (executor driver) (4/5)
[2025-10-03 20:38:21] INFO  Executor - Finished task 4.0 in stage 8.0 (TID 13). 5380 bytes result sent to driver
[2025-10-03 20:38:21] INFO  TaskSetManager - Finished task 4.0 in stage 8.0 (TID 13) in 213 ms on DESKTOP-618L1DH (executor driver) (5/5)
[2025-10-03 20:38:21] INFO  TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[2025-10-03 20:38:21] INFO  DAGScheduler - ShuffleMapStage 8 (count at DataCleaning.java:41) finished in 0.232 s
[2025-10-03 20:38:21] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:38:21] INFO  DAGScheduler - running: Set()
[2025-10-03 20:38:21] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:38:21] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:38:21] INFO  CodeGenerator - Code generated in 8.7652 ms
[2025-10-03 20:38:21] INFO  SparkContext - Starting job: count at DataCleaning.java:41
[2025-10-03 20:38:21] INFO  DAGScheduler - Got job 6 (count at DataCleaning.java:41) with 1 output partitions
[2025-10-03 20:38:21] INFO  DAGScheduler - Final stage: ResultStage 11 (count at DataCleaning.java:41)
[2025-10-03 20:38:21] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 10)
[2025-10-03 20:38:21] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:38:21] INFO  DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[23] at count at DataCleaning.java:41), which has no missing parents
[2025-10-03 20:38:21] INFO  MemoryStore - Block broadcast_6 stored as values in memory (estimated size 12.5 KiB, free 2.2 GiB)
[2025-10-03 20:38:21] INFO  MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
[2025-10-03 20:38:21] INFO  BlockManagerInfo - Added broadcast_6_piece0 in memory on DESKTOP-618L1DH:65248 (size: 5.9 KiB, free: 2.2 GiB)
[2025-10-03 20:38:21] INFO  SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:38:21] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[23] at count at DataCleaning.java:41) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:38:21] INFO  TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
[2025-10-03 20:38:21] INFO  TaskSetManager - Starting task 0.0 in stage 11.0 (TID 14) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:38:21] INFO  Executor - Running task 0.0 in stage 11.0 (TID 14)
[2025-10-03 20:38:21] INFO  ShuffleBlockFetcherIterator - Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:38:21] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:38:21] INFO  CodeGenerator - Code generated in 11.5276 ms
[2025-10-03 20:38:21] INFO  BlockManagerInfo - Removed broadcast_5_piece0 on DESKTOP-618L1DH:65248 in memory (size: 29.1 KiB, free: 2.2 GiB)
[2025-10-03 20:38:21] INFO  Executor - Finished task 0.0 in stage 11.0 (TID 14). 4081 bytes result sent to driver
[2025-10-03 20:38:21] INFO  TaskSetManager - Finished task 0.0 in stage 11.0 (TID 14) in 72 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:38:21] INFO  TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
[2025-10-03 20:38:21] INFO  DAGScheduler - ResultStage 11 (count at DataCleaning.java:41) finished in 0.083 s
[2025-10-03 20:38:21] INFO  DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:38:21] INFO  TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
[2025-10-03 20:38:21] INFO  DAGScheduler - Job 6 finished: count at DataCleaning.java:41, took 0.090976 s
[2025-10-03 20:38:21] INFO  DataCleaning - Cleaned dataset stored in silver layer. Row count = 54619
[2025-10-03 20:38:21] INFO  DataCleaning - Loading from DB Table: bronze.carrier_lookup
[2025-10-03 20:38:21] INFO  BlockManagerInfo - Removed broadcast_4_piece0 on DESKTOP-618L1DH:65248 in memory (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-03 20:38:21] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_carrier_lookup
[2025-10-03 20:38:21] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:21] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:38:21] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:38:21] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:21] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:38:21] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:38:21] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:21] INFO  CodeGenerator - Code generated in 15.1893 ms
[2025-10-03 20:38:21] INFO  SparkContext - Starting job: save at DataCleaning.java:132
[2025-10-03 20:38:21] INFO  DAGScheduler - Got job 7 (save at DataCleaning.java:132) with 1 output partitions
[2025-10-03 20:38:21] INFO  DAGScheduler - Final stage: ResultStage 12 (save at DataCleaning.java:132)
[2025-10-03 20:38:21] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:38:21] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:38:21] INFO  DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[27] at save at DataCleaning.java:132), which has no missing parents
[2025-10-03 20:38:21] INFO  MemoryStore - Block broadcast_7 stored as values in memory (estimated size 213.2 KiB, free 2.2 GiB)
[2025-10-03 20:38:21] INFO  MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 2.2 GiB)
[2025-10-03 20:38:21] INFO  BlockManagerInfo - Added broadcast_7_piece0 in memory on DESKTOP-618L1DH:65248 (size: 77.2 KiB, free: 2.2 GiB)
[2025-10-03 20:38:21] INFO  SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:38:21] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[27] at save at DataCleaning.java:132) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:38:21] INFO  TaskSchedulerImpl - Adding task set 12.0 with 1 tasks resource profile 0
[2025-10-03 20:38:21] INFO  TaskSetManager - Starting task 0.0 in stage 12.0 (TID 15) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9121 bytes) 
[2025-10-03 20:38:21] INFO  Executor - Running task 0.0 in stage 12.0 (TID 15)
[2025-10-03 20:38:21] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:38:21] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:38:21] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:21] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:38:21] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:38:21] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:21] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:38:21] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:38:21] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-03 20:38:21] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "carrier",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary carrier (STRING);
  optional binary carrier_name (STRING);
}

       
[2025-10-03 20:38:21] INFO  CodeGenerator - Code generated in 8.1872 ms
[2025-10-03 20:38:21] INFO  JDBCRDD - closed connection
[2025-10-03 20:38:21] INFO  FileOutputCommitter - Saved output of task 'attempt_202510032038216686258446157347247_0012_m_000000_15' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/silver/cleaned_carrier_lookup/_temporary/0/task_202510032038216686258446157347247_0012_m_000000
[2025-10-03 20:38:21] INFO  SparkHadoopMapRedUtil - attempt_202510032038216686258446157347247_0012_m_000000_15: Committed. Elapsed time: 4 ms.
[2025-10-03 20:38:21] INFO  Executor - Finished task 0.0 in stage 12.0 (TID 15). 2484 bytes result sent to driver
[2025-10-03 20:38:21] INFO  TaskSetManager - Finished task 0.0 in stage 12.0 (TID 15) in 111 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:38:21] INFO  TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool 
[2025-10-03 20:38:21] INFO  DAGScheduler - ResultStage 12 (save at DataCleaning.java:132) finished in 0.153 s
[2025-10-03 20:38:21] INFO  DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:38:21] INFO  TaskSchedulerImpl - Killing all running tasks in stage 12: Stage finished
[2025-10-03 20:38:21] INFO  DAGScheduler - Job 7 finished: save at DataCleaning.java:132, took 0.164788 s
[2025-10-03 20:38:21] INFO  FileFormatWriter - Start to commit write Job e8689eab-c63a-46d4-ae01-ca5ab1bce41e.
[2025-10-03 20:38:22] INFO  FileFormatWriter - Write Job e8689eab-c63a-46d4-ae01-ca5ab1bce41e committed. Elapsed time: 25 ms.
[2025-10-03 20:38:22] INFO  FileFormatWriter - Finished processing stats for write job e8689eab-c63a-46d4-ae01-ca5ab1bce41e.
[2025-10-03 20:38:22] INFO  DataCleaning - Overwriting DB Table: silver.cleaned_carrier_lookup
[2025-10-03 20:38:22] INFO  SparkContext - Starting job: save at DataCleaning.java:143
[2025-10-03 20:38:22] INFO  DAGScheduler - Got job 8 (save at DataCleaning.java:143) with 1 output partitions
[2025-10-03 20:38:22] INFO  DAGScheduler - Final stage: ResultStage 13 (save at DataCleaning.java:143)
[2025-10-03 20:38:22] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:38:22] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:38:22] INFO  DAGScheduler - Submitting ResultStage 13 (MapPartitionsRDD[32] at save at DataCleaning.java:143), which has no missing parents
[2025-10-03 20:38:22] INFO  MemoryStore - Block broadcast_8 stored as values in memory (estimated size 28.1 KiB, free 2.2 GiB)
[2025-10-03 20:38:22] INFO  MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.2 KiB, free 2.2 GiB)
[2025-10-03 20:38:22] INFO  BlockManagerInfo - Added broadcast_8_piece0 in memory on DESKTOP-618L1DH:65248 (size: 13.2 KiB, free: 2.2 GiB)
[2025-10-03 20:38:22] INFO  SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:38:22] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[32] at save at DataCleaning.java:143) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:38:22] INFO  TaskSchedulerImpl - Adding task set 13.0 with 1 tasks resource profile 0
[2025-10-03 20:38:22] INFO  TaskSetManager - Starting task 0.0 in stage 13.0 (TID 16) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) 
[2025-10-03 20:38:22] INFO  Executor - Running task 0.0 in stage 13.0 (TID 16)
[2025-10-03 20:38:22] INFO  CodeGenerator - Code generated in 9.0456 ms
[2025-10-03 20:38:22] INFO  JDBCRDD - closed connection
[2025-10-03 20:38:22] INFO  Executor - Finished task 0.0 in stage 13.0 (TID 16). 1230 bytes result sent to driver
[2025-10-03 20:38:22] INFO  TaskSetManager - Finished task 0.0 in stage 13.0 (TID 16) in 110 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:38:22] INFO  TaskSchedulerImpl - Removed TaskSet 13.0, whose tasks have all completed, from pool 
[2025-10-03 20:38:22] INFO  DAGScheduler - ResultStage 13 (save at DataCleaning.java:143) finished in 0.130 s
[2025-10-03 20:38:22] INFO  DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:38:22] INFO  TaskSchedulerImpl - Killing all running tasks in stage 13: Stage finished
[2025-10-03 20:38:22] INFO  DAGScheduler - Job 8 finished: save at DataCleaning.java:143, took 0.139489 s
[2025-10-03 20:38:22] INFO  DataCleaning - Loading from DB Table: bronze.airport_lookup
[2025-10-03 20:38:22] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_airport_lookup
[2025-10-03 20:38:22] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:22] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:38:22] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:38:22] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:22] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:38:22] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:38:22] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:22] INFO  CodeGenerator - Code generated in 7.2459 ms
[2025-10-03 20:38:22] INFO  SparkContext - Starting job: save at DataCleaning.java:132
[2025-10-03 20:38:22] INFO  DAGScheduler - Got job 9 (save at DataCleaning.java:132) with 1 output partitions
[2025-10-03 20:38:22] INFO  DAGScheduler - Final stage: ResultStage 14 (save at DataCleaning.java:132)
[2025-10-03 20:38:22] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:38:22] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:38:22] INFO  DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[36] at save at DataCleaning.java:132), which has no missing parents
[2025-10-03 20:38:22] INFO  MemoryStore - Block broadcast_9 stored as values in memory (estimated size 213.9 KiB, free 2.2 GiB)
[2025-10-03 20:38:22] INFO  MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 2.2 GiB)
[2025-10-03 20:38:22] INFO  BlockManagerInfo - Added broadcast_9_piece0 in memory on DESKTOP-618L1DH:65248 (size: 77.2 KiB, free: 2.2 GiB)
[2025-10-03 20:38:22] INFO  SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:38:22] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[36] at save at DataCleaning.java:132) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:38:22] INFO  TaskSchedulerImpl - Adding task set 14.0 with 1 tasks resource profile 0
[2025-10-03 20:38:22] INFO  TaskSetManager - Starting task 0.0 in stage 14.0 (TID 17) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9121 bytes) 
[2025-10-03 20:38:22] INFO  Executor - Running task 0.0 in stage 14.0 (TID 17)
[2025-10-03 20:38:22] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:38:22] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:38:22] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:22] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:38:22] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:38:22] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:38:22] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:38:22] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:38:22] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-03 20:38:22] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "iso_country",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "iata_code",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary iso_country (STRING);
  optional binary name (STRING);
  optional binary iata_code (STRING);
}

       
[2025-10-03 20:38:22] INFO  CodeGenerator - Code generated in 7.4277 ms
[2025-10-03 20:38:22] INFO  JDBCRDD - closed connection
[2025-10-03 20:38:22] INFO  FileOutputCommitter - Saved output of task 'attempt_202510032038224788739433696331344_0014_m_000000_17' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/silver/cleaned_airport_lookup/_temporary/0/task_202510032038224788739433696331344_0014_m_000000
[2025-10-03 20:38:22] INFO  SparkHadoopMapRedUtil - attempt_202510032038224788739433696331344_0014_m_000000_17: Committed. Elapsed time: 3 ms.
[2025-10-03 20:38:22] INFO  Executor - Finished task 0.0 in stage 14.0 (TID 17). 2484 bytes result sent to driver
[2025-10-03 20:38:22] INFO  TaskSetManager - Finished task 0.0 in stage 14.0 (TID 17) in 123 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:38:22] INFO  TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool 
[2025-10-03 20:38:22] INFO  DAGScheduler - ResultStage 14 (save at DataCleaning.java:132) finished in 0.154 s
[2025-10-03 20:38:22] INFO  DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:38:22] INFO  TaskSchedulerImpl - Killing all running tasks in stage 14: Stage finished
[2025-10-03 20:38:22] INFO  DAGScheduler - Job 9 finished: save at DataCleaning.java:132, took 0.162838 s
[2025-10-03 20:38:22] INFO  FileFormatWriter - Start to commit write Job 5340f177-d062-46c8-bb0b-41cea3301f6c.
[2025-10-03 20:38:22] INFO  FileFormatWriter - Write Job 5340f177-d062-46c8-bb0b-41cea3301f6c committed. Elapsed time: 11 ms.
[2025-10-03 20:38:22] INFO  FileFormatWriter - Finished processing stats for write job 5340f177-d062-46c8-bb0b-41cea3301f6c.
[2025-10-03 20:38:22] INFO  DataCleaning - Overwriting DB Table: silver.cleaned_airport_lookup
[2025-10-03 20:38:22] INFO  SparkContext - Starting job: save at DataCleaning.java:143
[2025-10-03 20:38:22] INFO  DAGScheduler - Got job 10 (save at DataCleaning.java:143) with 1 output partitions
[2025-10-03 20:38:22] INFO  DAGScheduler - Final stage: ResultStage 15 (save at DataCleaning.java:143)
[2025-10-03 20:38:22] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:38:22] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:38:22] INFO  DAGScheduler - Submitting ResultStage 15 (MapPartitionsRDD[41] at save at DataCleaning.java:143), which has no missing parents
[2025-10-03 20:38:22] INFO  MemoryStore - Block broadcast_10 stored as values in memory (estimated size 29.2 KiB, free 2.2 GiB)
[2025-10-03 20:38:22] INFO  MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 2.2 GiB)
[2025-10-03 20:38:22] INFO  BlockManagerInfo - Added broadcast_10_piece0 in memory on DESKTOP-618L1DH:65248 (size: 13.4 KiB, free: 2.2 GiB)
[2025-10-03 20:38:22] INFO  SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:38:22] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[41] at save at DataCleaning.java:143) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:38:22] INFO  TaskSchedulerImpl - Adding task set 15.0 with 1 tasks resource profile 0
[2025-10-03 20:38:22] INFO  TaskSetManager - Starting task 0.0 in stage 15.0 (TID 18) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) 
[2025-10-03 20:38:22] INFO  Executor - Running task 0.0 in stage 15.0 (TID 18)
[2025-10-03 20:38:22] INFO  CodeGenerator - Code generated in 6.274 ms
[2025-10-03 20:38:23] INFO  JDBCRDD - closed connection
[2025-10-03 20:38:23] INFO  Executor - Finished task 0.0 in stage 15.0 (TID 18). 1316 bytes result sent to driver
[2025-10-03 20:38:23] INFO  TaskSetManager - Finished task 0.0 in stage 15.0 (TID 18) in 805 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:38:23] INFO  TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
[2025-10-03 20:38:23] INFO  DAGScheduler - ResultStage 15 (save at DataCleaning.java:143) finished in 0.819 s
[2025-10-03 20:38:23] INFO  BlockManagerInfo - Removed broadcast_8_piece0 on DESKTOP-618L1DH:65248 in memory (size: 13.2 KiB, free: 2.2 GiB)
[2025-10-03 20:38:23] INFO  DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:38:23] INFO  TaskSchedulerImpl - Killing all running tasks in stage 15: Stage finished
[2025-10-03 20:38:23] INFO  DAGScheduler - Job 10 finished: save at DataCleaning.java:143, took 0.830484 s
[2025-10-03 20:38:23] INFO  BlockManagerInfo - Removed broadcast_9_piece0 on DESKTOP-618L1DH:65248 in memory (size: 77.2 KiB, free: 2.2 GiB)
[2025-10-03 20:38:23] INFO  BlockManagerInfo - Removed broadcast_6_piece0 on DESKTOP-618L1DH:65248 in memory (size: 5.9 KiB, free: 2.2 GiB)
[2025-10-03 20:38:23] INFO  BlockManagerInfo - Removed broadcast_7_piece0 on DESKTOP-618L1DH:65248 in memory (size: 77.2 KiB, free: 2.2 GiB)
[2025-10-03 20:38:23] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-03 20:38:23] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 20:38:23] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-03 20:38:23] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-03 20:38:23] INFO  MemoryStore - MemoryStore cleared
[2025-10-03 20:38:23] INFO  BlockManager - BlockManager stopped
[2025-10-03 20:38:23] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-03 20:38:23] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-03 20:38:23] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-03 20:38:23] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-03 20:38:23] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-192c8ee3-b6df-4970-8861-6485cd87b4c8
[2025-10-03 20:38:53] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-03 20:38:53] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-03 20:38:53] INFO  SparkContext - Java version 11.0.27
[2025-10-03 20:38:53] INFO  ResourceUtils - ==============================================================
[2025-10-03 20:38:53] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-03 20:38:53] INFO  ResourceUtils - ==============================================================
[2025-10-03 20:38:53] INFO  SparkContext - Submitted application: Airline Delay Data Transformation
[2025-10-03 20:38:53] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-03 20:38:53] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-03 20:38:53] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-03 20:38:53] INFO  SecurityManager - Changing view acls to: USER
[2025-10-03 20:38:53] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-03 20:38:53] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-03 20:38:53] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-03 20:38:53] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-03 20:38:55] INFO  Utils - Successfully started service 'sparkDriver' on port 59015.
[2025-10-03 20:38:55] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-03 20:38:55] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-03 20:38:55] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-03 20:38:55] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-03 20:38:55] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-03 20:38:55] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-7270cd76-558c-4a4e-82bd-fc31fb08c7cc
[2025-10-03 20:38:55] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-03 20:38:55] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-03 20:38:55] INFO  log - Logging initialized @3276ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-03 20:38:55] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-03 20:38:55] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-03 20:38:55] INFO  Server - Started @3443ms
[2025-10-03 20:38:55] INFO  AbstractConnector - Started ServerConnector@45cd7bc5{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 20:38:55] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4c361f63{/,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-03 20:38:55] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-03 20:38:55] INFO  Executor - Java version 11.0.27
[2025-10-03 20:38:55] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-03 20:38:55] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7fb53256 for default.
[2025-10-03 20:38:55] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59062.
[2025-10-03 20:38:55] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:59062
[2025-10-03 20:38:55] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-03 20:38:55] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 59062, None)
[2025-10-03 20:38:55] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:59062 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 59062, None)
[2025-10-03 20:38:55] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 59062, None)
[2025-10-03 20:38:55] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 59062, None)
[2025-10-03 20:38:55] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@4c361f63{/,null,STOPPED,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@136ccbfe{/jobs,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@484149eb{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f2d014a{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@a7cf42f{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@28e0e464{/stages,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@70a898b0{/stages/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7499eac7{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@b9d018b{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79eeff87{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@8bd076a{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1378eea2{/storage,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66522ead{/storage/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@e91b4f4{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58ae402b{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43ac0a68{/environment,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3728a578{/environment/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de0641b{/executors,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a464fa3{/executors/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ccb85d6{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@259b85d6{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@488f3dd1{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7bc58891{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@554188ac{/static,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e4389ed{/,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3513c84c{/api,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@716185fe{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@478b0739{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@36790bec{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  DataTransformation - Loading table: silver.cleaned_dataset
[2025-10-03 20:38:55] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-03 20:38:55] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@519c6fcc{/SQL,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7ecda95b{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@11787b64{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-03 20:38:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@77b3752b{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-03 20:38:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7d0100ea{/static/sql,null,AVAILABLE,@Spark}
[2025-10-03 20:38:58] INFO  DataTransformation - Loading table: silver.cleaned_carrier_lookup
[2025-10-03 20:38:58] INFO  DataTransformation - Loading table: silver.cleaned_airport_lookup
[2025-10-03 20:38:59] INFO  CodeGenerator - Code generated in 162.7295 ms
[2025-10-03 20:38:59] INFO  DAGScheduler - Registering RDD 2 (count at DataTransformation.java:29) as input to shuffle 0
[2025-10-03 20:38:59] INFO  DAGScheduler - Got map stage job 0 (count at DataTransformation.java:29) with 1 output partitions
[2025-10-03 20:38:59] INFO  DAGScheduler - Final stage: ShuffleMapStage 0 (count at DataTransformation.java:29)
[2025-10-03 20:38:59] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:38:59] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:38:59] INFO  DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at DataTransformation.java:29), which has no missing parents
[2025-10-03 20:38:59] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 13.8 KiB, free 2.2 GiB)
[2025-10-03 20:38:59] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 2.2 GiB)
[2025-10-03 20:38:59] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on DESKTOP-618L1DH:59062 (size: 7.2 KiB, free: 2.2 GiB)
[2025-10-03 20:38:59] INFO  SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:38:59] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at DataTransformation.java:29) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:38:59] INFO  TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
[2025-10-03 20:39:00] INFO  TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:00] INFO  Executor - Running task 0.0 in stage 0.0 (TID 0)
[2025-10-03 20:39:00] INFO  CodeGenerator - Code generated in 14.658 ms
[2025-10-03 20:39:00] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:00] INFO  Executor - Finished task 0.0 in stage 0.0 (TID 0). 1931 bytes result sent to driver
[2025-10-03 20:39:00] INFO  TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 370 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:00] INFO  TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:00] INFO  DAGScheduler - ShuffleMapStage 0 (count at DataTransformation.java:29) finished in 0.741 s
[2025-10-03 20:39:00] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:00] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:00] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:00] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:00] INFO  CodeGenerator - Code generated in 9.1748 ms
[2025-10-03 20:39:00] INFO  SparkContext - Starting job: count at DataTransformation.java:29
[2025-10-03 20:39:00] INFO  DAGScheduler - Got job 1 (count at DataTransformation.java:29) with 1 output partitions
[2025-10-03 20:39:00] INFO  DAGScheduler - Final stage: ResultStage 2 (count at DataTransformation.java:29)
[2025-10-03 20:39:00] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
[2025-10-03 20:39:00] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:00] INFO  DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[5] at count at DataTransformation.java:29), which has no missing parents
[2025-10-03 20:39:00] INFO  MemoryStore - Block broadcast_1 stored as values in memory (estimated size 12.5 KiB, free 2.2 GiB)
[2025-10-03 20:39:00] INFO  MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
[2025-10-03 20:39:00] INFO  BlockManagerInfo - Added broadcast_1_piece0 in memory on DESKTOP-618L1DH:59062 (size: 5.9 KiB, free: 2.2 GiB)
[2025-10-03 20:39:00] INFO  SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:00] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at DataTransformation.java:29) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:00] INFO  TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
[2025-10-03 20:39:00] INFO  TaskSetManager - Starting task 0.0 in stage 2.0 (TID 1) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:00] INFO  Executor - Running task 0.0 in stage 2.0 (TID 1)
[2025-10-03 20:39:00] INFO  ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:00] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 11 ms
[2025-10-03 20:39:00] INFO  CodeGenerator - Code generated in 15.7769 ms
[2025-10-03 20:39:00] INFO  Executor - Finished task 0.0 in stage 2.0 (TID 1). 4038 bytes result sent to driver
[2025-10-03 20:39:00] INFO  TaskSetManager - Finished task 0.0 in stage 2.0 (TID 1) in 107 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:00] INFO  TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:00] INFO  DAGScheduler - ResultStage 2 (count at DataTransformation.java:29) finished in 0.119 s
[2025-10-03 20:39:00] INFO  DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:00] INFO  TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
[2025-10-03 20:39:00] INFO  DAGScheduler - Job 1 finished: count at DataTransformation.java:29, took 0.136379 s
[2025-10-03 20:39:00] INFO  DataTransformation - Added on_time_flag and total_delay columns. Row count = 54619
[2025-10-03 20:39:01] INFO  CodeGenerator - Code generated in 22.7899 ms
[2025-10-03 20:39:01] INFO  DAGScheduler - Registering RDD 9 (save at DataTransformation.java:118) as input to shuffle 1
[2025-10-03 20:39:01] INFO  DAGScheduler - Got map stage job 2 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:01] INFO  DAGScheduler - Final stage: ShuffleMapStage 3 (save at DataTransformation.java:118)
[2025-10-03 20:39:01] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:01] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:01] INFO  DAGScheduler - Submitting ShuffleMapStage 3 (MapPartitionsRDD[9] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:01] INFO  MemoryStore - Block broadcast_2 stored as values in memory (estimated size 13.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:01] INFO  MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:01] INFO  BlockManagerInfo - Added broadcast_2_piece0 in memory on DESKTOP-618L1DH:59062 (size: 7.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:01] INFO  SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:01] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[9] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:01] INFO  TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
[2025-10-03 20:39:01] INFO  TaskSetManager - Starting task 0.0 in stage 3.0 (TID 2) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:01] INFO  Executor - Running task 0.0 in stage 3.0 (TID 2)
[2025-10-03 20:39:01] INFO  CodeGenerator - Code generated in 94.5907 ms
[2025-10-03 20:39:01] INFO  DAGScheduler - Registering RDD 11 (save at DataTransformation.java:118) as input to shuffle 2
[2025-10-03 20:39:01] INFO  DAGScheduler - Got map stage job 3 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:01] INFO  DAGScheduler - Final stage: ShuffleMapStage 4 (save at DataTransformation.java:118)
[2025-10-03 20:39:01] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:01] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:01] INFO  DAGScheduler - Submitting ShuffleMapStage 4 (MapPartitionsRDD[11] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:01] INFO  MemoryStore - Block broadcast_3 stored as values in memory (estimated size 35.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:01] INFO  MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 2.2 GiB)
[2025-10-03 20:39:01] INFO  BlockManagerInfo - Added broadcast_3_piece0 in memory on DESKTOP-618L1DH:59062 (size: 16.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:01] INFO  SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:01] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[11] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:01] INFO  TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
[2025-10-03 20:39:01] INFO  TaskSetManager - Starting task 0.0 in stage 4.0 (TID 3) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:01] INFO  Executor - Running task 0.0 in stage 4.0 (TID 3)
[2025-10-03 20:39:01] INFO  CodeGenerator - Code generated in 26.1356 ms
[2025-10-03 20:39:01] INFO  BlockManagerInfo - Removed broadcast_1_piece0 on DESKTOP-618L1DH:59062 in memory (size: 5.9 KiB, free: 2.2 GiB)
[2025-10-03 20:39:01] INFO  BlockManagerInfo - Removed broadcast_0_piece0 on DESKTOP-618L1DH:59062 in memory (size: 7.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:01] INFO  CodeGenerator - Code generated in 24.8165 ms
[2025-10-03 20:39:01] INFO  CodeGenerator - Code generated in 46.82 ms
[2025-10-03 20:39:01] INFO  CodeGenerator - Code generated in 13.8853 ms
[2025-10-03 20:39:01] INFO  CodeGenerator - Code generated in 4.7904 ms
[2025-10-03 20:39:01] INFO  CodeGenerator - Code generated in 11.7399 ms
[2025-10-03 20:39:01] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:01] INFO  Executor - Finished task 0.0 in stage 4.0 (TID 3). 2451 bytes result sent to driver
[2025-10-03 20:39:01] INFO  TaskSetManager - Finished task 0.0 in stage 4.0 (TID 3) in 306 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:01] INFO  TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:01] INFO  DAGScheduler - ShuffleMapStage 4 (save at DataTransformation.java:118) finished in 0.348 s
[2025-10-03 20:39:01] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:01] INFO  DAGScheduler - running: Set(ShuffleMapStage 3)
[2025-10-03 20:39:01] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:01] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:01] INFO  ShufflePartitionsUtil - For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:01] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:01] INFO  CodeGenerator - Code generated in 41.3411 ms
[2025-10-03 20:39:01] INFO  Executor - Finished task 0.0 in stage 3.0 (TID 2). 1992 bytes result sent to driver
[2025-10-03 20:39:01] INFO  TaskSetManager - Finished task 0.0 in stage 3.0 (TID 2) in 644 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:01] INFO  TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:01] INFO  DAGScheduler - ShuffleMapStage 3 (save at DataTransformation.java:118) finished in 0.673 s
[2025-10-03 20:39:01] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:01] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:01] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:01] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:01] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:01] INFO  DAGScheduler - Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:01] INFO  DAGScheduler - Final stage: ResultStage 6 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:01] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 5)
[2025-10-03 20:39:01] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:01] INFO  DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[14] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:01] INFO  MemoryStore - Block broadcast_4 stored as values in memory (estimated size 42.4 KiB, free 2.2 GiB)
[2025-10-03 20:39:01] INFO  MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 2.2 GiB)
[2025-10-03 20:39:01] INFO  BlockManagerInfo - Added broadcast_4_piece0 in memory on DESKTOP-618L1DH:59062 (size: 19.5 KiB, free: 2.2 GiB)
[2025-10-03 20:39:01] INFO  SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:01] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[14] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:01] INFO  TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
[2025-10-03 20:39:01] INFO  TaskSetManager - Starting task 0.0 in stage 6.0 (TID 4) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:01] INFO  Executor - Running task 0.0 in stage 6.0 (TID 4)
[2025-10-03 20:39:01] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.8 KiB) non-empty blocks including 1 (2.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:01] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:02] INFO  CodeGenerator - Code generated in 36.842 ms
[2025-10-03 20:39:02] INFO  Executor - Finished task 0.0 in stage 6.0 (TID 4). 5622 bytes result sent to driver
[2025-10-03 20:39:02] INFO  TaskSetManager - Finished task 0.0 in stage 6.0 (TID 4) in 73 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:02] INFO  TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:02] INFO  DAGScheduler - ResultStage 6 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.086 s
[2025-10-03 20:39:02] INFO  DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:02] INFO  TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
[2025-10-03 20:39:02] INFO  DAGScheduler - Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.094690 s
[2025-10-03 20:39:02] INFO  CodeGenerator - Code generated in 7.3103 ms
[2025-10-03 20:39:02] INFO  MemoryStore - Block broadcast_5 stored as values in memory (estimated size 8.0 MiB, free 2.2 GiB)
[2025-10-03 20:39:02] INFO  MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 1221.0 B, free 2.2 GiB)
[2025-10-03 20:39:02] INFO  BlockManagerInfo - Added broadcast_5_piece0 in memory on DESKTOP-618L1DH:59062 (size: 1221.0 B, free: 2.2 GiB)
[2025-10-03 20:39:02] INFO  SparkContext - Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:02] INFO  ShufflePartitionsUtil - For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:02] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:02] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:39:02] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:39:02] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:02] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:39:02] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:39:02] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:02] INFO  CodeGenerator - Code generated in 33.7179 ms
[2025-10-03 20:39:02] INFO  SparkContext - Starting job: save at DataTransformation.java:118
[2025-10-03 20:39:02] INFO  DAGScheduler - Got job 5 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:02] INFO  DAGScheduler - Final stage: ResultStage 8 (save at DataTransformation.java:118)
[2025-10-03 20:39:02] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 7)
[2025-10-03 20:39:02] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:02] INFO  DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[18] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:02] INFO  MemoryStore - Block broadcast_6 stored as values in memory (estimated size 265.9 KiB, free 2.2 GiB)
[2025-10-03 20:39:02] INFO  MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 96.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:02] INFO  BlockManagerInfo - Added broadcast_6_piece0 in memory on DESKTOP-618L1DH:59062 (size: 96.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:02] INFO  SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:02] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[18] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:02] INFO  TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
[2025-10-03 20:39:02] INFO  TaskSetManager - Starting task 0.0 in stage 8.0 (TID 5) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9275 bytes) 
[2025-10-03 20:39:02] INFO  Executor - Running task 0.0 in stage 8.0 (TID 5)
[2025-10-03 20:39:02] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:39:02] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:39:02] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:02] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:39:02] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:39:02] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:02] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:39:02] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:39:02] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-03 20:39:02] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "carrier",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "isSigned" : false,
      "scale" : 0
    }
  }, {
    "name" : "carrier_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary carrier (STRING);
  optional binary carrier_name (STRING);
}

       
[2025-10-03 20:39:02] INFO  CodecPool - Got brand-new compressor [.snappy]
[2025-10-03 20:39:02] INFO  ShuffleBlockFetcherIterator - Getting 1 (23.0 KiB) non-empty blocks including 1 (23.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:02] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:02] INFO  CodeGenerator - Code generated in 63.2459 ms
[2025-10-03 20:39:02] INFO  BlockManagerInfo - Removed broadcast_4_piece0 on DESKTOP-618L1DH:59062 in memory (size: 19.5 KiB, free: 2.2 GiB)
[2025-10-03 20:39:02] INFO  BlockManagerInfo - Removed broadcast_3_piece0 on DESKTOP-618L1DH:59062 in memory (size: 16.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:03] INFO  FileOutputCommitter - Saved output of task 'attempt_202510032039021023098831858432038_0008_m_000000_5' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/gold/dim_carrier/_temporary/0/task_202510032039021023098831858432038_0008_m_000000
[2025-10-03 20:39:03] INFO  SparkHadoopMapRedUtil - attempt_202510032039021023098831858432038_0008_m_000000_5: Committed. Elapsed time: 2 ms.
[2025-10-03 20:39:03] INFO  Executor - Finished task 0.0 in stage 8.0 (TID 5). 8414 bytes result sent to driver
[2025-10-03 20:39:03] INFO  TaskSetManager - Finished task 0.0 in stage 8.0 (TID 5) in 808 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:03] INFO  TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:03] INFO  DAGScheduler - ResultStage 8 (save at DataTransformation.java:118) finished in 0.917 s
[2025-10-03 20:39:03] INFO  DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:03] INFO  TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
[2025-10-03 20:39:03] INFO  DAGScheduler - Job 5 finished: save at DataTransformation.java:118, took 0.924140 s
[2025-10-03 20:39:03] INFO  FileFormatWriter - Start to commit write Job e96fda06-818e-4162-8a55-c074bd1e6c13.
[2025-10-03 20:39:03] INFO  FileFormatWriter - Write Job e96fda06-818e-4162-8a55-c074bd1e6c13 committed. Elapsed time: 11 ms.
[2025-10-03 20:39:03] INFO  FileFormatWriter - Finished processing stats for write job e96fda06-818e-4162-8a55-c074bd1e6c13.
[2025-10-03 20:39:03] WARN  SparkStringUtils - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2025-10-03 20:39:03] INFO  DAGScheduler - Registering RDD 22 (save at DataTransformation.java:131) as input to shuffle 3
[2025-10-03 20:39:03] INFO  DAGScheduler - Got map stage job 6 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:03] INFO  DAGScheduler - Final stage: ShuffleMapStage 9 (save at DataTransformation.java:131)
[2025-10-03 20:39:03] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:03] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:03] INFO  DAGScheduler - Submitting ShuffleMapStage 9 (MapPartitionsRDD[22] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:03] INFO  MemoryStore - Block broadcast_7 stored as values in memory (estimated size 13.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:03] INFO  MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:03] INFO  BlockManagerInfo - Added broadcast_7_piece0 in memory on DESKTOP-618L1DH:59062 (size: 7.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:03] INFO  SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:03] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[22] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:03] INFO  TaskSchedulerImpl - Adding task set 9.0 with 1 tasks resource profile 0
[2025-10-03 20:39:03] INFO  DAGScheduler - Registering RDD 24 (save at DataTransformation.java:131) as input to shuffle 4
[2025-10-03 20:39:03] INFO  TaskSetManager - Starting task 0.0 in stage 9.0 (TID 6) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:03] INFO  DAGScheduler - Got map stage job 7 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:03] INFO  DAGScheduler - Final stage: ShuffleMapStage 10 (save at DataTransformation.java:131)
[2025-10-03 20:39:03] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:03] INFO  Executor - Running task 0.0 in stage 9.0 (TID 6)
[2025-10-03 20:39:03] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:03] INFO  DAGScheduler - Submitting ShuffleMapStage 10 (MapPartitionsRDD[24] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:03] INFO  MemoryStore - Block broadcast_8 stored as values in memory (estimated size 35.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:03] INFO  MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 2.2 GiB)
[2025-10-03 20:39:03] INFO  BlockManagerInfo - Added broadcast_8_piece0 in memory on DESKTOP-618L1DH:59062 (size: 16.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:03] INFO  SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:03] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[24] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:03] INFO  TaskSchedulerImpl - Adding task set 10.0 with 1 tasks resource profile 0
[2025-10-03 20:39:03] INFO  TaskSetManager - Starting task 0.0 in stage 10.0 (TID 7) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:03] INFO  Executor - Running task 0.0 in stage 10.0 (TID 7)
[2025-10-03 20:39:03] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:03] INFO  Executor - Finished task 0.0 in stage 10.0 (TID 7). 2408 bytes result sent to driver
[2025-10-03 20:39:03] INFO  TaskSetManager - Finished task 0.0 in stage 10.0 (TID 7) in 178 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:03] INFO  TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:03] INFO  DAGScheduler - ShuffleMapStage 10 (save at DataTransformation.java:131) finished in 0.194 s
[2025-10-03 20:39:03] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:03] INFO  DAGScheduler - running: Set(ShuffleMapStage 9)
[2025-10-03 20:39:03] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:03] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:03] INFO  ShufflePartitionsUtil - For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:03] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:03] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:03] INFO  DAGScheduler - Got job 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:03] INFO  DAGScheduler - Final stage: ResultStage 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:03] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 11)
[2025-10-03 20:39:03] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:03] INFO  DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:03] INFO  MemoryStore - Block broadcast_9 stored as values in memory (estimated size 42.4 KiB, free 2.2 GiB)
[2025-10-03 20:39:03] INFO  MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 2.2 GiB)
[2025-10-03 20:39:03] INFO  BlockManagerInfo - Added broadcast_9_piece0 in memory on DESKTOP-618L1DH:59062 (size: 19.5 KiB, free: 2.2 GiB)
[2025-10-03 20:39:03] INFO  SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:03] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:03] INFO  TaskSchedulerImpl - Adding task set 12.0 with 1 tasks resource profile 0
[2025-10-03 20:39:03] INFO  TaskSetManager - Starting task 0.0 in stage 12.0 (TID 8) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:03] INFO  Executor - Running task 0.0 in stage 12.0 (TID 8)
[2025-10-03 20:39:03] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.8 KiB) non-empty blocks including 1 (2.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:03] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 3 ms
[2025-10-03 20:39:03] INFO  Executor - Finished task 0.0 in stage 12.0 (TID 8). 5708 bytes result sent to driver
[2025-10-03 20:39:03] INFO  TaskSetManager - Finished task 0.0 in stage 12.0 (TID 8) in 40 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:03] INFO  TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:03] INFO  DAGScheduler - ResultStage 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.056 s
[2025-10-03 20:39:03] INFO  DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:03] INFO  TaskSchedulerImpl - Killing all running tasks in stage 12: Stage finished
[2025-10-03 20:39:03] INFO  DAGScheduler - Job 8 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.068865 s
[2025-10-03 20:39:03] INFO  Executor - Finished task 0.0 in stage 9.0 (TID 6). 1906 bytes result sent to driver
[2025-10-03 20:39:03] INFO  TaskSetManager - Finished task 0.0 in stage 9.0 (TID 6) in 328 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:03] INFO  TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:03] INFO  DAGScheduler - ShuffleMapStage 9 (save at DataTransformation.java:131) finished in 0.339 s
[2025-10-03 20:39:03] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:03] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:03] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:03] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:03] INFO  MemoryStore - Block broadcast_10 stored as values in memory (estimated size 8.0 MiB, free 2.2 GiB)
[2025-10-03 20:39:03] INFO  MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 1221.0 B, free 2.2 GiB)
[2025-10-03 20:39:03] INFO  BlockManagerInfo - Added broadcast_10_piece0 in memory on DESKTOP-618L1DH:59062 (size: 1221.0 B, free: 2.2 GiB)
[2025-10-03 20:39:03] INFO  SparkContext - Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:03] INFO  ShufflePartitionsUtil - For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:03] INFO  SparkContext - Starting job: save at DataTransformation.java:131
[2025-10-03 20:39:03] INFO  DAGScheduler - Got job 9 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:03] INFO  DAGScheduler - Final stage: ResultStage 14 (save at DataTransformation.java:131)
[2025-10-03 20:39:03] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 13)
[2025-10-03 20:39:03] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:03] INFO  DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[32] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:03] INFO  MemoryStore - Block broadcast_11 stored as values in memory (estimated size 70.9 KiB, free 2.2 GiB)
[2025-10-03 20:39:03] INFO  MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 28.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:03] INFO  BlockManagerInfo - Added broadcast_11_piece0 in memory on DESKTOP-618L1DH:59062 (size: 28.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:03] INFO  SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:03] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[32] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:03] INFO  TaskSchedulerImpl - Adding task set 14.0 with 1 tasks resource profile 0
[2025-10-03 20:39:03] INFO  TaskSetManager - Starting task 0.0 in stage 14.0 (TID 9) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:03] INFO  Executor - Running task 0.0 in stage 14.0 (TID 9)
[2025-10-03 20:39:04] INFO  ShuffleBlockFetcherIterator - Getting 1 (23.0 KiB) non-empty blocks including 1 (23.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:04] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:05] INFO  CodeGenerator - Code generated in 4.7973 ms
[2025-10-03 20:39:05] INFO  BlockManagerInfo - Removed broadcast_7_piece0 on DESKTOP-618L1DH:59062 in memory (size: 7.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:05] INFO  BlockManagerInfo - Removed broadcast_6_piece0 on DESKTOP-618L1DH:59062 in memory (size: 96.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:05] INFO  BlockManagerInfo - Removed broadcast_9_piece0 on DESKTOP-618L1DH:59062 in memory (size: 19.5 KiB, free: 2.2 GiB)
[2025-10-03 20:39:05] INFO  BlockManagerInfo - Removed broadcast_8_piece0 on DESKTOP-618L1DH:59062 in memory (size: 16.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:05] INFO  Executor - Finished task 0.0 in stage 14.0 (TID 9). 7203 bytes result sent to driver
[2025-10-03 20:39:05] INFO  TaskSetManager - Finished task 0.0 in stage 14.0 (TID 9) in 1193 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:05] INFO  TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:05] INFO  DAGScheduler - ResultStage 14 (save at DataTransformation.java:131) finished in 1.229 s
[2025-10-03 20:39:05] INFO  DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:05] INFO  TaskSchedulerImpl - Killing all running tasks in stage 14: Stage finished
[2025-10-03 20:39:05] INFO  DAGScheduler - Job 9 finished: save at DataTransformation.java:131, took 1.242515 s
[2025-10-03 20:39:05] INFO  DataTransformation - Table dim_carrier written to DB
[2025-10-03 20:39:05] INFO  CodeGenerator - Code generated in 10.2443 ms
[2025-10-03 20:39:05] INFO  DAGScheduler - Registering RDD 37 (save at DataTransformation.java:118) as input to shuffle 5
[2025-10-03 20:39:05] INFO  DAGScheduler - Got map stage job 10 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:05] INFO  DAGScheduler - Final stage: ShuffleMapStage 15 (save at DataTransformation.java:118)
[2025-10-03 20:39:05] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:05] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:05] INFO  DAGScheduler - Submitting ShuffleMapStage 15 (MapPartitionsRDD[37] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:05] INFO  MemoryStore - Block broadcast_12 stored as values in memory (estimated size 14.1 KiB, free 2.2 GiB)
[2025-10-03 20:39:05] INFO  MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 2.2 GiB)
[2025-10-03 20:39:05] INFO  BlockManagerInfo - Added broadcast_12_piece0 in memory on DESKTOP-618L1DH:59062 (size: 7.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:05] INFO  SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:05] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[37] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:05] INFO  TaskSchedulerImpl - Adding task set 15.0 with 1 tasks resource profile 0
[2025-10-03 20:39:05] INFO  TaskSetManager - Starting task 0.0 in stage 15.0 (TID 10) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:05] INFO  DAGScheduler - Registering RDD 39 (save at DataTransformation.java:118) as input to shuffle 6
[2025-10-03 20:39:05] INFO  Executor - Running task 0.0 in stage 15.0 (TID 10)
[2025-10-03 20:39:05] INFO  DAGScheduler - Got map stage job 11 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:05] INFO  DAGScheduler - Final stage: ShuffleMapStage 16 (save at DataTransformation.java:118)
[2025-10-03 20:39:05] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:05] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:05] INFO  DAGScheduler - Submitting ShuffleMapStage 16 (MapPartitionsRDD[39] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:05] INFO  MemoryStore - Block broadcast_13 stored as values in memory (estimated size 35.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:05] INFO  MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 2.2 GiB)
[2025-10-03 20:39:05] INFO  BlockManagerInfo - Added broadcast_13_piece0 in memory on DESKTOP-618L1DH:59062 (size: 16.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:05] INFO  SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:05] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[39] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:05] INFO  TaskSchedulerImpl - Adding task set 16.0 with 1 tasks resource profile 0
[2025-10-03 20:39:05] INFO  TaskSetManager - Starting task 0.0 in stage 16.0 (TID 11) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:05] INFO  Executor - Running task 0.0 in stage 16.0 (TID 11)
[2025-10-03 20:39:05] INFO  CodeGenerator - Code generated in 21.1813 ms
[2025-10-03 20:39:05] INFO  DAGScheduler - Registering RDD 41 (save at DataTransformation.java:118) as input to shuffle 7
[2025-10-03 20:39:05] INFO  DAGScheduler - Got map stage job 12 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:05] INFO  DAGScheduler - Final stage: ShuffleMapStage 17 (save at DataTransformation.java:118)
[2025-10-03 20:39:05] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:05] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:05] INFO  DAGScheduler - Submitting ShuffleMapStage 17 (MapPartitionsRDD[41] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:05] INFO  MemoryStore - Block broadcast_14 stored as values in memory (estimated size 37.3 KiB, free 2.2 GiB)
[2025-10-03 20:39:05] INFO  MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 2.2 GiB)
[2025-10-03 20:39:05] INFO  BlockManagerInfo - Added broadcast_14_piece0 in memory on DESKTOP-618L1DH:59062 (size: 17.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:05] INFO  SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:05] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[41] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:05] INFO  TaskSchedulerImpl - Adding task set 17.0 with 1 tasks resource profile 0
[2025-10-03 20:39:05] INFO  TaskSetManager - Starting task 0.0 in stage 17.0 (TID 12) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:05] INFO  Executor - Running task 0.0 in stage 17.0 (TID 12)
[2025-10-03 20:39:05] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:05] INFO  CodeGenerator - Code generated in 35.5562 ms
[2025-10-03 20:39:05] INFO  CodeGenerator - Code generated in 7.0224 ms
[2025-10-03 20:39:05] INFO  CodeGenerator - Code generated in 10.2477 ms
[2025-10-03 20:39:05] INFO  CodeGenerator - Code generated in 8.2814 ms
[2025-10-03 20:39:05] INFO  Executor - Finished task 0.0 in stage 16.0 (TID 11). 2408 bytes result sent to driver
[2025-10-03 20:39:05] INFO  TaskSetManager - Finished task 0.0 in stage 16.0 (TID 11) in 151 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:05] INFO  TaskSchedulerImpl - Removed TaskSet 16.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:05] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:05] INFO  DAGScheduler - ShuffleMapStage 16 (save at DataTransformation.java:118) finished in 0.163 s
[2025-10-03 20:39:05] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:05] INFO  DAGScheduler - running: Set(ShuffleMapStage 15, ShuffleMapStage 17)
[2025-10-03 20:39:05] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:05] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:05] INFO  ShufflePartitionsUtil - For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:05] INFO  CodeGenerator - Code generated in 46.46 ms
[2025-10-03 20:39:05] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:05] INFO  DAGScheduler - Got job 13 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:05] INFO  DAGScheduler - Final stage: ResultStage 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:05] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 18)
[2025-10-03 20:39:05] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:05] INFO  DAGScheduler - Submitting ResultStage 19 (MapPartitionsRDD[44] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:05] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:05] INFO  MemoryStore - Block broadcast_15 stored as values in memory (estimated size 42.1 KiB, free 2.1 GiB)
[2025-10-03 20:39:05] INFO  MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 2.1 GiB)
[2025-10-03 20:39:05] INFO  BlockManagerInfo - Added broadcast_15_piece0 in memory on DESKTOP-618L1DH:59062 (size: 19.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:05] INFO  SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:05] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[44] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:05] INFO  TaskSchedulerImpl - Adding task set 19.0 with 1 tasks resource profile 0
[2025-10-03 20:39:05] INFO  TaskSetManager - Starting task 0.0 in stage 19.0 (TID 13) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:05] INFO  Executor - Running task 0.0 in stage 19.0 (TID 13)
[2025-10-03 20:39:05] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.8 KiB) non-empty blocks including 1 (2.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:05] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:05] INFO  CodeGenerator - Code generated in 33.3362 ms
[2025-10-03 20:39:05] INFO  Executor - Finished task 0.0 in stage 15.0 (TID 10). 1906 bytes result sent to driver
[2025-10-03 20:39:05] INFO  TaskSetManager - Finished task 0.0 in stage 15.0 (TID 10) in 370 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:05] INFO  TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:05] INFO  DAGScheduler - ShuffleMapStage 15 (save at DataTransformation.java:118) finished in 0.384 s
[2025-10-03 20:39:05] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:05] INFO  DAGScheduler - running: Set(ResultStage 19, ShuffleMapStage 17)
[2025-10-03 20:39:05] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:05] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:05] INFO  Executor - Finished task 0.0 in stage 19.0 (TID 13). 5109 bytes result sent to driver
[2025-10-03 20:39:05] INFO  TaskSetManager - Finished task 0.0 in stage 19.0 (TID 13) in 62 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:05] INFO  TaskSchedulerImpl - Removed TaskSet 19.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:05] INFO  DAGScheduler - ResultStage 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.072 s
[2025-10-03 20:39:05] INFO  DAGScheduler - Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:05] INFO  TaskSchedulerImpl - Killing all running tasks in stage 19: Stage finished
[2025-10-03 20:39:05] INFO  DAGScheduler - Job 13 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.079685 s
[2025-10-03 20:39:05] INFO  MemoryStore - Block broadcast_16 stored as values in memory (estimated size 8.0 MiB, free 2.1 GiB)
[2025-10-03 20:39:05] INFO  MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 643.0 B, free 2.1 GiB)
[2025-10-03 20:39:05] INFO  BlockManagerInfo - Added broadcast_16_piece0 in memory on DESKTOP-618L1DH:59062 (size: 643.0 B, free: 2.2 GiB)
[2025-10-03 20:39:05] INFO  SparkContext - Created broadcast 16 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:05] INFO  ShufflePartitionsUtil - For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:05] INFO  CodeGenerator - Code generated in 11.1937 ms
[2025-10-03 20:39:05] INFO  DAGScheduler - Registering RDD 47 (save at DataTransformation.java:118) as input to shuffle 8
[2025-10-03 20:39:05] INFO  DAGScheduler - Got map stage job 14 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:05] INFO  DAGScheduler - Final stage: ShuffleMapStage 21 (save at DataTransformation.java:118)
[2025-10-03 20:39:05] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 20)
[2025-10-03 20:39:05] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:05] INFO  DAGScheduler - Submitting ShuffleMapStage 21 (MapPartitionsRDD[47] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:05] INFO  MemoryStore - Block broadcast_17 stored as values in memory (estimated size 15.3 KiB, free 2.1 GiB)
[2025-10-03 20:39:05] INFO  MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 2.1 GiB)
[2025-10-03 20:39:05] INFO  BlockManagerInfo - Added broadcast_17_piece0 in memory on DESKTOP-618L1DH:59062 (size: 7.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:05] INFO  SparkContext - Created broadcast 17 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:05] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[47] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:05] INFO  TaskSchedulerImpl - Adding task set 21.0 with 1 tasks resource profile 0
[2025-10-03 20:39:05] INFO  TaskSetManager - Starting task 0.0 in stage 21.0 (TID 14) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9007 bytes) 
[2025-10-03 20:39:05] INFO  Executor - Running task 0.0 in stage 21.0 (TID 14)
[2025-10-03 20:39:05] INFO  ShuffleBlockFetcherIterator - Getting 1 (1074.2 KiB) non-empty blocks including 1 (1074.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:05] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:05] INFO  CodeGenerator - Code generated in 13.4838 ms
[2025-10-03 20:39:06] INFO  Executor - Finished task 0.0 in stage 17.0 (TID 12). 2408 bytes result sent to driver
[2025-10-03 20:39:06] INFO  TaskSetManager - Finished task 0.0 in stage 17.0 (TID 12) in 707 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:06] INFO  TaskSchedulerImpl - Removed TaskSet 17.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:06] INFO  DAGScheduler - ShuffleMapStage 17 (save at DataTransformation.java:118) finished in 0.719 s
[2025-10-03 20:39:06] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:06] INFO  DAGScheduler - running: Set(ShuffleMapStage 21)
[2025-10-03 20:39:06] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:06] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:06] INFO  ShufflePartitionsUtil - For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:06] INFO  CodeGenerator - Code generated in 36.8224 ms
[2025-10-03 20:39:06] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:06] INFO  DAGScheduler - Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:06] INFO  DAGScheduler - Final stage: ResultStage 23 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:06] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 22)
[2025-10-03 20:39:06] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:06] INFO  DAGScheduler - Submitting ResultStage 23 (MapPartitionsRDD[50] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:06] INFO  MemoryStore - Block broadcast_18 stored as values in memory (estimated size 44.0 KiB, free 2.1 GiB)
[2025-10-03 20:39:06] INFO  MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 2.1 GiB)
[2025-10-03 20:39:06] INFO  BlockManagerInfo - Added broadcast_18_piece0 in memory on DESKTOP-618L1DH:59062 (size: 19.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:06] INFO  SparkContext - Created broadcast 18 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:06] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[50] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:06] INFO  TaskSchedulerImpl - Adding task set 23.0 with 1 tasks resource profile 0
[2025-10-03 20:39:06] INFO  TaskSetManager - Starting task 0.0 in stage 23.0 (TID 15) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:06] INFO  Executor - Running task 0.0 in stage 23.0 (TID 15)
[2025-10-03 20:39:06] INFO  ShuffleBlockFetcherIterator - Getting 1 (99.6 KiB) non-empty blocks including 1 (99.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:06] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:06] INFO  CodeGenerator - Code generated in 23.3955 ms
[2025-10-03 20:39:06] INFO  Executor - Finished task 0.0 in stage 23.0 (TID 15). 59049 bytes result sent to driver
[2025-10-03 20:39:06] INFO  TaskSetManager - Finished task 0.0 in stage 23.0 (TID 15) in 62 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:06] INFO  TaskSchedulerImpl - Removed TaskSet 23.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:06] INFO  DAGScheduler - ResultStage 23 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.071 s
[2025-10-03 20:39:06] INFO  DAGScheduler - Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:06] INFO  TaskSchedulerImpl - Killing all running tasks in stage 23: Stage finished
[2025-10-03 20:39:06] INFO  DAGScheduler - Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.083663 s
[2025-10-03 20:39:06] INFO  CodeGenerator - Code generated in 10.8451 ms
[2025-10-03 20:39:06] INFO  MemoryStore - Block broadcast_19 stored as values in memory (estimated size 8.1 MiB, free 2.1 GiB)
[2025-10-03 20:39:06] INFO  MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 70.4 KiB, free 2.1 GiB)
[2025-10-03 20:39:06] INFO  BlockManagerInfo - Added broadcast_19_piece0 in memory on DESKTOP-618L1DH:59062 (size: 70.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:06] INFO  SparkContext - Created broadcast 19 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:06] INFO  Executor - Finished task 0.0 in stage 21.0 (TID 14). 4259 bytes result sent to driver
[2025-10-03 20:39:06] INFO  TaskSetManager - Finished task 0.0 in stage 21.0 (TID 14) in 561 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:06] INFO  TaskSchedulerImpl - Removed TaskSet 21.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:06] INFO  DAGScheduler - ShuffleMapStage 21 (save at DataTransformation.java:118) finished in 0.578 s
[2025-10-03 20:39:06] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:06] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:06] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:06] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:06] INFO  ShufflePartitionsUtil - For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:06] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:06] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:39:06] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:39:06] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:06] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:39:06] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:39:06] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:06] INFO  CodeGenerator - Code generated in 31.6867 ms
[2025-10-03 20:39:06] INFO  SparkContext - Starting job: save at DataTransformation.java:118
[2025-10-03 20:39:06] INFO  DAGScheduler - Got job 16 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:06] INFO  DAGScheduler - Final stage: ResultStage 26 (save at DataTransformation.java:118)
[2025-10-03 20:39:06] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 25)
[2025-10-03 20:39:06] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:06] INFO  DAGScheduler - Submitting ResultStage 26 (MapPartitionsRDD[54] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:06] INFO  BlockManagerInfo - Removed broadcast_12_piece0 on DESKTOP-618L1DH:59062 in memory (size: 7.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:06] INFO  MemoryStore - Block broadcast_20 stored as values in memory (estimated size 278.2 KiB, free 2.1 GiB)
[2025-10-03 20:39:06] INFO  MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 101.1 KiB, free 2.1 GiB)
[2025-10-03 20:39:06] INFO  BlockManagerInfo - Added broadcast_20_piece0 in memory on DESKTOP-618L1DH:59062 (size: 101.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:06] INFO  BlockManagerInfo - Removed broadcast_15_piece0 on DESKTOP-618L1DH:59062 in memory (size: 19.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:06] INFO  SparkContext - Created broadcast 20 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:06] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[54] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:06] INFO  TaskSchedulerImpl - Adding task set 26.0 with 1 tasks resource profile 0
[2025-10-03 20:39:06] INFO  TaskSetManager - Starting task 0.0 in stage 26.0 (TID 16) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9275 bytes) 
[2025-10-03 20:39:06] INFO  Executor - Running task 0.0 in stage 26.0 (TID 16)
[2025-10-03 20:39:06] INFO  BlockManagerInfo - Removed broadcast_18_piece0 on DESKTOP-618L1DH:59062 in memory (size: 19.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:06] INFO  BlockManagerInfo - Removed broadcast_11_piece0 on DESKTOP-618L1DH:59062 in memory (size: 28.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:06] INFO  BlockManagerInfo - Removed broadcast_14_piece0 on DESKTOP-618L1DH:59062 in memory (size: 17.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:06] INFO  BlockManagerInfo - Removed broadcast_10_piece0 on DESKTOP-618L1DH:59062 in memory (size: 1221.0 B, free: 2.2 GiB)
[2025-10-03 20:39:06] INFO  BlockManagerInfo - Removed broadcast_13_piece0 on DESKTOP-618L1DH:59062 in memory (size: 16.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:06] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:39:06] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:39:06] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:06] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:39:06] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:39:06] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:06] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:39:06] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:39:06] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-03 20:39:06] INFO  BlockManagerInfo - Removed broadcast_17_piece0 on DESKTOP-618L1DH:59062 in memory (size: 7.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:06] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "airport",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "isSigned" : false,
      "scale" : 0
    }
  }, {
    "name" : "airport_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary airport (STRING);
  optional binary airport_name (STRING);
}

       
[2025-10-03 20:39:06] INFO  ShuffleBlockFetcherIterator - Getting 1 (117.1 KiB) non-empty blocks including 1 (117.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:06] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-03 20:39:06] INFO  CodeGenerator - Code generated in 39.3468 ms
[2025-10-03 20:39:06] INFO  FileOutputCommitter - Saved output of task 'attempt_202510032039061236884919128978250_0026_m_000000_16' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/gold/dim_airport/_temporary/0/task_202510032039061236884919128978250_0026_m_000000
[2025-10-03 20:39:06] INFO  SparkHadoopMapRedUtil - attempt_202510032039061236884919128978250_0026_m_000000_16: Committed. Elapsed time: 4 ms.
[2025-10-03 20:39:06] INFO  Executor - Finished task 0.0 in stage 26.0 (TID 16). 12067 bytes result sent to driver
[2025-10-03 20:39:06] INFO  TaskSetManager - Finished task 0.0 in stage 26.0 (TID 16) in 220 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:06] INFO  TaskSchedulerImpl - Removed TaskSet 26.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:06] INFO  DAGScheduler - ResultStage 26 (save at DataTransformation.java:118) finished in 0.263 s
[2025-10-03 20:39:06] INFO  DAGScheduler - Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:06] INFO  TaskSchedulerImpl - Killing all running tasks in stage 26: Stage finished
[2025-10-03 20:39:06] INFO  DAGScheduler - Job 16 finished: save at DataTransformation.java:118, took 0.265795 s
[2025-10-03 20:39:06] INFO  FileFormatWriter - Start to commit write Job 046372b7-b5e8-4892-9d04-a5ebb20ad08b.
[2025-10-03 20:39:06] INFO  FileFormatWriter - Write Job 046372b7-b5e8-4892-9d04-a5ebb20ad08b committed. Elapsed time: 43 ms.
[2025-10-03 20:39:06] INFO  FileFormatWriter - Finished processing stats for write job 046372b7-b5e8-4892-9d04-a5ebb20ad08b.
[2025-10-03 20:39:06] INFO  DAGScheduler - Registering RDD 59 (save at DataTransformation.java:131) as input to shuffle 9
[2025-10-03 20:39:06] INFO  DAGScheduler - Got map stage job 17 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:06] INFO  DAGScheduler - Final stage: ShuffleMapStage 27 (save at DataTransformation.java:131)
[2025-10-03 20:39:06] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:06] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:06] INFO  DAGScheduler - Submitting ShuffleMapStage 27 (MapPartitionsRDD[59] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:06] INFO  MemoryStore - Block broadcast_21 stored as values in memory (estimated size 14.1 KiB, free 2.1 GiB)
[2025-10-03 20:39:06] INFO  MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 2.1 GiB)
[2025-10-03 20:39:06] INFO  BlockManagerInfo - Added broadcast_21_piece0 in memory on DESKTOP-618L1DH:59062 (size: 7.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:06] INFO  SparkContext - Created broadcast 21 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:06] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[59] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:06] INFO  TaskSchedulerImpl - Adding task set 27.0 with 1 tasks resource profile 0
[2025-10-03 20:39:06] INFO  TaskSetManager - Starting task 0.0 in stage 27.0 (TID 17) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:06] INFO  Executor - Running task 0.0 in stage 27.0 (TID 17)
[2025-10-03 20:39:06] INFO  DAGScheduler - Registering RDD 61 (save at DataTransformation.java:131) as input to shuffle 10
[2025-10-03 20:39:06] INFO  DAGScheduler - Got map stage job 18 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:06] INFO  DAGScheduler - Final stage: ShuffleMapStage 28 (save at DataTransformation.java:131)
[2025-10-03 20:39:06] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:06] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:06] INFO  DAGScheduler - Submitting ShuffleMapStage 28 (MapPartitionsRDD[61] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_22 stored as values in memory (estimated size 35.8 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_22_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Added broadcast_22_piece0 in memory on DESKTOP-618L1DH:59062 (size: 16.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  SparkContext - Created broadcast 22 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:07] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[61] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Adding task set 28.0 with 1 tasks resource profile 0
[2025-10-03 20:39:07] INFO  TaskSetManager - Starting task 0.0 in stage 28.0 (TID 18) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:07] INFO  DAGScheduler - Registering RDD 63 (save at DataTransformation.java:131) as input to shuffle 11
[2025-10-03 20:39:07] INFO  Executor - Running task 0.0 in stage 28.0 (TID 18)
[2025-10-03 20:39:07] INFO  DAGScheduler - Got map stage job 19 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:07] INFO  DAGScheduler - Final stage: ShuffleMapStage 29 (save at DataTransformation.java:131)
[2025-10-03 20:39:07] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:07] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:07] INFO  DAGScheduler - Submitting ShuffleMapStage 29 (MapPartitionsRDD[63] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_23 stored as values in memory (estimated size 37.3 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_23_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Added broadcast_23_piece0 in memory on DESKTOP-618L1DH:59062 (size: 17.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  SparkContext - Created broadcast 23 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:07] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[63] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Adding task set 29.0 with 1 tasks resource profile 0
[2025-10-03 20:39:07] INFO  TaskSetManager - Starting task 0.0 in stage 29.0 (TID 19) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:07] INFO  Executor - Running task 0.0 in stage 29.0 (TID 19)
[2025-10-03 20:39:07] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:07] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:07] INFO  Executor - Finished task 0.0 in stage 28.0 (TID 18). 2451 bytes result sent to driver
[2025-10-03 20:39:07] INFO  TaskSetManager - Finished task 0.0 in stage 28.0 (TID 18) in 177 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Removed TaskSet 28.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:07] INFO  DAGScheduler - ShuffleMapStage 28 (save at DataTransformation.java:131) finished in 0.195 s
[2025-10-03 20:39:07] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:07] INFO  DAGScheduler - running: Set(ShuffleMapStage 27, ShuffleMapStage 29)
[2025-10-03 20:39:07] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:07] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:07] INFO  ShufflePartitionsUtil - For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:07] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:07] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:07] INFO  DAGScheduler - Got job 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:07] INFO  DAGScheduler - Final stage: ResultStage 31 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:07] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 30)
[2025-10-03 20:39:07] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:07] INFO  DAGScheduler - Submitting ResultStage 31 (MapPartitionsRDD[66] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_24 stored as values in memory (estimated size 42.1 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_24_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Added broadcast_24_piece0 in memory on DESKTOP-618L1DH:59062 (size: 19.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  SparkContext - Created broadcast 24 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:07] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[66] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Adding task set 31.0 with 1 tasks resource profile 0
[2025-10-03 20:39:07] INFO  TaskSetManager - Starting task 0.0 in stage 31.0 (TID 20) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:07] INFO  Executor - Running task 0.0 in stage 31.0 (TID 20)
[2025-10-03 20:39:07] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.8 KiB) non-empty blocks including 1 (2.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:07] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:07] INFO  Executor - Finished task 0.0 in stage 31.0 (TID 20). 5109 bytes result sent to driver
[2025-10-03 20:39:07] INFO  TaskSetManager - Finished task 0.0 in stage 31.0 (TID 20) in 20 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Removed TaskSet 31.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:07] INFO  DAGScheduler - ResultStage 31 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.032 s
[2025-10-03 20:39:07] INFO  DAGScheduler - Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Killing all running tasks in stage 31: Stage finished
[2025-10-03 20:39:07] INFO  DAGScheduler - Job 20 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.040295 s
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_25 stored as values in memory (estimated size 8.0 MiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  Executor - Finished task 0.0 in stage 27.0 (TID 17). 1906 bytes result sent to driver
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_25_piece0 stored as bytes in memory (estimated size 643.0 B, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  TaskSetManager - Finished task 0.0 in stage 27.0 (TID 17) in 345 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Removed TaskSet 27.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Added broadcast_25_piece0 in memory on DESKTOP-618L1DH:59062 (size: 643.0 B, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  DAGScheduler - ShuffleMapStage 27 (save at DataTransformation.java:131) finished in 0.356 s
[2025-10-03 20:39:07] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:07] INFO  DAGScheduler - running: Set(ShuffleMapStage 29)
[2025-10-03 20:39:07] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:07] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:07] INFO  SparkContext - Created broadcast 25 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:07] INFO  ShufflePartitionsUtil - For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:07] INFO  DAGScheduler - Registering RDD 69 (save at DataTransformation.java:131) as input to shuffle 12
[2025-10-03 20:39:07] INFO  DAGScheduler - Got map stage job 21 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:07] INFO  DAGScheduler - Final stage: ShuffleMapStage 33 (save at DataTransformation.java:131)
[2025-10-03 20:39:07] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 32)
[2025-10-03 20:39:07] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:07] INFO  DAGScheduler - Submitting ShuffleMapStage 33 (MapPartitionsRDD[69] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_26 stored as values in memory (estimated size 15.3 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_26_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Added broadcast_26_piece0 in memory on DESKTOP-618L1DH:59062 (size: 7.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  SparkContext - Created broadcast 26 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:07] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[69] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Adding task set 33.0 with 1 tasks resource profile 0
[2025-10-03 20:39:07] INFO  TaskSetManager - Starting task 0.0 in stage 33.0 (TID 21) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9007 bytes) 
[2025-10-03 20:39:07] INFO  Executor - Running task 0.0 in stage 33.0 (TID 21)
[2025-10-03 20:39:07] INFO  ShuffleBlockFetcherIterator - Getting 1 (1074.2 KiB) non-empty blocks including 1 (1074.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:07] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:07] INFO  Executor - Finished task 0.0 in stage 29.0 (TID 19). 2408 bytes result sent to driver
[2025-10-03 20:39:07] INFO  TaskSetManager - Finished task 0.0 in stage 29.0 (TID 19) in 586 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Removed TaskSet 29.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:07] INFO  DAGScheduler - ShuffleMapStage 29 (save at DataTransformation.java:131) finished in 0.607 s
[2025-10-03 20:39:07] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:07] INFO  DAGScheduler - running: Set(ShuffleMapStage 33)
[2025-10-03 20:39:07] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:07] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:07] INFO  ShufflePartitionsUtil - For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:07] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:07] INFO  DAGScheduler - Got job 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:07] INFO  DAGScheduler - Final stage: ResultStage 35 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:07] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 34)
[2025-10-03 20:39:07] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:07] INFO  DAGScheduler - Submitting ResultStage 35 (MapPartitionsRDD[72] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_27 stored as values in memory (estimated size 44.0 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_27_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Added broadcast_27_piece0 in memory on DESKTOP-618L1DH:59062 (size: 19.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  SparkContext - Created broadcast 27 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:07] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[72] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Adding task set 35.0 with 1 tasks resource profile 0
[2025-10-03 20:39:07] INFO  TaskSetManager - Starting task 0.0 in stage 35.0 (TID 22) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:07] INFO  Executor - Running task 0.0 in stage 35.0 (TID 22)
[2025-10-03 20:39:07] INFO  ShuffleBlockFetcherIterator - Getting 1 (99.6 KiB) non-empty blocks including 1 (99.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:07] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:07] INFO  Executor - Finished task 0.0 in stage 35.0 (TID 22). 59092 bytes result sent to driver
[2025-10-03 20:39:07] INFO  TaskSetManager - Finished task 0.0 in stage 35.0 (TID 22) in 33 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Removed TaskSet 35.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:07] INFO  DAGScheduler - ResultStage 35 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.048 s
[2025-10-03 20:39:07] INFO  DAGScheduler - Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Killing all running tasks in stage 35: Stage finished
[2025-10-03 20:39:07] INFO  DAGScheduler - Job 22 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.057584 s
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_28 stored as values in memory (estimated size 8.1 MiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_28_piece0 stored as bytes in memory (estimated size 70.4 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Added broadcast_28_piece0 in memory on DESKTOP-618L1DH:59062 (size: 70.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  SparkContext - Created broadcast 28 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:07] INFO  Executor - Finished task 0.0 in stage 33.0 (TID 21). 4259 bytes result sent to driver
[2025-10-03 20:39:07] INFO  TaskSetManager - Finished task 0.0 in stage 33.0 (TID 21) in 468 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Removed TaskSet 33.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:07] INFO  DAGScheduler - ShuffleMapStage 33 (save at DataTransformation.java:131) finished in 0.479 s
[2025-10-03 20:39:07] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:07] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:07] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:07] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:07] INFO  ShufflePartitionsUtil - For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Removed broadcast_26_piece0 on DESKTOP-618L1DH:59062 in memory (size: 7.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Removed broadcast_19_piece0 on DESKTOP-618L1DH:59062 in memory (size: 70.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Removed broadcast_23_piece0 on DESKTOP-618L1DH:59062 in memory (size: 17.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  SparkContext - Starting job: save at DataTransformation.java:131
[2025-10-03 20:39:07] INFO  DAGScheduler - Got job 23 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:07] INFO  DAGScheduler - Final stage: ResultStage 38 (save at DataTransformation.java:131)
[2025-10-03 20:39:07] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 37)
[2025-10-03 20:39:07] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:07] INFO  DAGScheduler - Submitting ResultStage 38 (MapPartitionsRDD[77] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Removed broadcast_16_piece0 on DESKTOP-618L1DH:59062 in memory (size: 643.0 B, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_29 stored as values in memory (estimated size 83.2 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Removed broadcast_22_piece0 on DESKTOP-618L1DH:59062 in memory (size: 16.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  MemoryStore - Block broadcast_29_piece0 stored as bytes in memory (estimated size 32.3 KiB, free 2.1 GiB)
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Added broadcast_29_piece0 in memory on DESKTOP-618L1DH:59062 (size: 32.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  SparkContext - Created broadcast 29 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:07] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[77] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:07] INFO  TaskSchedulerImpl - Adding task set 38.0 with 1 tasks resource profile 0
[2025-10-03 20:39:07] INFO  TaskSetManager - Starting task 0.0 in stage 38.0 (TID 23) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Removed broadcast_24_piece0 on DESKTOP-618L1DH:59062 in memory (size: 19.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  Executor - Running task 0.0 in stage 38.0 (TID 23)
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Removed broadcast_20_piece0 on DESKTOP-618L1DH:59062 in memory (size: 101.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  ShuffleBlockFetcherIterator - Getting 1 (117.1 KiB) non-empty blocks including 1 (117.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:07] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Removed broadcast_27_piece0 on DESKTOP-618L1DH:59062 in memory (size: 19.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:07] INFO  BlockManagerInfo - Removed broadcast_21_piece0 on DESKTOP-618L1DH:59062 in memory (size: 7.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:08] INFO  Executor - Finished task 0.0 in stage 38.0 (TID 23). 10813 bytes result sent to driver
[2025-10-03 20:39:08] INFO  TaskSetManager - Finished task 0.0 in stage 38.0 (TID 23) in 396 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:08] INFO  TaskSchedulerImpl - Removed TaskSet 38.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:08] INFO  DAGScheduler - ResultStage 38 (save at DataTransformation.java:131) finished in 0.410 s
[2025-10-03 20:39:08] INFO  DAGScheduler - Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:08] INFO  TaskSchedulerImpl - Killing all running tasks in stage 38: Stage finished
[2025-10-03 20:39:08] INFO  DAGScheduler - Job 23 finished: save at DataTransformation.java:131, took 0.419548 s
[2025-10-03 20:39:08] INFO  DataTransformation - Table dim_airport written to DB
[2025-10-03 20:39:08] INFO  DataTransformation - Loading table: gold.dim_carrier
[2025-10-03 20:39:08] INFO  DataTransformation - Loading table: gold.dim_airport
[2025-10-03 20:39:08] INFO  CodeGenerator - Code generated in 11.0901 ms
[2025-10-03 20:39:08] INFO  DAGScheduler - Registering RDD 84 (save at DataTransformation.java:118) as input to shuffle 13
[2025-10-03 20:39:08] INFO  DAGScheduler - Got map stage job 24 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:08] INFO  DAGScheduler - Final stage: ShuffleMapStage 39 (save at DataTransformation.java:118)
[2025-10-03 20:39:08] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:08] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:08] INFO  DAGScheduler - Submitting ShuffleMapStage 39 (MapPartitionsRDD[84] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:08] INFO  MemoryStore - Block broadcast_30 stored as values in memory (estimated size 24.8 KiB, free 2.1 GiB)
[2025-10-03 20:39:08] INFO  MemoryStore - Block broadcast_30_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 2.1 GiB)
[2025-10-03 20:39:08] INFO  BlockManagerInfo - Added broadcast_30_piece0 in memory on DESKTOP-618L1DH:59062 (size: 10.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:08] INFO  SparkContext - Created broadcast 30 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:08] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[84] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:08] INFO  TaskSchedulerImpl - Adding task set 39.0 with 1 tasks resource profile 0
[2025-10-03 20:39:08] INFO  DAGScheduler - Registering RDD 86 (save at DataTransformation.java:118) as input to shuffle 14
[2025-10-03 20:39:08] INFO  TaskSetManager - Starting task 0.0 in stage 39.0 (TID 24) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:08] INFO  DAGScheduler - Got map stage job 25 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:08] INFO  DAGScheduler - Final stage: ShuffleMapStage 40 (save at DataTransformation.java:118)
[2025-10-03 20:39:08] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:08] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:08] INFO  Executor - Running task 0.0 in stage 39.0 (TID 24)
[2025-10-03 20:39:08] INFO  DAGScheduler - Submitting ShuffleMapStage 40 (MapPartitionsRDD[86] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:08] INFO  MemoryStore - Block broadcast_31 stored as values in memory (estimated size 35.8 KiB, free 2.1 GiB)
[2025-10-03 20:39:08] INFO  MemoryStore - Block broadcast_31_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 2.1 GiB)
[2025-10-03 20:39:08] INFO  BlockManagerInfo - Added broadcast_31_piece0 in memory on DESKTOP-618L1DH:59062 (size: 16.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:08] INFO  SparkContext - Created broadcast 31 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:08] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[86] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:08] INFO  TaskSchedulerImpl - Adding task set 40.0 with 1 tasks resource profile 0
[2025-10-03 20:39:08] INFO  TaskSetManager - Starting task 0.0 in stage 40.0 (TID 25) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:08] INFO  Executor - Running task 0.0 in stage 40.0 (TID 25)
[2025-10-03 20:39:08] INFO  DAGScheduler - Registering RDD 88 (save at DataTransformation.java:118) as input to shuffle 15
[2025-10-03 20:39:08] INFO  DAGScheduler - Got map stage job 26 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:08] INFO  DAGScheduler - Final stage: ShuffleMapStage 41 (save at DataTransformation.java:118)
[2025-10-03 20:39:08] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:08] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:08] INFO  DAGScheduler - Submitting ShuffleMapStage 41 (MapPartitionsRDD[88] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:08] INFO  MemoryStore - Block broadcast_32 stored as values in memory (estimated size 37.3 KiB, free 2.1 GiB)
[2025-10-03 20:39:08] INFO  MemoryStore - Block broadcast_32_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 2.1 GiB)
[2025-10-03 20:39:08] INFO  BlockManagerInfo - Added broadcast_32_piece0 in memory on DESKTOP-618L1DH:59062 (size: 17.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:08] INFO  SparkContext - Created broadcast 32 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:08] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[88] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:08] INFO  TaskSchedulerImpl - Adding task set 41.0 with 1 tasks resource profile 0
[2025-10-03 20:39:08] INFO  CodeGenerator - Code generated in 10.1406 ms
[2025-10-03 20:39:08] INFO  TaskSetManager - Starting task 0.0 in stage 41.0 (TID 26) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:08] INFO  Executor - Running task 0.0 in stage 41.0 (TID 26)
[2025-10-03 20:39:08] INFO  DAGScheduler - Registering RDD 90 (save at DataTransformation.java:118) as input to shuffle 16
[2025-10-03 20:39:08] INFO  DAGScheduler - Got map stage job 27 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:08] INFO  DAGScheduler - Final stage: ShuffleMapStage 42 (save at DataTransformation.java:118)
[2025-10-03 20:39:08] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:08] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:08] INFO  DAGScheduler - Submitting ShuffleMapStage 42 (MapPartitionsRDD[90] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:08] INFO  MemoryStore - Block broadcast_33 stored as values in memory (estimated size 14.5 KiB, free 2.1 GiB)
[2025-10-03 20:39:08] INFO  MemoryStore - Block broadcast_33_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.1 GiB)
[2025-10-03 20:39:08] INFO  BlockManagerInfo - Added broadcast_33_piece0 in memory on DESKTOP-618L1DH:59062 (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:08] INFO  SparkContext - Created broadcast 33 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:08] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[90] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:08] INFO  TaskSchedulerImpl - Adding task set 42.0 with 1 tasks resource profile 0
[2025-10-03 20:39:08] INFO  TaskSetManager - Starting task 0.0 in stage 42.0 (TID 27) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:08] INFO  CodeGenerator - Code generated in 13.3721 ms
[2025-10-03 20:39:08] INFO  Executor - Running task 0.0 in stage 42.0 (TID 27)
[2025-10-03 20:39:08] INFO  DAGScheduler - Registering RDD 92 (save at DataTransformation.java:118) as input to shuffle 17
[2025-10-03 20:39:08] INFO  DAGScheduler - Got map stage job 28 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:08] INFO  DAGScheduler - Final stage: ShuffleMapStage 43 (save at DataTransformation.java:118)
[2025-10-03 20:39:08] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:08] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:08] INFO  DAGScheduler - Submitting ShuffleMapStage 43 (MapPartitionsRDD[92] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:08] INFO  MemoryStore - Block broadcast_34 stored as values in memory (estimated size 14.5 KiB, free 2.1 GiB)
[2025-10-03 20:39:08] INFO  MemoryStore - Block broadcast_34_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.1 GiB)
[2025-10-03 20:39:08] INFO  BlockManagerInfo - Added broadcast_34_piece0 in memory on DESKTOP-618L1DH:59062 (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:08] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:08] INFO  SparkContext - Created broadcast 34 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:08] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[92] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:08] INFO  TaskSchedulerImpl - Adding task set 43.0 with 1 tasks resource profile 0
[2025-10-03 20:39:08] INFO  TaskSetManager - Starting task 0.0 in stage 43.0 (TID 28) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:08] INFO  Executor - Running task 0.0 in stage 43.0 (TID 28)
[2025-10-03 20:39:08] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:08] INFO  CodeGenerator - Code generated in 8.5562 ms
[2025-10-03 20:39:08] INFO  CodeGenerator - Code generated in 7.1029 ms
[2025-10-03 20:39:08] INFO  CodeGenerator - Code generated in 13.752 ms
[2025-10-03 20:39:08] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:08] INFO  Executor - Finished task 0.0 in stage 40.0 (TID 25). 2408 bytes result sent to driver
[2025-10-03 20:39:08] INFO  TaskSetManager - Finished task 0.0 in stage 40.0 (TID 25) in 139 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:08] INFO  TaskSchedulerImpl - Removed TaskSet 40.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:08] INFO  DAGScheduler - ShuffleMapStage 40 (save at DataTransformation.java:118) finished in 0.151 s
[2025-10-03 20:39:08] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:08] INFO  DAGScheduler - running: Set(ShuffleMapStage 42, ShuffleMapStage 39, ShuffleMapStage 43, ShuffleMapStage 41)
[2025-10-03 20:39:08] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:08] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:09] INFO  ShufflePartitionsUtil - For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:09] INFO  Executor - Finished task 0.0 in stage 42.0 (TID 27). 1949 bytes result sent to driver
[2025-10-03 20:39:09] INFO  TaskSetManager - Finished task 0.0 in stage 42.0 (TID 27) in 133 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:09] INFO  TaskSchedulerImpl - Removed TaskSet 42.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:09] INFO  DAGScheduler - ShuffleMapStage 42 (save at DataTransformation.java:118) finished in 0.145 s
[2025-10-03 20:39:09] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:09] INFO  DAGScheduler - running: Set(ShuffleMapStage 39, ShuffleMapStage 43, ShuffleMapStage 41)
[2025-10-03 20:39:09] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:09] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:09] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:09] INFO  CodeGenerator - Code generated in 53.2102 ms
[2025-10-03 20:39:09] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:09] INFO  DAGScheduler - Got job 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:09] INFO  DAGScheduler - Final stage: ResultStage 45 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:09] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 44)
[2025-10-03 20:39:09] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:09] INFO  DAGScheduler - Submitting ResultStage 45 (MapPartitionsRDD[95] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:09] INFO  MemoryStore - Block broadcast_35 stored as values in memory (estimated size 42.1 KiB, free 2.1 GiB)
[2025-10-03 20:39:09] INFO  MemoryStore - Block broadcast_35_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 2.1 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Added broadcast_35_piece0 in memory on DESKTOP-618L1DH:59062 (size: 19.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  SparkContext - Created broadcast 35 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:09] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[95] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:09] INFO  TaskSchedulerImpl - Adding task set 45.0 with 1 tasks resource profile 0
[2025-10-03 20:39:09] INFO  TaskSetManager - Starting task 0.0 in stage 45.0 (TID 29) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:09] INFO  Executor - Running task 0.0 in stage 45.0 (TID 29)
[2025-10-03 20:39:09] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.8 KiB) non-empty blocks including 1 (2.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:09] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:09] INFO  CodeGenerator - Code generated in 36.2674 ms
[2025-10-03 20:39:09] INFO  Executor - Finished task 0.0 in stage 45.0 (TID 29). 5109 bytes result sent to driver
[2025-10-03 20:39:09] INFO  TaskSetManager - Finished task 0.0 in stage 45.0 (TID 29) in 71 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:09] INFO  TaskSchedulerImpl - Removed TaskSet 45.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:09] INFO  DAGScheduler - ResultStage 45 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.080 s
[2025-10-03 20:39:09] INFO  DAGScheduler - Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:09] INFO  TaskSchedulerImpl - Killing all running tasks in stage 45: Stage finished
[2025-10-03 20:39:09] INFO  DAGScheduler - Job 29 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.086420 s
[2025-10-03 20:39:09] INFO  MemoryStore - Block broadcast_36 stored as values in memory (estimated size 8.0 MiB, free 2.1 GiB)
[2025-10-03 20:39:09] INFO  MemoryStore - Block broadcast_36_piece0 stored as bytes in memory (estimated size 643.0 B, free 2.1 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Added broadcast_36_piece0 in memory on DESKTOP-618L1DH:59062 (size: 643.0 B, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  SparkContext - Created broadcast 36 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:09] INFO  Executor - Finished task 0.0 in stage 43.0 (TID 28). 1949 bytes result sent to driver
[2025-10-03 20:39:09] INFO  TaskSetManager - Finished task 0.0 in stage 43.0 (TID 28) in 482 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:09] INFO  TaskSchedulerImpl - Removed TaskSet 43.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:09] INFO  DAGScheduler - ShuffleMapStage 43 (save at DataTransformation.java:118) finished in 0.491 s
[2025-10-03 20:39:09] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:09] INFO  DAGScheduler - running: Set(ShuffleMapStage 39, ShuffleMapStage 41)
[2025-10-03 20:39:09] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:09] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:09] INFO  CodeGenerator - Code generated in 17.2196 ms
[2025-10-03 20:39:09] INFO  CodeGenerator - Code generated in 10.1744 ms
[2025-10-03 20:39:09] INFO  ShufflePartitionsUtil - For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:09] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:09] INFO  DAGScheduler - Got job 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:09] INFO  DAGScheduler - Final stage: ResultStage 47 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:09] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 46)
[2025-10-03 20:39:09] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:09] INFO  DAGScheduler - Submitting ResultStage 47 (MapPartitionsRDD[97] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:09] INFO  MemoryStore - Block broadcast_37 stored as values in memory (estimated size 8.2 KiB, free 2.1 GiB)
[2025-10-03 20:39:09] INFO  MemoryStore - Block broadcast_37_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 2.1 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Added broadcast_37_piece0 in memory on DESKTOP-618L1DH:59062 (size: 4.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  SparkContext - Created broadcast 37 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:09] INFO  Executor - Finished task 0.0 in stage 41.0 (TID 26). 2408 bytes result sent to driver
[2025-10-03 20:39:09] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[97] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:09] INFO  TaskSchedulerImpl - Adding task set 47.0 with 1 tasks resource profile 0
[2025-10-03 20:39:09] INFO  TaskSetManager - Starting task 0.0 in stage 47.0 (TID 30) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9018 bytes) 
[2025-10-03 20:39:09] INFO  TaskSetManager - Finished task 0.0 in stage 41.0 (TID 26) in 590 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:09] INFO  TaskSchedulerImpl - Removed TaskSet 41.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:09] INFO  Executor - Running task 0.0 in stage 47.0 (TID 30)
[2025-10-03 20:39:09] INFO  DAGScheduler - ShuffleMapStage 41 (save at DataTransformation.java:118) finished in 0.601 s
[2025-10-03 20:39:09] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:09] INFO  DAGScheduler - running: Set(ShuffleMapStage 39, ResultStage 47)
[2025-10-03 20:39:09] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:09] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:09] INFO  ShuffleBlockFetcherIterator - Getting 1 (15.2 KiB) non-empty blocks including 1 (15.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:09] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:09] INFO  Executor - Finished task 0.0 in stage 47.0 (TID 30). 7972 bytes result sent to driver
[2025-10-03 20:39:09] INFO  TaskSetManager - Finished task 0.0 in stage 47.0 (TID 30) in 19 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:09] INFO  TaskSchedulerImpl - Removed TaskSet 47.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:09] INFO  DAGScheduler - ResultStage 47 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.032 s
[2025-10-03 20:39:09] INFO  DAGScheduler - Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:09] INFO  TaskSchedulerImpl - Killing all running tasks in stage 47: Stage finished
[2025-10-03 20:39:09] INFO  DAGScheduler - Job 30 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.037801 s
[2025-10-03 20:39:09] INFO  ShufflePartitionsUtil - For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:09] INFO  MemoryStore - Block broadcast_38 stored as values in memory (estimated size 8.0 MiB, free 2.1 GiB)
[2025-10-03 20:39:09] INFO  MemoryStore - Block broadcast_38_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 2.1 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Added broadcast_38_piece0 in memory on DESKTOP-618L1DH:59062 (size: 6.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  SparkContext - Created broadcast 38 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Removed broadcast_37_piece0 on DESKTOP-618L1DH:59062 in memory (size: 4.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Removed broadcast_34_piece0 on DESKTOP-618L1DH:59062 in memory (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Removed broadcast_2_piece0 on DESKTOP-618L1DH:59062 in memory (size: 7.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Removed broadcast_35_piece0 on DESKTOP-618L1DH:59062 in memory (size: 19.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Removed broadcast_29_piece0 on DESKTOP-618L1DH:59062 in memory (size: 32.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Removed broadcast_31_piece0 on DESKTOP-618L1DH:59062 in memory (size: 16.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  CodeGenerator - Code generated in 68.866 ms
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Removed broadcast_25_piece0 on DESKTOP-618L1DH:59062 in memory (size: 643.0 B, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Removed broadcast_28_piece0 on DESKTOP-618L1DH:59062 in memory (size: 70.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Removed broadcast_33_piece0 on DESKTOP-618L1DH:59062 in memory (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Removed broadcast_32_piece0 on DESKTOP-618L1DH:59062 in memory (size: 17.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:09] INFO  DAGScheduler - Got job 31 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:09] INFO  DAGScheduler - Final stage: ResultStage 49 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:09] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 48)
[2025-10-03 20:39:09] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:09] INFO  DAGScheduler - Submitting ResultStage 49 (MapPartitionsRDD[100] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:09] INFO  MemoryStore - Block broadcast_39 stored as values in memory (estimated size 43.7 KiB, free 2.1 GiB)
[2025-10-03 20:39:09] INFO  MemoryStore - Block broadcast_39_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 2.1 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Added broadcast_39_piece0 in memory on DESKTOP-618L1DH:59062 (size: 19.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  SparkContext - Created broadcast 39 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:09] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[100] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:09] INFO  TaskSchedulerImpl - Adding task set 49.0 with 1 tasks resource profile 0
[2025-10-03 20:39:09] INFO  TaskSetManager - Starting task 0.0 in stage 49.0 (TID 31) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:09] INFO  Executor - Running task 0.0 in stage 49.0 (TID 31)
[2025-10-03 20:39:09] INFO  ShuffleBlockFetcherIterator - Getting 1 (99.6 KiB) non-empty blocks including 1 (99.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:09] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:09] INFO  CodeGenerator - Code generated in 39.2169 ms
[2025-10-03 20:39:09] INFO  Executor - Finished task 0.0 in stage 49.0 (TID 31). 16326 bytes result sent to driver
[2025-10-03 20:39:09] INFO  TaskSetManager - Finished task 0.0 in stage 49.0 (TID 31) in 87 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:09] INFO  TaskSchedulerImpl - Removed TaskSet 49.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:09] INFO  DAGScheduler - ResultStage 49 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.098 s
[2025-10-03 20:39:09] INFO  DAGScheduler - Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:09] INFO  TaskSchedulerImpl - Killing all running tasks in stage 49: Stage finished
[2025-10-03 20:39:09] INFO  DAGScheduler - Job 31 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.105986 s
[2025-10-03 20:39:09] INFO  MemoryStore - Block broadcast_40 stored as values in memory (estimated size 8.1 MiB, free 2.1 GiB)
[2025-10-03 20:39:09] INFO  MemoryStore - Block broadcast_40_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 2.1 GiB)
[2025-10-03 20:39:09] INFO  BlockManagerInfo - Added broadcast_40_piece0 in memory on DESKTOP-618L1DH:59062 (size: 29.0 KiB, free: 2.2 GiB)
[2025-10-03 20:39:09] INFO  SparkContext - Created broadcast 40 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:10] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:10] INFO  Executor - Finished task 0.0 in stage 39.0 (TID 24). 1949 bytes result sent to driver
[2025-10-03 20:39:10] INFO  TaskSetManager - Finished task 0.0 in stage 39.0 (TID 24) in 1271 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:10] INFO  TaskSchedulerImpl - Removed TaskSet 39.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:10] INFO  DAGScheduler - ShuffleMapStage 39 (save at DataTransformation.java:118) finished in 1.290 s
[2025-10-03 20:39:10] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:10] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:10] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:10] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:10] INFO  ShufflePartitionsUtil - For shuffle(13, 16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:10] INFO  BlockManagerInfo - Removed broadcast_39_piece0 on DESKTOP-618L1DH:59062 in memory (size: 19.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:10] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:10] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:39:10] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:39:10] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:10] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:39:10] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:39:10] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:10] INFO  CodeGenerator - Code generated in 20.4966 ms
[2025-10-03 20:39:10] INFO  CodeGenerator - Code generated in 21.2254 ms
[2025-10-03 20:39:10] INFO  CodeGenerator - Code generated in 13.1009 ms
[2025-10-03 20:39:10] INFO  SparkContext - Starting job: save at DataTransformation.java:118
[2025-10-03 20:39:10] INFO  DAGScheduler - Got job 32 (save at DataTransformation.java:118) with 1 output partitions
[2025-10-03 20:39:10] INFO  DAGScheduler - Final stage: ResultStage 52 (save at DataTransformation.java:118)
[2025-10-03 20:39:10] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 51, ShuffleMapStage 50)
[2025-10-03 20:39:10] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:10] INFO  DAGScheduler - Submitting ResultStage 52 (MapPartitionsRDD[108] at save at DataTransformation.java:118), which has no missing parents
[2025-10-03 20:39:10] INFO  MemoryStore - Block broadcast_41 stored as values in memory (estimated size 301.9 KiB, free 2.1 GiB)
[2025-10-03 20:39:10] INFO  MemoryStore - Block broadcast_41_piece0 stored as bytes in memory (estimated size 109.2 KiB, free 2.1 GiB)
[2025-10-03 20:39:10] INFO  BlockManagerInfo - Added broadcast_41_piece0 in memory on DESKTOP-618L1DH:59062 (size: 109.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:10] INFO  SparkContext - Created broadcast 41 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:10] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[108] at save at DataTransformation.java:118) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:10] INFO  TaskSchedulerImpl - Adding task set 52.0 with 1 tasks resource profile 0
[2025-10-03 20:39:10] INFO  TaskSetManager - Starting task 0.0 in stage 52.0 (TID 32) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9695 bytes) 
[2025-10-03 20:39:10] INFO  Executor - Running task 0.0 in stage 52.0 (TID 32)
[2025-10-03 20:39:10] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:39:10] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:39:10] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:10] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-03 20:39:10] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-03 20:39:10] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-03 20:39:10] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:39:10] INFO  CodecConfig - Compression: SNAPPY
[2025-10-03 20:39:10] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-03 20:39:10] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "year",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "month",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "airport_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_flights",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_del15",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "weather_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "nas_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "security_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "late_aircraft_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "weather_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "nas_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "security_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "late_aircraft_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_cancelled",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_diverted",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "on_time_flag",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "total_delay",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "date",
    "type" : "date",
    "nullable" : true,
    "metadata" : {
      "isSigned" : false,
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 year;
  optional int32 month;
  optional int32 airport_id;
  optional int32 carrier_id;
  optional int32 arr_flights;
  optional double arr_delay;
  optional double arr_del15;
  optional double carrier_ct;
  optional double weather_ct;
  optional double nas_ct;
  optional double security_ct;
  optional double late_aircraft_ct;
  optional double carrier_delay;
  optional double weather_delay;
  optional double nas_delay;
  optional double security_delay;
  optional double late_aircraft_delay;
  optional double arr_cancelled;
  optional double arr_diverted;
  required int32 on_time_flag;
  required double total_delay;
  optional int32 date (DATE);
}

       
[2025-10-03 20:39:10] INFO  ShuffleBlockFetcherIterator - Getting 1 (1267.1 KiB) non-empty blocks including 1 (1267.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:10] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:10] INFO  CodeGenerator - Code generated in 15.5193 ms
[2025-10-03 20:39:10] INFO  CodeGenerator - Code generated in 19.1269 ms
[2025-10-03 20:39:10] INFO  CodeGenerator - Code generated in 14.0544 ms
[2025-10-03 20:39:10] INFO  ShuffleBlockFetcherIterator - Getting 1 (432.0 B) non-empty blocks including 1 (432.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:10] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:10] INFO  CodeGenerator - Code generated in 10.9347 ms
[2025-10-03 20:39:10] INFO  CodeGenerator - Code generated in 6.1668 ms
[2025-10-03 20:39:10] INFO  CodeGenerator - Code generated in 7.8398 ms
[2025-10-03 20:39:10] INFO  CodeGenerator - Code generated in 19.1592 ms
[2025-10-03 20:39:10] INFO  ShuffleBlockFetcherIterator - Getting 1 (1034.7 KiB) non-empty blocks including 1 (1034.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:10] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:10] INFO  ShuffleBlockFetcherIterator - Getting 1 (288.0 B) non-empty blocks including 1 (288.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:10] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:11] INFO  ShuffleBlockFetcherIterator - Getting 1 (1641.5 KiB) non-empty blocks including 1 (1641.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:11] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:11] INFO  ShuffleBlockFetcherIterator - Getting 1 (792.0 B) non-empty blocks including 1 (792.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:11] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:11] INFO  FileOutputCommitter - Saved output of task 'attempt_20251003203910871914488849543356_0052_m_000000_32' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/gold/fact_flight_performance/_temporary/0/task_20251003203910871914488849543356_0052_m_000000
[2025-10-03 20:39:11] INFO  SparkHadoopMapRedUtil - attempt_20251003203910871914488849543356_0052_m_000000_32: Committed. Elapsed time: 2 ms.
[2025-10-03 20:39:11] INFO  Executor - Finished task 0.0 in stage 52.0 (TID 32). 13661 bytes result sent to driver
[2025-10-03 20:39:11] INFO  TaskSetManager - Finished task 0.0 in stage 52.0 (TID 32) in 897 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:11] INFO  TaskSchedulerImpl - Removed TaskSet 52.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:11] INFO  DAGScheduler - ResultStage 52 (save at DataTransformation.java:118) finished in 0.947 s
[2025-10-03 20:39:11] INFO  DAGScheduler - Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:11] INFO  TaskSchedulerImpl - Killing all running tasks in stage 52: Stage finished
[2025-10-03 20:39:11] INFO  DAGScheduler - Job 32 finished: save at DataTransformation.java:118, took 0.952488 s
[2025-10-03 20:39:11] INFO  FileFormatWriter - Start to commit write Job e25c6b10-c5dc-4ac9-a152-eebb9b09d9b3.
[2025-10-03 20:39:11] INFO  FileFormatWriter - Write Job e25c6b10-c5dc-4ac9-a152-eebb9b09d9b3 committed. Elapsed time: 29 ms.
[2025-10-03 20:39:11] INFO  FileFormatWriter - Finished processing stats for write job e25c6b10-c5dc-4ac9-a152-eebb9b09d9b3.
[2025-10-03 20:39:11] INFO  DAGScheduler - Registering RDD 115 (save at DataTransformation.java:131) as input to shuffle 18
[2025-10-03 20:39:11] INFO  DAGScheduler - Got map stage job 33 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:11] INFO  DAGScheduler - Final stage: ShuffleMapStage 53 (save at DataTransformation.java:131)
[2025-10-03 20:39:11] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:11] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:11] INFO  DAGScheduler - Submitting ShuffleMapStage 53 (MapPartitionsRDD[115] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_42 stored as values in memory (estimated size 24.8 KiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_42_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  BlockManagerInfo - Added broadcast_42_piece0 in memory on DESKTOP-618L1DH:59062 (size: 10.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:11] INFO  SparkContext - Created broadcast 42 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:11] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[115] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:11] INFO  TaskSchedulerImpl - Adding task set 53.0 with 1 tasks resource profile 0
[2025-10-03 20:39:11] INFO  DAGScheduler - Registering RDD 117 (save at DataTransformation.java:131) as input to shuffle 19
[2025-10-03 20:39:11] INFO  TaskSetManager - Starting task 0.0 in stage 53.0 (TID 33) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:11] INFO  DAGScheduler - Got map stage job 34 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:11] INFO  DAGScheduler - Final stage: ShuffleMapStage 54 (save at DataTransformation.java:131)
[2025-10-03 20:39:11] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:11] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:11] INFO  DAGScheduler - Submitting ShuffleMapStage 54 (MapPartitionsRDD[117] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:11] INFO  Executor - Running task 0.0 in stage 53.0 (TID 33)
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_43 stored as values in memory (estimated size 35.8 KiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_43_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  BlockManagerInfo - Added broadcast_43_piece0 in memory on DESKTOP-618L1DH:59062 (size: 16.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:11] INFO  SparkContext - Created broadcast 43 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:11] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[117] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:11] INFO  TaskSchedulerImpl - Adding task set 54.0 with 1 tasks resource profile 0
[2025-10-03 20:39:11] INFO  TaskSetManager - Starting task 0.0 in stage 54.0 (TID 34) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:11] INFO  DAGScheduler - Registering RDD 119 (save at DataTransformation.java:131) as input to shuffle 20
[2025-10-03 20:39:11] INFO  DAGScheduler - Got map stage job 35 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:11] INFO  DAGScheduler - Final stage: ShuffleMapStage 55 (save at DataTransformation.java:131)
[2025-10-03 20:39:11] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:11] INFO  Executor - Running task 0.0 in stage 54.0 (TID 34)
[2025-10-03 20:39:11] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:11] INFO  DAGScheduler - Submitting ShuffleMapStage 55 (MapPartitionsRDD[119] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_44 stored as values in memory (estimated size 37.3 KiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_44_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  BlockManagerInfo - Added broadcast_44_piece0 in memory on DESKTOP-618L1DH:59062 (size: 17.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:11] INFO  SparkContext - Created broadcast 44 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:11] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[119] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:11] INFO  TaskSchedulerImpl - Adding task set 55.0 with 1 tasks resource profile 0
[2025-10-03 20:39:11] INFO  DAGScheduler - Registering RDD 121 (save at DataTransformation.java:131) as input to shuffle 21
[2025-10-03 20:39:11] INFO  DAGScheduler - Got map stage job 36 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:11] INFO  DAGScheduler - Final stage: ShuffleMapStage 56 (save at DataTransformation.java:131)
[2025-10-03 20:39:11] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:11] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:11] INFO  TaskSetManager - Starting task 0.0 in stage 55.0 (TID 35) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:11] INFO  DAGScheduler - Submitting ShuffleMapStage 56 (MapPartitionsRDD[121] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:11] INFO  Executor - Running task 0.0 in stage 55.0 (TID 35)
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_45 stored as values in memory (estimated size 14.5 KiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_45_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  BlockManagerInfo - Added broadcast_45_piece0 in memory on DESKTOP-618L1DH:59062 (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:11] INFO  SparkContext - Created broadcast 45 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:11] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[121] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:11] INFO  TaskSchedulerImpl - Adding task set 56.0 with 1 tasks resource profile 0
[2025-10-03 20:39:11] INFO  DAGScheduler - Registering RDD 123 (save at DataTransformation.java:131) as input to shuffle 22
[2025-10-03 20:39:11] INFO  DAGScheduler - Got map stage job 37 (save at DataTransformation.java:131) with 1 output partitions
[2025-10-03 20:39:11] INFO  DAGScheduler - Final stage: ShuffleMapStage 57 (save at DataTransformation.java:131)
[2025-10-03 20:39:11] INFO  TaskSetManager - Starting task 0.0 in stage 56.0 (TID 36) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:11] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:11] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:11] INFO  DAGScheduler - Submitting ShuffleMapStage 57 (MapPartitionsRDD[123] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:11] INFO  Executor - Running task 0.0 in stage 56.0 (TID 36)
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_46 stored as values in memory (estimated size 14.5 KiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_46_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  BlockManagerInfo - Added broadcast_46_piece0 in memory on DESKTOP-618L1DH:59062 (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:11] INFO  SparkContext - Created broadcast 46 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:11] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[123] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:11] INFO  TaskSchedulerImpl - Adding task set 57.0 with 1 tasks resource profile 0
[2025-10-03 20:39:11] INFO  TaskSetManager - Starting task 0.0 in stage 57.0 (TID 37) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:11] INFO  Executor - Running task 0.0 in stage 57.0 (TID 37)
[2025-10-03 20:39:11] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:11] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:11] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:11] INFO  Executor - Finished task 0.0 in stage 56.0 (TID 36). 1906 bytes result sent to driver
[2025-10-03 20:39:11] INFO  TaskSetManager - Finished task 0.0 in stage 56.0 (TID 36) in 143 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:11] INFO  TaskSchedulerImpl - Removed TaskSet 56.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:11] INFO  DAGScheduler - ShuffleMapStage 56 (save at DataTransformation.java:131) finished in 0.151 s
[2025-10-03 20:39:11] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:11] INFO  DAGScheduler - running: Set(ShuffleMapStage 53, ShuffleMapStage 57, ShuffleMapStage 54, ShuffleMapStage 55)
[2025-10-03 20:39:11] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:11] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:11] INFO  Executor - Finished task 0.0 in stage 54.0 (TID 34). 2451 bytes result sent to driver
[2025-10-03 20:39:11] INFO  TaskSetManager - Finished task 0.0 in stage 54.0 (TID 34) in 167 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:11] INFO  TaskSchedulerImpl - Removed TaskSet 54.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:11] INFO  DAGScheduler - ShuffleMapStage 54 (save at DataTransformation.java:131) finished in 0.176 s
[2025-10-03 20:39:11] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:11] INFO  DAGScheduler - running: Set(ShuffleMapStage 53, ShuffleMapStage 57, ShuffleMapStage 55)
[2025-10-03 20:39:11] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:11] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:11] INFO  BlockManagerInfo - Removed broadcast_45_piece0 on DESKTOP-618L1DH:59062 in memory (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:11] INFO  BlockManagerInfo - Removed broadcast_43_piece0 on DESKTOP-618L1DH:59062 in memory (size: 16.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:11] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:11] INFO  ShufflePartitionsUtil - For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:11] INFO  BlockManagerInfo - Removed broadcast_41_piece0 on DESKTOP-618L1DH:59062 in memory (size: 109.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:11] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:11] INFO  DAGScheduler - Got job 38 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:11] INFO  DAGScheduler - Final stage: ResultStage 59 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:11] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 58)
[2025-10-03 20:39:11] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:11] INFO  DAGScheduler - Submitting ResultStage 59 (MapPartitionsRDD[126] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_47 stored as values in memory (estimated size 42.1 KiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_47_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  BlockManagerInfo - Added broadcast_47_piece0 in memory on DESKTOP-618L1DH:59062 (size: 19.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:11] INFO  SparkContext - Created broadcast 47 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:11] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[126] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:11] INFO  TaskSchedulerImpl - Adding task set 59.0 with 1 tasks resource profile 0
[2025-10-03 20:39:11] INFO  TaskSetManager - Starting task 0.0 in stage 59.0 (TID 38) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:11] INFO  Executor - Running task 0.0 in stage 59.0 (TID 38)
[2025-10-03 20:39:11] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.8 KiB) non-empty blocks including 1 (2.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:11] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:11] INFO  Executor - Finished task 0.0 in stage 59.0 (TID 38). 5109 bytes result sent to driver
[2025-10-03 20:39:11] INFO  TaskSetManager - Finished task 0.0 in stage 59.0 (TID 38) in 38 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:11] INFO  TaskSchedulerImpl - Removed TaskSet 59.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:11] INFO  DAGScheduler - ResultStage 59 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.057 s
[2025-10-03 20:39:11] INFO  DAGScheduler - Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:11] INFO  TaskSchedulerImpl - Killing all running tasks in stage 59: Stage finished
[2025-10-03 20:39:11] INFO  DAGScheduler - Job 38 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.064342 s
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_48 stored as values in memory (estimated size 8.0 MiB, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  MemoryStore - Block broadcast_48_piece0 stored as bytes in memory (estimated size 643.0 B, free 2.1 GiB)
[2025-10-03 20:39:11] INFO  BlockManagerInfo - Added broadcast_48_piece0 in memory on DESKTOP-618L1DH:59062 (size: 643.0 B, free: 2.2 GiB)
[2025-10-03 20:39:11] INFO  SparkContext - Created broadcast 48 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:12] INFO  Executor - Finished task 0.0 in stage 57.0 (TID 37). 1949 bytes result sent to driver
[2025-10-03 20:39:12] INFO  TaskSetManager - Finished task 0.0 in stage 57.0 (TID 37) in 596 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:12] INFO  TaskSchedulerImpl - Removed TaskSet 57.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:12] INFO  DAGScheduler - ShuffleMapStage 57 (save at DataTransformation.java:131) finished in 0.617 s
[2025-10-03 20:39:12] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:12] INFO  DAGScheduler - running: Set(ShuffleMapStage 53, ShuffleMapStage 55)
[2025-10-03 20:39:12] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:12] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:12] INFO  Executor - Finished task 0.0 in stage 55.0 (TID 35). 2494 bytes result sent to driver
[2025-10-03 20:39:12] INFO  ShufflePartitionsUtil - For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:12] INFO  TaskSetManager - Finished task 0.0 in stage 55.0 (TID 35) in 644 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:12] INFO  TaskSchedulerImpl - Removed TaskSet 55.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:12] INFO  DAGScheduler - ShuffleMapStage 55 (save at DataTransformation.java:131) finished in 0.651 s
[2025-10-03 20:39:12] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:12] INFO  DAGScheduler - running: Set(ShuffleMapStage 53)
[2025-10-03 20:39:12] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:12] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:12] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:12] INFO  DAGScheduler - Got job 39 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:12] INFO  DAGScheduler - Final stage: ResultStage 61 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:12] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 60)
[2025-10-03 20:39:12] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:12] INFO  DAGScheduler - Submitting ResultStage 61 (MapPartitionsRDD[128] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:12] INFO  ShufflePartitionsUtil - For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:12] INFO  MemoryStore - Block broadcast_49 stored as values in memory (estimated size 8.2 KiB, free 2.1 GiB)
[2025-10-03 20:39:12] INFO  MemoryStore - Block broadcast_49_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 2.1 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Added broadcast_49_piece0 in memory on DESKTOP-618L1DH:59062 (size: 4.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  SparkContext - Created broadcast 49 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:12] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[128] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:12] INFO  TaskSchedulerImpl - Adding task set 61.0 with 1 tasks resource profile 0
[2025-10-03 20:39:12] INFO  TaskSetManager - Starting task 0.0 in stage 61.0 (TID 39) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9018 bytes) 
[2025-10-03 20:39:12] INFO  Executor - Running task 0.0 in stage 61.0 (TID 39)
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (15.2 KiB) non-empty blocks including 1 (15.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:12] INFO  Executor - Finished task 0.0 in stage 61.0 (TID 39). 7972 bytes result sent to driver
[2025-10-03 20:39:12] INFO  TaskSetManager - Finished task 0.0 in stage 61.0 (TID 39) in 13 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:12] INFO  TaskSchedulerImpl - Removed TaskSet 61.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:12] INFO  DAGScheduler - ResultStage 61 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.025 s
[2025-10-03 20:39:12] INFO  DAGScheduler - Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:12] INFO  TaskSchedulerImpl - Killing all running tasks in stage 61: Stage finished
[2025-10-03 20:39:12] INFO  DAGScheduler - Job 39 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.029667 s
[2025-10-03 20:39:12] INFO  MemoryStore - Block broadcast_50 stored as values in memory (estimated size 8.0 MiB, free 2.1 GiB)
[2025-10-03 20:39:12] INFO  MemoryStore - Block broadcast_50_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 2.1 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Added broadcast_50_piece0 in memory on DESKTOP-618L1DH:59062 (size: 6.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  SparkContext - Created broadcast 50 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:12] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:12] INFO  DAGScheduler - Got job 40 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:12] INFO  DAGScheduler - Final stage: ResultStage 63 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:12] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 62)
[2025-10-03 20:39:12] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:12] INFO  DAGScheduler - Submitting ResultStage 63 (MapPartitionsRDD[131] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:12] INFO  MemoryStore - Block broadcast_51 stored as values in memory (estimated size 43.7 KiB, free 2.1 GiB)
[2025-10-03 20:39:12] INFO  MemoryStore - Block broadcast_51_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 2.1 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Added broadcast_51_piece0 in memory on DESKTOP-618L1DH:59062 (size: 19.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  SparkContext - Created broadcast 51 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:12] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[131] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:12] INFO  TaskSchedulerImpl - Adding task set 63.0 with 1 tasks resource profile 0
[2025-10-03 20:39:12] INFO  TaskSetManager - Starting task 0.0 in stage 63.0 (TID 40) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:12] INFO  Executor - Running task 0.0 in stage 63.0 (TID 40)
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (99.6 KiB) non-empty blocks including 1 (99.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:12] INFO  Executor - Finished task 0.0 in stage 63.0 (TID 40). 16283 bytes result sent to driver
[2025-10-03 20:39:12] INFO  TaskSetManager - Finished task 0.0 in stage 63.0 (TID 40) in 27 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:12] INFO  TaskSchedulerImpl - Removed TaskSet 63.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:12] INFO  DAGScheduler - ResultStage 63 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.036 s
[2025-10-03 20:39:12] INFO  DAGScheduler - Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:12] INFO  TaskSchedulerImpl - Killing all running tasks in stage 63: Stage finished
[2025-10-03 20:39:12] INFO  DAGScheduler - Job 40 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.042002 s
[2025-10-03 20:39:12] INFO  MemoryStore - Block broadcast_52 stored as values in memory (estimated size 8.1 MiB, free 2.1 GiB)
[2025-10-03 20:39:12] INFO  MemoryStore - Block broadcast_52_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 2.1 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Added broadcast_52_piece0 in memory on DESKTOP-618L1DH:59062 (size: 29.0 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  SparkContext - Created broadcast 52 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Removed broadcast_47_piece0 on DESKTOP-618L1DH:59062 in memory (size: 19.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Removed broadcast_51_piece0 on DESKTOP-618L1DH:59062 in memory (size: 19.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Removed broadcast_49_piece0 on DESKTOP-618L1DH:59062 in memory (size: 4.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:12] INFO  Executor - Finished task 0.0 in stage 53.0 (TID 33). 1949 bytes result sent to driver
[2025-10-03 20:39:12] INFO  TaskSetManager - Finished task 0.0 in stage 53.0 (TID 33) in 924 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:12] INFO  TaskSchedulerImpl - Removed TaskSet 53.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:12] INFO  DAGScheduler - ShuffleMapStage 53 (save at DataTransformation.java:131) finished in 0.934 s
[2025-10-03 20:39:12] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:12] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:12] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:12] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:12] INFO  ShufflePartitionsUtil - For shuffle(18, 21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:12] INFO  SparkContext - Starting job: save at DataTransformation.java:131
[2025-10-03 20:39:12] INFO  DAGScheduler - Got job 41 (save at DataTransformation.java:131) with 3 output partitions
[2025-10-03 20:39:12] INFO  DAGScheduler - Final stage: ResultStage 66 (save at DataTransformation.java:131)
[2025-10-03 20:39:12] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 64, ShuffleMapStage 65)
[2025-10-03 20:39:12] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:12] INFO  DAGScheduler - Submitting ResultStage 66 (MapPartitionsRDD[140] at save at DataTransformation.java:131), which has no missing parents
[2025-10-03 20:39:12] INFO  MemoryStore - Block broadcast_53 stored as values in memory (estimated size 107.7 KiB, free 2.1 GiB)
[2025-10-03 20:39:12] INFO  MemoryStore - Block broadcast_53_piece0 stored as bytes in memory (estimated size 41.2 KiB, free 2.1 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Added broadcast_53_piece0 in memory on DESKTOP-618L1DH:59062 (size: 41.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  SparkContext - Created broadcast 53 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:12] INFO  DAGScheduler - Submitting 3 missing tasks from ResultStage 66 (MapPartitionsRDD[140] at save at DataTransformation.java:131) (first 15 tasks are for partitions Vector(0, 1, 2))
[2025-10-03 20:39:12] INFO  TaskSchedulerImpl - Adding task set 66.0 with 3 tasks resource profile 0
[2025-10-03 20:39:12] INFO  TaskSetManager - Starting task 0.0 in stage 66.0 (TID 41) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9281 bytes) 
[2025-10-03 20:39:12] INFO  TaskSetManager - Starting task 1.0 in stage 66.0 (TID 42) (DESKTOP-618L1DH, executor driver, partition 1, NODE_LOCAL, 9281 bytes) 
[2025-10-03 20:39:12] INFO  TaskSetManager - Starting task 2.0 in stage 66.0 (TID 43) (DESKTOP-618L1DH, executor driver, partition 2, NODE_LOCAL, 9281 bytes) 
[2025-10-03 20:39:12] INFO  Executor - Running task 1.0 in stage 66.0 (TID 42)
[2025-10-03 20:39:12] INFO  Executor - Running task 0.0 in stage 66.0 (TID 41)
[2025-10-03 20:39:12] INFO  Executor - Running task 2.0 in stage 66.0 (TID 43)
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (1641.5 KiB) non-empty blocks including 1 (1641.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (1034.7 KiB) non-empty blocks including 1 (1034.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (1267.1 KiB) non-empty blocks including 1 (1267.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (432.0 B) non-empty blocks including 1 (432.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (288.0 B) non-empty blocks including 1 (288.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Getting 1 (792.0 B) non-empty blocks including 1 (792.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:12] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:12] INFO  CodeGenerator - Code generated in 39.4755 ms
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Removed broadcast_42_piece0 on DESKTOP-618L1DH:59062 in memory (size: 10.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Removed broadcast_44_piece0 on DESKTOP-618L1DH:59062 in memory (size: 17.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Removed broadcast_36_piece0 on DESKTOP-618L1DH:59062 in memory (size: 643.0 B, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Removed broadcast_5_piece0 on DESKTOP-618L1DH:59062 in memory (size: 1221.0 B, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Removed broadcast_38_piece0 on DESKTOP-618L1DH:59062 in memory (size: 6.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Removed broadcast_30_piece0 on DESKTOP-618L1DH:59062 in memory (size: 10.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Removed broadcast_46_piece0 on DESKTOP-618L1DH:59062 in memory (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:12] INFO  BlockManagerInfo - Removed broadcast_40_piece0 on DESKTOP-618L1DH:59062 in memory (size: 29.0 KiB, free: 2.2 GiB)
[2025-10-03 20:39:18] INFO  Executor - Finished task 1.0 in stage 66.0 (TID 42). 12493 bytes result sent to driver
[2025-10-03 20:39:18] INFO  TaskSetManager - Finished task 1.0 in stage 66.0 (TID 42) in 6306 ms on DESKTOP-618L1DH (executor driver) (1/3)
[2025-10-03 20:39:19] INFO  Executor - Finished task 0.0 in stage 66.0 (TID 41). 12493 bytes result sent to driver
[2025-10-03 20:39:19] INFO  TaskSetManager - Finished task 0.0 in stage 66.0 (TID 41) in 6809 ms on DESKTOP-618L1DH (executor driver) (2/3)
[2025-10-03 20:39:23] INFO  Executor - Finished task 2.0 in stage 66.0 (TID 43). 12493 bytes result sent to driver
[2025-10-03 20:39:23] INFO  TaskSetManager - Finished task 2.0 in stage 66.0 (TID 43) in 11028 ms on DESKTOP-618L1DH (executor driver) (3/3)
[2025-10-03 20:39:23] INFO  TaskSchedulerImpl - Removed TaskSet 66.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:23] INFO  DAGScheduler - ResultStage 66 (save at DataTransformation.java:131) finished in 11.058 s
[2025-10-03 20:39:23] INFO  DAGScheduler - Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:23] INFO  TaskSchedulerImpl - Killing all running tasks in stage 66: Stage finished
[2025-10-03 20:39:23] INFO  DAGScheduler - Job 41 finished: save at DataTransformation.java:131, took 11.060966 s
[2025-10-03 20:39:23] INFO  DataTransformation - Table fact_flight_performance written to DB
[2025-10-03 20:39:23] INFO  DataTransformation - Fact table written successfully
[2025-10-03 20:39:23] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-03 20:39:23] INFO  AbstractConnector - Stopped Spark@45cd7bc5{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 20:39:23] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-03 20:39:23] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-03 20:39:23] INFO  MemoryStore - MemoryStore cleared
[2025-10-03 20:39:23] INFO  BlockManager - BlockManager stopped
[2025-10-03 20:39:23] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-03 20:39:23] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-03 20:39:23] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-03 20:39:23] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-03 20:39:23] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-b4d76faa-0dd7-4863-ba49-f5eb94717d00
[2025-10-03 20:39:31] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-03 20:39:31] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-03 20:39:31] INFO  SparkContext - Java version 11.0.27
[2025-10-03 20:39:31] INFO  ResourceUtils - ==============================================================
[2025-10-03 20:39:31] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-03 20:39:31] INFO  ResourceUtils - ==============================================================
[2025-10-03 20:39:31] INFO  SparkContext - Submitted application: Fact Loader
[2025-10-03 20:39:31] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-03 20:39:31] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-03 20:39:31] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-03 20:39:31] INFO  SecurityManager - Changing view acls to: USER
[2025-10-03 20:39:31] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-03 20:39:31] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-03 20:39:31] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-03 20:39:31] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-03 20:39:32] INFO  Utils - Successfully started service 'sparkDriver' on port 59139.
[2025-10-03 20:39:32] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-03 20:39:32] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-03 20:39:32] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-03 20:39:32] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-03 20:39:32] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-03 20:39:32] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-a5665a20-1199-4daa-8cb0-fa5cbd1b8129
[2025-10-03 20:39:33] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-03 20:39:33] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-03 20:39:33] INFO  log - Logging initialized @3205ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-03 20:39:33] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-03 20:39:33] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-03 20:39:33] INFO  Server - Started @3382ms
[2025-10-03 20:39:33] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 20:39:33] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@36c281ed{/,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-03 20:39:33] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-03 20:39:33] INFO  Executor - Java version 11.0.27
[2025-10-03 20:39:33] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-03 20:39:33] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@ceddaf8 for default.
[2025-10-03 20:39:33] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59186.
[2025-10-03 20:39:33] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:59186
[2025-10-03 20:39:33] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-03 20:39:33] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 59186, None)
[2025-10-03 20:39:33] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:59186 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 59186, None)
[2025-10-03 20:39:33] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 59186, None)
[2025-10-03 20:39:33] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 59186, None)
[2025-10-03 20:39:33] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@36c281ed{/,null,STOPPED,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6cfbbff7{/jobs,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@45b32dfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@14c141c0{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@d611f1c{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@51fc862e{/stages,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@fe09383{/stages/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@f25f48a{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b2e5c0d{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5438c17a{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@429aeac1{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6b4fc2d1{/storage,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de4285e{/storage/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@634ff56{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5a484ce1{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2ffe243f{/environment,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4099209b{/environment/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1dad01fe{/executors,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3e3cd6fe{/executors/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@68b734a8{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4215e133{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@d88f893{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@48eaf42f{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2091833{/static,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1084ac45{/,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6ea246af{/api,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@17e0933c{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1dcedc93{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@38291795{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  SQLQueries - Loading table: fact_flight_performance
[2025-10-03 20:39:33] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-03 20:39:33] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6d6ac396{/SQL,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@f5a7226{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@100ad67e{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@62aeddc8{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-03 20:39:33] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@35bfa1bb{/static/sql,null,AVAILABLE,@Spark}
[2025-10-03 20:39:35] INFO  SQLQueries - Loading table: dim_carrier
[2025-10-03 20:39:36] INFO  SQLQueries - Loading table: dim_airport
[2025-10-03 20:39:36] INFO  SQLQueries - Task 6.1 - % of delayed flights
[2025-10-03 20:39:37] INFO  CodeGenerator - Code generated in 190.8893 ms
[2025-10-03 20:39:37] INFO  DAGScheduler - Registering RDD 2 (collectAsList at SQLQueries.java:154) as input to shuffle 0
[2025-10-03 20:39:37] INFO  DAGScheduler - Got map stage job 0 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:37] INFO  DAGScheduler - Final stage: ShuffleMapStage 0 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:37] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:37] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:37] INFO  DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:37] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 17.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:37] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 2.2 GiB)
[2025-10-03 20:39:37] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on DESKTOP-618L1DH:59186 (size: 8.5 KiB, free: 2.2 GiB)
[2025-10-03 20:39:37] INFO  SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:37] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:37] INFO  TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
[2025-10-03 20:39:38] INFO  TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:38] INFO  Executor - Running task 0.0 in stage 0.0 (TID 0)
[2025-10-03 20:39:38] INFO  CodeGenerator - Code generated in 19.4229 ms
[2025-10-03 20:39:38] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:38] INFO  Executor - Finished task 0.0 in stage 0.0 (TID 0). 1931 bytes result sent to driver
[2025-10-03 20:39:38] INFO  TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 406 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:38] INFO  TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:38] INFO  DAGScheduler - ShuffleMapStage 0 (collectAsList at SQLQueries.java:154) finished in 0.737 s
[2025-10-03 20:39:38] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:38] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:38] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:38] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:38] INFO  CodeGenerator - Code generated in 52.5868 ms
[2025-10-03 20:39:38] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:38] INFO  DAGScheduler - Got job 1 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:38] INFO  DAGScheduler - Final stage: ResultStage 2 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:38] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
[2025-10-03 20:39:38] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:38] INFO  DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[5] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:38] INFO  MemoryStore - Block broadcast_1 stored as values in memory (estimated size 17.4 KiB, free 2.2 GiB)
[2025-10-03 20:39:38] INFO  MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 2.2 GiB)
[2025-10-03 20:39:38] INFO  BlockManagerInfo - Added broadcast_1_piece0 in memory on DESKTOP-618L1DH:59186 (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:38] INFO  SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:38] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:38] INFO  TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
[2025-10-03 20:39:38] INFO  TaskSetManager - Starting task 0.0 in stage 2.0 (TID 1) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:38] INFO  Executor - Running task 0.0 in stage 2.0 (TID 1)
[2025-10-03 20:39:38] INFO  ShuffleBlockFetcherIterator - Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:38] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 22 ms
[2025-10-03 20:39:38] INFO  CodeGenerator - Code generated in 31.487 ms
[2025-10-03 20:39:38] INFO  Executor - Finished task 0.0 in stage 2.0 (TID 1). 4051 bytes result sent to driver
[2025-10-03 20:39:38] INFO  TaskSetManager - Finished task 0.0 in stage 2.0 (TID 1) in 168 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:38] INFO  TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:38] INFO  DAGScheduler - ResultStage 2 (collectAsList at SQLQueries.java:154) finished in 0.187 s
[2025-10-03 20:39:38] INFO  DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:38] INFO  TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
[2025-10-03 20:39:38] INFO  DAGScheduler - Job 1 finished: collectAsList at SQLQueries.java:154, took 0.214190 s
[2025-10-03 20:39:39] INFO  BlockManagerInfo - Removed broadcast_0_piece0 on DESKTOP-618L1DH:59186 in memory (size: 8.5 KiB, free: 2.2 GiB)
[2025-10-03 20:39:39] INFO  BlockManagerInfo - Removed broadcast_1_piece0 on DESKTOP-618L1DH:59186 in memory (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:39] INFO  CodeGenerator - Code generated in 12.2546 ms
[2025-10-03 20:39:39] INFO  SQLQueries - [20.19719614257616]
[2025-10-03 20:39:39] INFO  SQLQueries - Task 6.2 - On-time performance by carrier
[2025-10-03 20:39:39] INFO  CodeGenerator - Code generated in 6.9271 ms
[2025-10-03 20:39:39] INFO  DAGScheduler - Registering RDD 9 (collectAsList at SQLQueries.java:154) as input to shuffle 1
[2025-10-03 20:39:39] INFO  DAGScheduler - Got map stage job 2 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:39] INFO  DAGScheduler - Final stage: ShuffleMapStage 3 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:39] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:39] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:39] INFO  DAGScheduler - Submitting ShuffleMapStage 3 (MapPartitionsRDD[9] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:39] INFO  CodeGenerator - Code generated in 10.9324 ms
[2025-10-03 20:39:39] INFO  MemoryStore - Block broadcast_2 stored as values in memory (estimated size 14.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:39] INFO  MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 2.2 GiB)
[2025-10-03 20:39:39] INFO  BlockManagerInfo - Added broadcast_2_piece0 in memory on DESKTOP-618L1DH:59186 (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:39] INFO  SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:39] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[9] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:39] INFO  TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
[2025-10-03 20:39:39] INFO  DAGScheduler - Registering RDD 11 (collectAsList at SQLQueries.java:154) as input to shuffle 2
[2025-10-03 20:39:39] INFO  DAGScheduler - Got map stage job 3 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:39] INFO  TaskSetManager - Starting task 0.0 in stage 3.0 (TID 2) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:39] INFO  DAGScheduler - Final stage: ShuffleMapStage 4 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:39] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:39] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:39] INFO  Executor - Running task 0.0 in stage 3.0 (TID 2)
[2025-10-03 20:39:39] INFO  DAGScheduler - Submitting ShuffleMapStage 4 (MapPartitionsRDD[11] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:39] INFO  MemoryStore - Block broadcast_3 stored as values in memory (estimated size 14.5 KiB, free 2.2 GiB)
[2025-10-03 20:39:39] INFO  MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
[2025-10-03 20:39:39] INFO  BlockManagerInfo - Added broadcast_3_piece0 in memory on DESKTOP-618L1DH:59186 (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:39] INFO  SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:39] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[11] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:39] INFO  TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
[2025-10-03 20:39:39] INFO  TaskSetManager - Starting task 0.0 in stage 4.0 (TID 3) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:39] INFO  Executor - Running task 0.0 in stage 4.0 (TID 3)
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 12.6729 ms
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 13.797 ms
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 10.287 ms
[2025-10-03 20:39:40] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:40] INFO  Executor - Finished task 0.0 in stage 4.0 (TID 3). 1906 bytes result sent to driver
[2025-10-03 20:39:40] INFO  TaskSetManager - Finished task 0.0 in stage 4.0 (TID 3) in 244 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:40] INFO  TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:40] INFO  DAGScheduler - ShuffleMapStage 4 (collectAsList at SQLQueries.java:154) finished in 0.264 s
[2025-10-03 20:39:40] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:40] INFO  DAGScheduler - running: Set(ShuffleMapStage 3)
[2025-10-03 20:39:40] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:40] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:40] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:40] INFO  Executor - Finished task 0.0 in stage 3.0 (TID 2). 1906 bytes result sent to driver
[2025-10-03 20:39:40] INFO  TaskSetManager - Finished task 0.0 in stage 3.0 (TID 2) in 370 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:40] INFO  TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:40] INFO  DAGScheduler - ShuffleMapStage 3 (collectAsList at SQLQueries.java:154) finished in 0.395 s
[2025-10-03 20:39:40] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:40] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:40] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:40] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:40] INFO  ShufflePartitionsUtil - For shuffle(1, 2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 94.3132 ms
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 15.098 ms
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 11.4675 ms
[2025-10-03 20:39:40] INFO  DAGScheduler - Registering RDD 18 (collectAsList at SQLQueries.java:154) as input to shuffle 3
[2025-10-03 20:39:40] INFO  DAGScheduler - Got map stage job 4 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:40] INFO  DAGScheduler - Final stage: ShuffleMapStage 7 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:40] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 6)
[2025-10-03 20:39:40] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:40] INFO  DAGScheduler - Submitting ShuffleMapStage 7 (MapPartitionsRDD[18] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:40] INFO  MemoryStore - Block broadcast_4 stored as values in memory (estimated size 62.1 KiB, free 2.2 GiB)
[2025-10-03 20:39:40] INFO  MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.3 KiB, free 2.2 GiB)
[2025-10-03 20:39:40] INFO  BlockManagerInfo - Added broadcast_4_piece0 in memory on DESKTOP-618L1DH:59186 (size: 27.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:40] INFO  SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:40] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[18] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:40] INFO  TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
[2025-10-03 20:39:40] INFO  TaskSetManager - Starting task 0.0 in stage 7.0 (TID 4) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9270 bytes) 
[2025-10-03 20:39:40] INFO  Executor - Running task 0.0 in stage 7.0 (TID 4)
[2025-10-03 20:39:40] INFO  ShuffleBlockFetcherIterator - Getting 1 (511.2 KiB) non-empty blocks including 1 (511.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:40] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 11.1651 ms
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 21.8313 ms
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 9.6524 ms
[2025-10-03 20:39:40] INFO  ShuffleBlockFetcherIterator - Getting 1 (1738.0 B) non-empty blocks including 1 (1738.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:40] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 14.3377 ms
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 46.6634 ms
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 36.6758 ms
[2025-10-03 20:39:40] INFO  BlockManagerInfo - Removed broadcast_3_piece0 on DESKTOP-618L1DH:59186 in memory (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:40] INFO  BlockManagerInfo - Removed broadcast_2_piece0 on DESKTOP-618L1DH:59186 in memory (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 8.0442 ms
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 5.5677 ms
[2025-10-03 20:39:40] INFO  CodeGenerator - Code generated in 7.7678 ms
[2025-10-03 20:39:41] INFO  Executor - Finished task 0.0 in stage 7.0 (TID 4). 6857 bytes result sent to driver
[2025-10-03 20:39:41] INFO  TaskSetManager - Finished task 0.0 in stage 7.0 (TID 4) in 541 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:41] INFO  TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:41] INFO  DAGScheduler - ShuffleMapStage 7 (collectAsList at SQLQueries.java:154) finished in 0.560 s
[2025-10-03 20:39:41] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:41] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:41] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:41] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:41] INFO  ShufflePartitionsUtil - For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:41] INFO  HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-10-03 20:39:41] INFO  CodeGenerator - Code generated in 18.911 ms
[2025-10-03 20:39:41] INFO  CodeGenerator - Code generated in 6.4283 ms
[2025-10-03 20:39:41] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:41] INFO  DAGScheduler - Got job 5 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:41] INFO  DAGScheduler - Final stage: ResultStage 11 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:41] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 10)
[2025-10-03 20:39:41] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:41] INFO  DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[23] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:41] INFO  MemoryStore - Block broadcast_5 stored as values in memory (estimated size 59.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:41] INFO  MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 26.5 KiB, free 2.2 GiB)
[2025-10-03 20:39:41] INFO  BlockManagerInfo - Added broadcast_5_piece0 in memory on DESKTOP-618L1DH:59186 (size: 26.5 KiB, free: 2.2 GiB)
[2025-10-03 20:39:41] INFO  SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:41] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[23] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:41] INFO  TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
[2025-10-03 20:39:41] INFO  TaskSetManager - Starting task 0.0 in stage 11.0 (TID 5) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:41] INFO  Executor - Running task 0.0 in stage 11.0 (TID 5)
[2025-10-03 20:39:41] INFO  ShuffleBlockFetcherIterator - Getting 1 (2030.0 B) non-empty blocks including 1 (2030.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:41] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:41] INFO  CodeGenerator - Code generated in 24.5022 ms
[2025-10-03 20:39:41] INFO  CodeGenerator - Code generated in 10.1456 ms
[2025-10-03 20:39:41] INFO  Executor - Finished task 0.0 in stage 11.0 (TID 5). 9276 bytes result sent to driver
[2025-10-03 20:39:41] INFO  TaskSetManager - Finished task 0.0 in stage 11.0 (TID 5) in 102 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:41] INFO  TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:41] INFO  DAGScheduler - ResultStage 11 (collectAsList at SQLQueries.java:154) finished in 0.113 s
[2025-10-03 20:39:41] INFO  DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:41] INFO  TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
[2025-10-03 20:39:41] INFO  DAGScheduler - Job 5 finished: collectAsList at SQLQueries.java:154, took 0.122674 s
[2025-10-03 20:39:41] INFO  DAGScheduler - Registering RDD 24 (collectAsList at SQLQueries.java:154) as input to shuffle 4
[2025-10-03 20:39:41] INFO  DAGScheduler - Got map stage job 6 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:41] INFO  DAGScheduler - Final stage: ShuffleMapStage 15 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:41] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 14)
[2025-10-03 20:39:41] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:41] INFO  DAGScheduler - Submitting ShuffleMapStage 15 (MapPartitionsRDD[24] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:41] INFO  MemoryStore - Block broadcast_6 stored as values in memory (estimated size 61.7 KiB, free 2.2 GiB)
[2025-10-03 20:39:41] INFO  MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:41] INFO  BlockManagerInfo - Added broadcast_6_piece0 in memory on DESKTOP-618L1DH:59186 (size: 27.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:41] INFO  SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:41] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[24] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:41] INFO  TaskSchedulerImpl - Adding task set 15.0 with 1 tasks resource profile 0
[2025-10-03 20:39:41] INFO  TaskSetManager - Starting task 0.0 in stage 15.0 (TID 6) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-03 20:39:41] INFO  Executor - Running task 0.0 in stage 15.0 (TID 6)
[2025-10-03 20:39:41] INFO  CodeGenerator - Code generated in 8.8439 ms
[2025-10-03 20:39:41] INFO  ShuffleBlockFetcherIterator - Getting 1 (2030.0 B) non-empty blocks including 1 (2030.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:41] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:41] INFO  Executor - Finished task 0.0 in stage 15.0 (TID 6). 8256 bytes result sent to driver
[2025-10-03 20:39:41] INFO  TaskSetManager - Finished task 0.0 in stage 15.0 (TID 6) in 199 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:41] INFO  TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:41] INFO  DAGScheduler - ShuffleMapStage 15 (collectAsList at SQLQueries.java:154) finished in 0.235 s
[2025-10-03 20:39:41] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:41] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:41] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:41] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:41] INFO  ShufflePartitionsUtil - For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:41] INFO  CodeGenerator - Code generated in 8.332 ms
[2025-10-03 20:39:41] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:41] INFO  DAGScheduler - Got job 7 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:41] INFO  DAGScheduler - Final stage: ResultStage 20 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:41] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 19)
[2025-10-03 20:39:41] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:41] INFO  DAGScheduler - Submitting ResultStage 20 (MapPartitionsRDD[27] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:41] INFO  MemoryStore - Block broadcast_7 stored as values in memory (estimated size 53.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:41] INFO  MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 2.2 GiB)
[2025-10-03 20:39:41] INFO  BlockManagerInfo - Added broadcast_7_piece0 in memory on DESKTOP-618L1DH:59186 (size: 24.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:41] INFO  SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:41] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[27] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:41] INFO  TaskSchedulerImpl - Adding task set 20.0 with 1 tasks resource profile 0
[2025-10-03 20:39:41] INFO  TaskSetManager - Starting task 0.0 in stage 20.0 (TID 7) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:41] INFO  Executor - Running task 0.0 in stage 20.0 (TID 7)
[2025-10-03 20:39:41] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.6 KiB) non-empty blocks including 1 (2.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:41] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:41] INFO  CodeGenerator - Code generated in 6.9538 ms
[2025-10-03 20:39:41] INFO  CodeGenerator - Code generated in 6.9226 ms
[2025-10-03 20:39:41] INFO  CodeGenerator - Code generated in 9.2283 ms
[2025-10-03 20:39:41] INFO  Executor - Finished task 0.0 in stage 20.0 (TID 7). 10543 bytes result sent to driver
[2025-10-03 20:39:41] INFO  TaskSetManager - Finished task 0.0 in stage 20.0 (TID 7) in 62 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:41] INFO  TaskSchedulerImpl - Removed TaskSet 20.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:41] INFO  DAGScheduler - ResultStage 20 (collectAsList at SQLQueries.java:154) finished in 0.076 s
[2025-10-03 20:39:41] INFO  DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:41] INFO  TaskSchedulerImpl - Killing all running tasks in stage 20: Stage finished
[2025-10-03 20:39:41] INFO  DAGScheduler - Job 7 finished: collectAsList at SQLQueries.java:154, took 0.086100 s
[2025-10-03 20:39:41] INFO  CodeGenerator - Code generated in 11.7031 ms
[2025-10-03 20:39:41] INFO  SQLQueries - [FRONTIER AIRLINES INC.,134798,469465,28.71310960348482]
[2025-10-03 20:39:41] INFO  SQLQueries - [JETBLUE AIRWAYS,166188,611706,27.16795323243519]
[2025-10-03 20:39:41] INFO  SQLQueries - [SPIRIT AIRLINES,153800,614625,25.02338824486475]
[2025-10-03 20:39:41] INFO  SQLQueries - [AMERICAN AIRLINES INC.,555237,2320721,23.92519393757371]
[2025-10-03 20:39:41] INFO  SQLQueries - [ALLEGIANT AIR,66907,286825,23.32676719253900]
[2025-10-03 20:39:41] INFO  SQLQueries - [AIR WISCONSIN AIRLINES CORP,28051,121114,23.16082368677444]
[2025-10-03 20:39:41] INFO  SQLQueries - [PSA AIRLINES INC.,108984,528192,20.63340603416939]
[2025-10-03 20:39:41] INFO  SQLQueries - [SOUTHWEST AIRLINES CO.,702221,3423263,20.51320625964175]
[2025-10-03 20:39:41] INFO  SQLQueries - [ALASKA AIRLINES INC.,119750,585342,20.45812533527408]
[2025-10-03 20:39:41] INFO  SQLQueries - [MESA AIRLINES INC.,43553,213281,20.42047814854582]
[2025-10-03 20:39:41] INFO  SQLQueries - [UNITED AIRLINES INC.,357510,1811355,19.73715809435478]
[2025-10-03 20:39:41] INFO  SQLQueries - [GOJET AIRLINES LLC D/B/A UNITED EXPRESS,24900,128046,19.44613654467926]
[2025-10-03 20:39:41] INFO  SQLQueries - [ENVOY AIR,121004,623120,19.41905250994993]
[2025-10-03 20:39:41] INFO  SQLQueries - [HAWAIIAN AIRLINES INC.,36053,192555,18.72348160265898]
[2025-10-03 20:39:41] INFO  SQLQueries - [SKYWEST AIRLINES INC.,314058,1757526,17.86932312807890]
[2025-10-03 20:39:41] INFO  SQLQueries - [DELTA AIRLINES INC.,410005,2400405,17.08065930540888]
[2025-10-03 20:39:41] INFO  SQLQueries - [COMMUTEAIR LLC DBA COMMUTEAIR,29666,176790,16.78036088014028]
[2025-10-03 20:39:41] INFO  SQLQueries - [ENDEAVOR AIR INC.,78713,498682,15.78420717010038]
[2025-10-03 20:39:41] INFO  SQLQueries - [PIEDMONT AIRLINES,42639,271336,15.71446472270543]
[2025-10-03 20:39:41] INFO  SQLQueries - [HORIZON AIR,29214,190509,15.33470859644426]
[2025-10-03 20:39:41] INFO  SQLQueries - [REPUBLIC AIRLINE,104347,736041,14.17679178197954]
[2025-10-03 20:39:41] INFO  SQLQueries - Task 6.3 - On-time performance by airport
[2025-10-03 20:39:42] INFO  DAGScheduler - Registering RDD 31 (collectAsList at SQLQueries.java:154) as input to shuffle 5
[2025-10-03 20:39:42] INFO  DAGScheduler - Got map stage job 8 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:42] INFO  DAGScheduler - Final stage: ShuffleMapStage 21 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:42] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:42] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:42] INFO  DAGScheduler - Submitting ShuffleMapStage 21 (MapPartitionsRDD[31] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:42] INFO  MemoryStore - Block broadcast_8 stored as values in memory (estimated size 14.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:42] INFO  MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 2.2 GiB)
[2025-10-03 20:39:42] INFO  BlockManagerInfo - Added broadcast_8_piece0 in memory on DESKTOP-618L1DH:59186 (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:42] INFO  SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:42] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[31] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:42] INFO  TaskSchedulerImpl - Adding task set 21.0 with 1 tasks resource profile 0
[2025-10-03 20:39:42] INFO  DAGScheduler - Registering RDD 33 (collectAsList at SQLQueries.java:154) as input to shuffle 6
[2025-10-03 20:39:42] INFO  TaskSetManager - Starting task 0.0 in stage 21.0 (TID 8) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:42] INFO  DAGScheduler - Got map stage job 9 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:42] INFO  DAGScheduler - Final stage: ShuffleMapStage 22 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:42] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:42] INFO  Executor - Running task 0.0 in stage 21.0 (TID 8)
[2025-10-03 20:39:42] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:42] INFO  DAGScheduler - Submitting ShuffleMapStage 22 (MapPartitionsRDD[33] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:42] INFO  MemoryStore - Block broadcast_9 stored as values in memory (estimated size 14.5 KiB, free 2.2 GiB)
[2025-10-03 20:39:42] INFO  MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
[2025-10-03 20:39:42] INFO  BlockManagerInfo - Added broadcast_9_piece0 in memory on DESKTOP-618L1DH:59186 (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:42] INFO  SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:42] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[33] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:42] INFO  TaskSchedulerImpl - Adding task set 22.0 with 1 tasks resource profile 0
[2025-10-03 20:39:42] INFO  TaskSetManager - Starting task 0.0 in stage 22.0 (TID 9) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:42] INFO  Executor - Running task 0.0 in stage 22.0 (TID 9)
[2025-10-03 20:39:42] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:42] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:42] INFO  Executor - Finished task 0.0 in stage 22.0 (TID 9). 1906 bytes result sent to driver
[2025-10-03 20:39:42] INFO  TaskSetManager - Finished task 0.0 in stage 22.0 (TID 9) in 529 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:42] INFO  TaskSchedulerImpl - Removed TaskSet 22.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:42] INFO  DAGScheduler - ShuffleMapStage 22 (collectAsList at SQLQueries.java:154) finished in 0.542 s
[2025-10-03 20:39:42] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:42] INFO  DAGScheduler - running: Set(ShuffleMapStage 21)
[2025-10-03 20:39:42] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:42] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:42] INFO  ShufflePartitionsUtil - For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:42] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:42] INFO  DAGScheduler - Got job 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-03 20:39:42] INFO  DAGScheduler - Final stage: ResultStage 24 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-03 20:39:42] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 23)
[2025-10-03 20:39:42] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:42] INFO  DAGScheduler - Submitting ResultStage 24 (MapPartitionsRDD[35] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-03 20:39:42] INFO  MemoryStore - Block broadcast_10 stored as values in memory (estimated size 8.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:42] INFO  MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:42] INFO  BlockManagerInfo - Added broadcast_10_piece0 in memory on DESKTOP-618L1DH:59186 (size: 4.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:42] INFO  SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:42] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[35] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:42] INFO  TaskSchedulerImpl - Adding task set 24.0 with 1 tasks resource profile 0
[2025-10-03 20:39:42] INFO  Executor - Finished task 0.0 in stage 21.0 (TID 8). 1906 bytes result sent to driver
[2025-10-03 20:39:42] INFO  TaskSetManager - Starting task 0.0 in stage 24.0 (TID 10) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9018 bytes) 
[2025-10-03 20:39:42] INFO  Executor - Running task 0.0 in stage 24.0 (TID 10)
[2025-10-03 20:39:42] INFO  TaskSetManager - Finished task 0.0 in stage 21.0 (TID 8) in 705 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:42] INFO  TaskSchedulerImpl - Removed TaskSet 21.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:42] INFO  DAGScheduler - ShuffleMapStage 21 (collectAsList at SQLQueries.java:154) finished in 0.719 s
[2025-10-03 20:39:42] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:42] INFO  DAGScheduler - running: Set(ResultStage 24)
[2025-10-03 20:39:42] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:42] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:42] INFO  ShuffleBlockFetcherIterator - Getting 1 (25.5 KiB) non-empty blocks including 1 (25.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:42] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-03 20:39:42] INFO  Executor - Finished task 0.0 in stage 24.0 (TID 10). 13882 bytes result sent to driver
[2025-10-03 20:39:42] INFO  TaskSetManager - Finished task 0.0 in stage 24.0 (TID 10) in 31 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:42] INFO  TaskSchedulerImpl - Removed TaskSet 24.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:42] INFO  DAGScheduler - ResultStage 24 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.046 s
[2025-10-03 20:39:42] INFO  DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:42] INFO  TaskSchedulerImpl - Killing all running tasks in stage 24: Stage finished
[2025-10-03 20:39:42] INFO  DAGScheduler - Job 10 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.059387 s
[2025-10-03 20:39:42] INFO  CodeGenerator - Code generated in 9.001 ms
[2025-10-03 20:39:42] INFO  MemoryStore - Block broadcast_11 stored as values in memory (estimated size 1026.9 KiB, free 2.2 GiB)
[2025-10-03 20:39:42] INFO  MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 11.3 KiB, free 2.2 GiB)
[2025-10-03 20:39:42] INFO  BlockManagerInfo - Added broadcast_11_piece0 in memory on DESKTOP-618L1DH:59186 (size: 11.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:42] INFO  SparkContext - Created broadcast 11 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-03 20:39:42] INFO  ShufflePartitionsUtil - For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:43] INFO  CodeGenerator - Code generated in 37.6224 ms
[2025-10-03 20:39:43] INFO  DAGScheduler - Registering RDD 38 (collectAsList at SQLQueries.java:154) as input to shuffle 7
[2025-10-03 20:39:43] INFO  DAGScheduler - Got map stage job 11 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:43] INFO  DAGScheduler - Final stage: ShuffleMapStage 26 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:43] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 25)
[2025-10-03 20:39:43] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:43] INFO  DAGScheduler - Submitting ShuffleMapStage 26 (MapPartitionsRDD[38] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:43] INFO  MemoryStore - Block broadcast_12 stored as values in memory (estimated size 56.0 KiB, free 2.2 GiB)
[2025-10-03 20:39:43] INFO  MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 25.1 KiB, free 2.2 GiB)
[2025-10-03 20:39:43] INFO  BlockManagerInfo - Added broadcast_12_piece0 in memory on DESKTOP-618L1DH:59186 (size: 25.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:43] INFO  SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:43] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[38] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:43] INFO  TaskSchedulerImpl - Adding task set 26.0 with 1 tasks resource profile 0
[2025-10-03 20:39:43] INFO  TaskSetManager - Starting task 0.0 in stage 26.0 (TID 11) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9007 bytes) 
[2025-10-03 20:39:43] INFO  Executor - Running task 0.0 in stage 26.0 (TID 11)
[2025-10-03 20:39:43] INFO  ShuffleBlockFetcherIterator - Getting 1 (580.9 KiB) non-empty blocks including 1 (580.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:43] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:43] INFO  CodeGenerator - Code generated in 32.5855 ms
[2025-10-03 20:39:43] INFO  BlockManagerInfo - Removed broadcast_10_piece0 on DESKTOP-618L1DH:59186 in memory (size: 4.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:43] INFO  BlockManagerInfo - Removed broadcast_6_piece0 on DESKTOP-618L1DH:59186 in memory (size: 27.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:43] INFO  BlockManagerInfo - Removed broadcast_9_piece0 on DESKTOP-618L1DH:59186 in memory (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:43] INFO  BlockManagerInfo - Removed broadcast_7_piece0 on DESKTOP-618L1DH:59186 in memory (size: 24.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:43] INFO  BlockManagerInfo - Removed broadcast_5_piece0 on DESKTOP-618L1DH:59186 in memory (size: 26.5 KiB, free: 2.2 GiB)
[2025-10-03 20:39:43] INFO  BlockManagerInfo - Removed broadcast_8_piece0 on DESKTOP-618L1DH:59186 in memory (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:43] INFO  BlockManagerInfo - Removed broadcast_4_piece0 on DESKTOP-618L1DH:59186 in memory (size: 27.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:43] INFO  Executor - Finished task 0.0 in stage 26.0 (TID 11). 6634 bytes result sent to driver
[2025-10-03 20:39:43] INFO  TaskSetManager - Finished task 0.0 in stage 26.0 (TID 11) in 593 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:43] INFO  TaskSchedulerImpl - Removed TaskSet 26.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:43] INFO  DAGScheduler - ShuffleMapStage 26 (collectAsList at SQLQueries.java:154) finished in 0.604 s
[2025-10-03 20:39:43] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:43] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:43] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:43] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:43] INFO  ShufflePartitionsUtil - For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:43] INFO  HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-10-03 20:39:43] INFO  CodeGenerator - Code generated in 18.2953 ms
[2025-10-03 20:39:43] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:43] INFO  DAGScheduler - Got job 12 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:43] INFO  DAGScheduler - Final stage: ResultStage 29 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:43] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 28)
[2025-10-03 20:39:43] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:43] INFO  DAGScheduler - Submitting ResultStage 29 (MapPartitionsRDD[43] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:43] INFO  MemoryStore - Block broadcast_13 stored as values in memory (estimated size 60.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:43] INFO  MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 26.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:43] INFO  BlockManagerInfo - Added broadcast_13_piece0 in memory on DESKTOP-618L1DH:59186 (size: 26.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:43] INFO  SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:43] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[43] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:43] INFO  TaskSchedulerImpl - Adding task set 29.0 with 1 tasks resource profile 0
[2025-10-03 20:39:43] INFO  TaskSetManager - Starting task 0.0 in stage 29.0 (TID 12) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:43] INFO  Executor - Running task 0.0 in stage 29.0 (TID 12)
[2025-10-03 20:39:43] INFO  ShuffleBlockFetcherIterator - Getting 1 (28.0 KiB) non-empty blocks including 1 (28.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:43] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:43] INFO  CodeGenerator - Code generated in 18.7706 ms
[2025-10-03 20:39:43] INFO  Executor - Finished task 0.0 in stage 29.0 (TID 12). 25946 bytes result sent to driver
[2025-10-03 20:39:43] INFO  TaskSetManager - Finished task 0.0 in stage 29.0 (TID 12) in 61 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:43] INFO  TaskSchedulerImpl - Removed TaskSet 29.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:43] INFO  DAGScheduler - ResultStage 29 (collectAsList at SQLQueries.java:154) finished in 0.071 s
[2025-10-03 20:39:43] INFO  DAGScheduler - Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:43] INFO  TaskSchedulerImpl - Killing all running tasks in stage 29: Stage finished
[2025-10-03 20:39:43] INFO  DAGScheduler - Job 12 finished: collectAsList at SQLQueries.java:154, took 0.079624 s
[2025-10-03 20:39:43] INFO  DAGScheduler - Registering RDD 44 (collectAsList at SQLQueries.java:154) as input to shuffle 8
[2025-10-03 20:39:43] INFO  DAGScheduler - Got map stage job 13 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:43] INFO  DAGScheduler - Final stage: ShuffleMapStage 32 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:43] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 31)
[2025-10-03 20:39:43] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:43] INFO  DAGScheduler - Submitting ShuffleMapStage 32 (MapPartitionsRDD[44] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:43] INFO  MemoryStore - Block broadcast_14 stored as values in memory (estimated size 70.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:43] INFO  MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 2.2 GiB)
[2025-10-03 20:39:43] INFO  BlockManagerInfo - Added broadcast_14_piece0 in memory on DESKTOP-618L1DH:59186 (size: 30.0 KiB, free: 2.2 GiB)
[2025-10-03 20:39:43] INFO  SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:43] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[44] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:43] INFO  TaskSchedulerImpl - Adding task set 32.0 with 1 tasks resource profile 0
[2025-10-03 20:39:43] INFO  TaskSetManager - Starting task 0.0 in stage 32.0 (TID 13) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-03 20:39:43] INFO  Executor - Running task 0.0 in stage 32.0 (TID 13)
[2025-10-03 20:39:43] INFO  ShuffleBlockFetcherIterator - Getting 1 (28.0 KiB) non-empty blocks including 1 (28.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:43] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:44] INFO  Executor - Finished task 0.0 in stage 32.0 (TID 13). 8215 bytes result sent to driver
[2025-10-03 20:39:44] INFO  TaskSetManager - Finished task 0.0 in stage 32.0 (TID 13) in 488 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:44] INFO  TaskSchedulerImpl - Removed TaskSet 32.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:44] INFO  DAGScheduler - ShuffleMapStage 32 (collectAsList at SQLQueries.java:154) finished in 0.501 s
[2025-10-03 20:39:44] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:44] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:44] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:44] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:44] INFO  ShufflePartitionsUtil - For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:44] INFO  CodeGenerator - Code generated in 13.5233 ms
[2025-10-03 20:39:44] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:44] INFO  DAGScheduler - Got job 14 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:44] INFO  DAGScheduler - Final stage: ResultStage 36 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:44] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 35)
[2025-10-03 20:39:44] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:44] INFO  DAGScheduler - Submitting ResultStage 36 (MapPartitionsRDD[47] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:44] INFO  MemoryStore - Block broadcast_15 stored as values in memory (estimated size 54.4 KiB, free 2.2 GiB)
[2025-10-03 20:39:44] INFO  MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:44] INFO  BlockManagerInfo - Added broadcast_15_piece0 in memory on DESKTOP-618L1DH:59186 (size: 24.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:44] INFO  SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:44] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[47] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:44] INFO  TaskSchedulerImpl - Adding task set 36.0 with 1 tasks resource profile 0
[2025-10-03 20:39:44] INFO  TaskSetManager - Starting task 0.0 in stage 36.0 (TID 14) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:44] INFO  Executor - Running task 0.0 in stage 36.0 (TID 14)
[2025-10-03 20:39:44] INFO  ShuffleBlockFetcherIterator - Getting 1 (37.0 KiB) non-empty blocks including 1 (37.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:44] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:44] INFO  CodeGenerator - Code generated in 8.094 ms
[2025-10-03 20:39:44] INFO  Executor - Finished task 0.0 in stage 36.0 (TID 14). 27873 bytes result sent to driver
[2025-10-03 20:39:44] INFO  TaskSetManager - Finished task 0.0 in stage 36.0 (TID 14) in 28 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:44] INFO  TaskSchedulerImpl - Removed TaskSet 36.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:44] INFO  DAGScheduler - ResultStage 36 (collectAsList at SQLQueries.java:154) finished in 0.038 s
[2025-10-03 20:39:44] INFO  DAGScheduler - Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:44] INFO  TaskSchedulerImpl - Killing all running tasks in stage 36: Stage finished
[2025-10-03 20:39:44] INFO  DAGScheduler - Job 14 finished: collectAsList at SQLQueries.java:154, took 0.052174 s
[2025-10-03 20:39:44] INFO  SQLQueries - [JACK EDWARDS NATIONAL AIRPORT,7,19,36.84210526315789]
[2025-10-03 20:39:44] INFO  SQLQueries - [PONCE, PR: MERCEDITA,772,2259,34.17441345728198]
[2025-10-03 20:39:44] INFO  SQLQueries - [AGUADILLA, PR: RAFAEL HERNANDEZ,2066,6277,32.91381233073124]
[2025-10-03 20:39:44] INFO  SQLQueries - [PROVO-UTAH LAKE INTERNATIONAL AIRPORT,1820,5563,32.71616034513752]
[2025-10-03 20:39:44] INFO  SQLQueries - [ORLANDO SANFORD INTERNATIONAL AIRPORT,6542,23059,28.37070124463333]
[2025-10-03 20:39:44] INFO  SQLQueries - [HAGERSTOWN REGIONAL RICHARD A HENSON FIELD,170,609,27.91461412151067]
[2025-10-03 20:39:44] INFO  SQLQueries - [SAN JUAN, PR: LUIS MUNOZ MARIN INTERNATIONAL,23125,83895,27.56421717623220]
[2025-10-03 20:39:44] INFO  SQLQueries - [CONCORD-PADGETT REGIONAL AIRPORT,485,1760,27.55681818181818]
[2025-10-03 20:39:44] INFO  SQLQueries - [ASPEN-PITKIN COUNTY AIRPORT (SARDY FIELD),4950,18067,27.39801848674379]
[2025-10-03 20:39:44] INFO  SQLQueries - [HOUGHTON COUNTY MEMORIAL AIRPORT,473,1737,27.23085780080599]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHIPPEWA VALLEY REGIONAL AIRPORT,79,292,27.05479452054795]
[2025-10-03 20:39:44] INFO  SQLQueries - [TRENTON MERCER AIRPORT,1239,4616,26.84142114384749]
[2025-10-03 20:39:44] INFO  SQLQueries - [PRESQUE ISLE INTERNATIONAL AIRPORT,363,1357,26.75018422991894]
[2025-10-03 20:39:44] INFO  SQLQueries - [PUNTA GORDA AIRPORT,4233,16116,26.26582278481013]
[2025-10-03 20:39:44] INFO  SQLQueries - [STOCKTON METROPOLITAN AIRPORT,319,1240,25.72580645161290]
[2025-10-03 20:39:44] INFO  SQLQueries - [PALM BEACH INTERNATIONAL AIRPORT,18378,71475,25.71248688352571]
[2025-10-03 20:39:44] INFO  SQLQueries - [BISHOP INTERNATIONAL AIRPORT,1891,7382,25.61636412896234]
[2025-10-03 20:39:44] INFO  SQLQueries - [SAN FRANCISCO INTERNATIONAL AIRPORT,84394,334989,25.19306604097448]
[2025-10-03 20:39:44] INFO  SQLQueries - [FORT LAUDERDALE HOLLYWOOD INTERNATIONAL AIRPORT,55335,220499,25.09535190635785]
[2025-10-03 20:39:44] INFO  SQLQueries - [SANTA MARIA PUBLIC AIRPORT CAPTAIN G ALLAN HANCOCK FIELD,64,256,25.00000000000000]
[2025-10-03 20:39:44] INFO  SQLQueries - [FOUR CORNERS REGIONAL AIRPORT,6,24,25.00000000000000]
[2025-10-03 20:39:44] INFO  SQLQueries - [PAGO PAGO, TT: PAGO PAGO INTERNATIONAL,76,306,24.83660130718954]
[2025-10-03 20:39:44] INFO  SQLQueries - [LEA COUNTY REGIONAL AIRPORT,407,1645,24.74164133738602]
[2025-10-03 20:39:44] INFO  SQLQueries - [WILEY POST WILL ROGERS MEMORIAL AIRPORT,237,972,24.38271604938272]
[2025-10-03 20:39:44] INFO  SQLQueries - [ST. PETERSBURG CLEARWATER INTERNATIONAL AIRPORT,4869,20031,24.30732364834507]
[2025-10-03 20:39:44] INFO  SQLQueries - [ORLANDO INTERNATIONAL AIRPORT,95270,392415,24.27786909266975]
[2025-10-03 20:39:44] INFO  SQLQueries - [AKRON CANTON REGIONAL AIRPORT,2055,8596,23.90646812470917]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHRISTIANSTED, VI: HENRY E. ROHLSEN,695,2928,23.73633879781421]
[2025-10-03 20:39:44] INFO  SQLQueries - [LINCOLN AIRPORT,1499,6316,23.73337555414820]
[2025-10-03 20:39:44] INFO  SQLQueries - [LONG ISLAND MAC ARTHUR AIRPORT,2814,11880,23.68686868686869]
[2025-10-03 20:39:44] INFO  SQLQueries - [YELLOWSTONE REGIONAL AIRPORT,487,2068,23.54932301740812]
[2025-10-03 20:39:44] INFO  SQLQueries - [APPLETON INTERNATIONAL AIRPORT,4095,17442,23.47781217750258]
[2025-10-03 20:39:44] INFO  SQLQueries - [WESTCHESTER COUNTY AIRPORT,7106,30355,23.40965244605502]
[2025-10-03 20:39:44] INFO  SQLQueries - [WILKES BARRE SCRANTON INTERNATIONAL AIRPORT,1666,7132,23.35950644980370]
[2025-10-03 20:39:44] INFO  SQLQueries - [TAMPA INTERNATIONAL AIRPORT,44908,192272,23.35649496546559]
[2025-10-03 20:39:44] INFO  SQLQueries - [EASTERN SIERRA REGIONAL AIRPORT,163,701,23.25249643366619]
[2025-10-03 20:39:44] INFO  SQLQueries - [JACKSONVILLE INTERNATIONAL AIRPORT,16770,72698,23.06803488404083]
[2025-10-03 20:39:44] INFO  SQLQueries - [HARRY REID INTERNATIONAL AIRPORT,106470,461852,23.05283943774196]
[2025-10-03 20:39:44] INFO  SQLQueries - [EAGLE COUNTY REGIONAL AIRPORT,2103,9213,22.82644089873006]
[2025-10-03 20:39:44] INFO  SQLQueries - [MIAMI INTERNATIONAL AIRPORT,59802,262331,22.79639081923219]
[2025-10-03 20:39:44] INFO  SQLQueries - [SAN DIEGO INTERNATIONAL AIRPORT,51510,226264,22.76544213838702]
[2025-10-03 20:39:44] INFO  SQLQueries - [CITY OF COLORADO SPRINGS MUNICIPAL AIRPORT,6908,30436,22.69680641345775]
[2025-10-03 20:39:44] INFO  SQLQueries - [LOGAN INTERNATIONAL AIRPORT,77962,345511,22.56425989331743]
[2025-10-03 20:39:44] INFO  SQLQueries - [MCALLEN MILLER INTERNATIONAL AIRPORT,3061,13587,22.52888790755870]
[2025-10-03 20:39:44] INFO  SQLQueries - [WICHITA EISENHOWER NATIONAL AIRPORT,6160,27358,22.51626580890416]
[2025-10-03 20:39:44] INFO  SQLQueries - [BRADLEY INTERNATIONAL AIRPORT,12767,56725,22.50683120317320]
[2025-10-03 20:39:44] INFO  SQLQueries - [SAN ANTONIO INTERNATIONAL AIRPORT,22444,99978,22.44893876652864]
[2025-10-03 20:39:44] INFO  SQLQueries - [SOUTHWEST OREGON REGIONAL AIRPORT,185,825,22.42424242424242]
[2025-10-03 20:39:44] INFO  SQLQueries - [DALLAS FORT WORTH INTERNATIONAL AIRPORT,164622,734327,22.41807804969721]
[2025-10-03 20:39:44] INFO  SQLQueries - [YEAGER AIRPORT,1899,8478,22.39915074309979]
[2025-10-03 20:39:44] INFO  SQLQueries - [BUFFALO NIAGARA INTERNATIONAL AIRPORT,12914,57676,22.39059574172966]
[2025-10-03 20:39:44] INFO  SQLQueries - [NORTH CENTRAL WEST VIRGINIA AIRPORT,111,497,22.33400402414487]
[2025-10-03 20:39:44] INFO  SQLQueries - [LOUIS ARMSTRONG NEW ORLEANS INTERNATIONAL AIRPORT,27502,123279,22.30874682630456]
[2025-10-03 20:39:44] INFO  SQLQueries - [SOUTHWEST FLORIDA INTERNATIONAL AIRPORT,19148,85888,22.29415052160954]
[2025-10-03 20:39:44] INFO  SQLQueries - [DES MOINES INTERNATIONAL AIRPORT,8540,38505,22.17893780028568]
[2025-10-03 20:39:44] INFO  SQLQueries - [PENSACOLA INTERNATIONAL AIRPORT,7233,32723,22.10371909665984]
[2025-10-03 20:39:44] INFO  SQLQueries - [AUSTIN BERGSTROM INTERNATIONAL AIRPORT,47257,214301,22.05169364585326]
[2025-10-03 20:39:44] INFO  SQLQueries - [MEMPHIS INTERNATIONAL AIRPORT,12929,58697,22.02667938736222]
[2025-10-03 20:39:44] INFO  SQLQueries - [ROCHESTER INTERNATIONAL AIRPORT,1099,4996,21.99759807846277]
[2025-10-03 20:39:44] INFO  SQLQueries - [BILL & HILLARY CLINTON NATIONAL AIRPORT/ADAMS FIELD,7583,34554,21.94536088441280]
[2025-10-03 20:39:44] INFO  SQLQueries - [SPRINGFIELD BRANSON NATIONAL AIRPORT,5356,24516,21.84695708924784]
[2025-10-03 20:39:44] INFO  SQLQueries - [ALBANY INTERNATIONAL AIRPORT,8170,37521,21.77447296180805]
[2025-10-03 20:39:44] INFO  SQLQueries - [JOHN F KENNEDY INTERNATIONAL AIRPORT,66721,306626,21.75973335594503]
[2025-10-03 20:39:44] INFO  SQLQueries - [WILL ROGERS WORLD AIRPORT,12565,57759,21.75418549490123]
[2025-10-03 20:39:44] INFO  SQLQueries - [GENERAL MITCHELL INTERNATIONAL AIRPORT,15500,71289,21.74248481532915]
[2025-10-03 20:39:44] INFO  SQLQueries - [SARASOTA BRADENTON INTERNATIONAL AIRPORT,8775,40517,21.65757583236666]
[2025-10-03 20:39:44] INFO  SQLQueries - [RICKENBACKER INTERNATIONAL AIRPORT,510,2355,21.65605095541401]
[2025-10-03 20:39:44] INFO  SQLQueries - [THE EASTERN IOWA AIRPORT,4296,19869,21.62162162162162]
[2025-10-03 20:39:44] INFO  SQLQueries - [FORT DODGE REGIONAL AIRPORT,326,1508,21.61803713527851]
[2025-10-03 20:39:44] INFO  SQLQueries - [SOUTH BEND REGIONAL AIRPORT,3418,15835,21.58509630565204]
[2025-10-03 20:39:44] INFO  SQLQueries - [BIRMINGHAM-SHUTTLESWORTH INTERNATIONAL AIRPORT,9663,44790,21.57401205626256]
[2025-10-03 20:39:44] INFO  SQLQueries - [NEWARK LIBERTY INTERNATIONAL AIRPORT,75019,347746,21.57292966705584]
[2025-10-03 20:39:44] INFO  SQLQueries - [ATLANTIC CITY INTERNATIONAL AIRPORT,1539,7136,21.56670403587444]
[2025-10-03 20:39:44] INFO  SQLQueries - [RICHMOND INTERNATIONAL AIRPORT,12337,57386,21.49827484055345]
[2025-10-03 20:39:44] INFO  SQLQueries - [RALEIGH DURHAM INTERNATIONAL AIRPORT,31661,147317,21.49174908530584]
[2025-10-03 20:39:44] INFO  SQLQueries - [MORGANTOWN MUNICIPAL AIRPORT WALTER L. (BILL) HART FIELD,73,340,21.47058823529412]
[2025-10-03 20:39:44] INFO  SQLQueries - [GENERAL WAYNE A. DOWNING PEORIA INTERNATIONAL AIRPORT,2390,11136,21.46192528735632]
[2025-10-03 20:39:44] INFO  SQLQueries - [MCGHEE TYSON AIRPORT,9724,45309,21.46151978635591]
[2025-10-03 20:39:44] INFO  SQLQueries - [QUAD CITY INTERNATIONAL AIRPORT,2530,11798,21.44431259535514]
[2025-10-03 20:39:44] INFO  SQLQueries - [DANE COUNTY REGIONAL TRUAX FIELD,6623,30887,21.44267814938324]
[2025-10-03 20:39:44] INFO  SQLQueries - [SEATTLE PAINE FIELD INTERNATIONAL AIRPORT,1824,8507,21.44116609850711]
[2025-10-03 20:39:44] INFO  SQLQueries - [EL PASO INTERNATIONAL AIRPORT,10092,47215,21.37456316848459]
[2025-10-03 20:39:44] INFO  SQLQueries - [MBS INTERNATIONAL AIRPORT,1083,5078,21.32729421031902]
[2025-10-03 20:39:44] INFO  SQLQueries - [NORFOLK INTERNATIONAL AIRPORT,11598,54384,21.32612533097970]
[2025-10-03 20:39:44] INFO  SQLQueries - [YAMPA VALLEY AIRPORT,1362,6392,21.30788485607009]
[2025-10-03 20:39:44] INFO  SQLQueries - [THEODORE FRANCIS GREEN STATE AIRPORT,8489,39861,21.29650535611249]
[2025-10-03 20:39:44] INFO  SQLQueries - [LUBBOCK PRESTON SMITH INTERNATIONAL AIRPORT,3680,17306,21.26430139835895]
[2025-10-03 20:39:44] INFO  SQLQueries - [GERALD R. FORD INTERNATIONAL AIRPORT,9765,45962,21.24581175753884]
[2025-10-03 20:39:44] INFO  SQLQueries - [PHILADELPHIA INTERNATIONAL AIRPORT,59166,279423,21.17434856829967]
[2025-10-03 20:39:44] INFO  SQLQueries - [JOHN MURTHA JOHNSTOWN CAMBRIA COUNTY AIRPORT,372,1759,21.14837976122797]
[2025-10-03 20:39:44] INFO  SQLQueries - [COLUMBIA REGIONAL AIRPORT,998,4722,21.13511224057603]
[2025-10-03 20:39:44] INFO  SQLQueries - [CAPITAL CITY AIRPORT,1056,5005,21.09890109890110]
[2025-10-03 20:39:44] INFO  SQLQueries - [EPPLEY AIRFIELD,12111,57480,21.06993736951983]
[2025-10-03 20:39:44] INFO  SQLQueries - [TULSA INTERNATIONAL AIRPORT,9437,44873,21.03046375325920]
[2025-10-03 20:39:44] INFO  SQLQueries - [SALINA MUNICIPAL AIRPORT,373,1774,21.02593010146561]
[2025-10-03 20:39:44] INFO  SQLQueries - [SAVANNAH HILTON HEAD INTERNATIONAL AIRPORT,10401,49503,21.01084782740440]
[2025-10-03 20:39:44] INFO  SQLQueries - [CLEVELAND HOPKINS INTERNATIONAL AIRPORT,21969,104820,20.95878649112765]
[2025-10-03 20:39:44] INFO  SQLQueries - [KANSAS CITY INTERNATIONAL AIRPORT,25623,122285,20.95351024246637]
[2025-10-03 20:39:44] INFO  SQLQueries - [MONTROSE REGIONAL AIRPORT,1462,6992,20.90961098398169]
[2025-10-03 20:39:44] INFO  SQLQueries - [NORTHWEST FLORIDA BEACHES INTERNATIONAL AIRPORT,4353,20854,20.87369329625012]
[2025-10-03 20:39:44] INFO  SQLQueries - [SYRACUSE HANCOCK INTERNATIONAL AIRPORT,8029,38494,20.85779602015899]
[2025-10-03 20:39:44] INFO  SQLQueries - [FRESNO YOSEMITE INTERNATIONAL AIRPORT,5913,28353,20.85493598560999]
[2025-10-03 20:39:44] INFO  SQLQueries - [CINCINNATI NORTHERN KENTUCKY INTERNATIONAL AIRPORT,21606,103613,20.85259571675369]
[2025-10-03 20:39:44] INFO  SQLQueries - [PRESCOTT INTERNATIONAL AIRPORT - ERNEST A. LOVE FIELD,366,1756,20.84282460136674]
[2025-10-03 20:39:44] INFO  SQLQueries - [JAMES M COX DAYTON INTERNATIONAL AIRPORT,5053,24261,20.82766580107992]
[2025-10-03 20:39:44] INFO  SQLQueries - [ASHEVILLE REGIONAL AIRPORT,6257,30107,20.78254226591822]
[2025-10-03 20:39:44] INFO  SQLQueries - [SIOUX GATEWAY AIRPORT / BRIGADIER GENERAL BUD DAY FIELD,365,1758,20.76222980659841]
[2025-10-03 20:39:44] INFO  SQLQueries - [SIOUX FALLS REGIONAL AIRPORT / JOE FOSS FIELD,3997,19258,20.75501090455914]
[2025-10-03 20:39:44] INFO  SQLQueries - [LA CROSSE REGIONAL AIRPORT,484,2343,20.65727699530516]
[2025-10-03 20:39:44] INFO  SQLQueries - [DECATUR AIRPORT,418,2025,20.64197530864198]
[2025-10-03 20:39:44] INFO  SQLQueries - [AUSTIN STRAUBEL INTERNATIONAL AIRPORT,2599,12599,20.62862131915231]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHARLESTON INTERNATIONAL AIRPORT,12901,62664,20.58757819481680]
[2025-10-03 20:39:44] INFO  SQLQueries - [DESTIN-FORT WALTON BEACH AIRPORT,4722,22939,20.58502986180740]
[2025-10-03 20:39:44] INFO  SQLQueries - [ONTARIO INTERNATIONAL AIRPORT,12701,61722,20.57775185509219]
[2025-10-03 20:39:44] INFO  SQLQueries - [FORT WAYNE INTERNATIONAL AIRPORT,3288,15989,20.56413784476828]
[2025-10-03 20:39:44] INFO  SQLQueries - [MESA GATEWAY AIRPORT,2956,14384,20.55061179087875]
[2025-10-03 20:39:44] INFO  SQLQueries - [RONALD REAGAN WASHINGTON NATIONAL AIRPORT,71495,347972,20.54619337188050]
[2025-10-03 20:39:44] INFO  SQLQueries - [MARQUETTE/SAWYER INTERNATIONAL AIRPORT,470,2292,20.50610820244328]
[2025-10-03 20:39:44] INFO  SQLQueries - [KEY FIELD / MERIDIAN REGIONAL AIRPORT,320,1570,20.38216560509554]
[2025-10-03 20:39:44] INFO  SQLQueries - [EUGENE F. KRANZ TOLEDO EXPRESS AIRPORT,198,972,20.37037037037037]
[2025-10-03 20:39:44] INFO  SQLQueries - [CASPER-NATRONA COUNTY INTERNATIONAL AIRPORT,1090,5357,20.34720925891357]
[2025-10-03 20:39:44] INFO  SQLQueries - [ALBUQUERQUE INTERNATIONAL SUNPORT,12133,59752,20.30559646539028]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHERRY CAPITAL AIRPORT,2479,12212,20.29970520799214]
[2025-10-03 20:39:44] INFO  SQLQueries - [WATERLOO REGIONAL AIRPORT,331,1640,20.18292682926829]
[2025-10-03 20:39:44] INFO  SQLQueries - [ABRAHAM LINCOLN CAPITAL AIRPORT,385,1910,20.15706806282723]
[2025-10-03 20:39:44] INFO  SQLQueries - [INDIANAPOLIS INTERNATIONAL AIRPORT,23181,115079,20.14355355885957]
[2025-10-03 20:39:44] INFO  SQLQueries - [SITKA ROCKY GUTIERREZ AIRPORT,667,3312,20.13888888888889]
[2025-10-03 20:39:44] INFO  SQLQueries - [SANTA FE MUNICIPAL AIRPORT,1517,7540,20.11936339522546]
[2025-10-03 20:39:44] INFO  SQLQueries - [JACKSON HOLE AIRPORT,2654,13196,20.11215519854501]
[2025-10-03 20:39:44] INFO  SQLQueries - [SAN LUIS COUNTY REGIONAL AIRPORT,2591,12885,20.10865347303066]
[2025-10-03 20:39:44] INFO  SQLQueries - [DENVER INTERNATIONAL AIRPORT,148452,739089,20.08580833972634]
[2025-10-03 20:39:44] INFO  SQLQueries - [RICK HUSBAND AMARILLO INTERNATIONAL AIRPORT,2846,14174,20.07901792013546]
[2025-10-03 20:39:44] INFO  SQLQueries - [KILLEEN REGIONAL AIRPORT / ROBERT GRAY ARMY AIRFIELD,858,4278,20.05610098176718]
[2025-10-03 20:39:44] INFO  SQLQueries - [MANCHESTER-BOSTON REGIONAL AIRPORT,3521,17563,20.04782781984855]
[2025-10-03 20:39:44] INFO  SQLQueries - [MARTHA'S VINEYARD AIRPORT,453,2263,20.01767565178966]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHICAGO O'HARE INTERNATIONAL AIRPORT,150062,749680,20.01680717105965]
[2025-10-03 20:39:44] INFO  SQLQueries - [FREDERICK DOUGLASS GREATER ROCHESTER INTERNATIONAL AIRPORT,7694,38468,20.00103982530935]
[2025-10-03 20:39:44] INFO  SQLQueries - [ITHACA TOMPKINS REGIONAL AIRPORT,698,3492,19.98854524627721]
[2025-10-03 20:39:44] INFO  SQLQueries - [GARDEN CITY REGIONAL AIRPORT,351,1757,19.97723392145703]
[2025-10-03 20:39:44] INFO  SQLQueries - [ABILENE REGIONAL AIRPORT,767,3849,19.92725383216420]
[2025-10-03 20:39:44] INFO  SQLQueries - [GREENVILLE SPARTANBURG INTERNATIONAL AIRPORT,7779,39064,19.91347532254761]
[2025-10-03 20:39:44] INFO  SQLQueries - [PITTSBURGH INTERNATIONAL AIRPORT,21352,107286,19.90194433570084]
[2025-10-03 20:39:44] INFO  SQLQueries - [TED STEVENS ANCHORAGE INTERNATIONAL AIRPORT,10334,52039,19.85818328561271]
[2025-10-03 20:39:44] INFO  SQLQueries - [LOUISVILLE MUHAMMAD ALI INTERNATIONAL AIRPORT,12443,62774,19.82190078695001]
[2025-10-03 20:39:44] INFO  SQLQueries - [LEHIGH VALLEY INTERNATIONAL AIRPORT,2216,11195,19.79455113890130]
[2025-10-03 20:39:44] INFO  SQLQueries - [JOHN GLENN COLUMBUS INTERNATIONAL AIRPORT,20888,105540,19.79154822815994]
[2025-10-03 20:39:44] INFO  SQLQueries - [SCOTT AFB/MIDAMERICA AIRPORT,513,2599,19.73836090804155]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHARLOTTE DOUGLAS INTERNATIONAL AIRPORT,114355,579930,19.71875916058835]
[2025-10-03 20:39:44] INFO  SQLQueries - [ROANOKE–BLACKSBURG REGIONAL AIRPORT,3233,16408,19.70380302291565]
[2025-10-03 20:39:44] INFO  SQLQueries - [BATON ROUGE METROPOLITAN AIRPORT,3032,15409,19.67681225257966]
[2025-10-03 20:39:44] INFO  SQLQueries - [BOZEMAN YELLOWSTONE INTERNATIONAL AIRPORT,5027,25573,19.65745121808157]
[2025-10-03 20:39:44] INFO  SQLQueries - [CALIFORNIA REDWOOD COAST-HUMBOLDT COUNTY AIRPORT,814,4143,19.64759835867729]
[2025-10-03 20:39:44] INFO  SQLQueries - [TUCSON INTERNATIONAL AIRPORT / MORRIS AIR NATIONAL GUARD BASE,9056,46166,19.61616774249448]
[2025-10-03 20:39:44] INFO  SQLQueries - [DALLAS LOVE FIELD,34705,177019,19.60524011546783]
[2025-10-03 20:39:44] INFO  SQLQueries - [NASHVILLE INTERNATIONAL AIRPORT,47143,240480,19.60370924817033]
[2025-10-03 20:39:44] INFO  SQLQueries - [BLUE GRASS AIRPORT,4561,23310,19.56670956670957]
[2025-10-03 20:39:44] INFO  SQLQueries - [RENO TAHOE INTERNATIONAL AIRPORT,10128,51802,19.55136867302421]
[2025-10-03 20:39:44] INFO  SQLQueries - [KEY WEST INTERNATIONAL AIRPORT,3672,18787,19.54543035077447]
[2025-10-03 20:39:44] INFO  SQLQueries - [LARAMIE REGIONAL AIRPORT,295,1510,19.53642384105960]
[2025-10-03 20:39:44] INFO  SQLQueries - [NORTHWEST ARKANSAS NATIONAL AIRPORT,6926,35471,19.52580981646979]
[2025-10-03 20:39:44] INFO  SQLQueries - [WACO REGIONAL AIRPORT,509,2608,19.51687116564417]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHARLOTTE AMALIE, VI: CYRIL E KING,2471,12685,19.47970043358297]
[2025-10-03 20:39:44] INFO  SQLQueries - [MYRTLE BEACH INTERNATIONAL AIRPORT,7177,36899,19.45039160952871]
[2025-10-03 20:39:44] INFO  SQLQueries - [HAYS REGIONAL AIRPORT,322,1657,19.43270971635486]
[2025-10-03 20:39:44] INFO  SQLQueries - [WILLIAM P HOBBY AIRPORT,26112,134520,19.41123996431757]
[2025-10-03 20:39:44] INFO  SQLQueries - [KALAMAZOO BATTLE CREEK INTERNATIONAL AIRPORT,825,4260,19.36619718309859]
[2025-10-03 20:39:44] INFO  SQLQueries - [COLUMBIA METROPOLITAN AIRPORT,4656,24047,19.36208258826465]
[2025-10-03 20:39:44] INFO  SQLQueries - [BURLINGTON INTERNATIONAL AIRPORT,4157,21482,19.35108462899171]
[2025-10-03 20:39:44] INFO  SQLQueries - [HARRISBURG INTERNATIONAL AIRPORT,4211,21775,19.33869115958668]
[2025-10-03 20:39:44] INFO  SQLQueries - [LAGUARDIA AIRPORT,76645,397625,19.27569946557686]
[2025-10-03 20:39:44] INFO  SQLQueries - [GEORGE BUSH INTERCONTINENTAL HOUSTON AIRPORT,75754,393258,19.26318091431071]
[2025-10-03 20:39:44] INFO  SQLQueries - [HOLLYWOOD BURBANK AIRPORT,14152,73473,19.26149742082125]
[2025-10-03 20:39:44] INFO  SQLQueries - [LOS ANGELES INTERNATIONAL AIRPORT,90764,471376,19.25511693425206]
[2025-10-03 20:39:44] INFO  SQLQueries - [HECTOR INTERNATIONAL AIRPORT,3175,16549,19.18544927185933]
[2025-10-03 20:39:44] INFO  SQLQueries - [PORTLAND INTERNATIONAL JETPORT,5553,28959,19.17538589039677]
[2025-10-03 20:39:44] INFO  SQLQueries - [NANTUCKET MEMORIAL AIRPORT,750,3912,19.17177914110429]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHARLES M. SCHULZ SONOMA COUNTY AIRPORT,1918,10006,19.16849890065960]
[2025-10-03 20:39:44] INFO  SQLQueries - [ST. LOUIS LAMBERT INTERNATIONAL AIRPORT,30902,161278,19.16070387777626]
[2025-10-03 20:39:44] INFO  SQLQueries - [SACRAMENTO INTERNATIONAL AIRPORT,25763,134516,19.15236849148057]
[2025-10-03 20:39:44] INFO  SQLQueries - [BALTIMORE/WASHINGTON INTERNATIONAL THURGOOD MARSHALL AIRPORT,44661,233297,19.14340947376091]
[2025-10-03 20:39:44] INFO  SQLQueries - [MIDLAND INTERNATIONAL AIR AND SPACE PORT,4847,25354,19.11729904551550]
[2025-10-03 20:39:44] INFO  SQLQueries - [UNIVERSITY OF ILLINOIS WILLARD AIRPORT,719,3764,19.10201912858661]
[2025-10-03 20:39:44] INFO  SQLQueries - [MEADOWS FIELD,1261,6616,19.05985489721886]
[2025-10-03 20:39:44] INFO  SQLQueries - [SHREVEPORT REGIONAL AIRPORT,2703,14235,18.98840885142255]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHIPPEWA COUNTY INTERNATIONAL AIRPORT,336,1772,18.96162528216704]
[2025-10-03 20:39:44] INFO  SQLQueries - [CENTRAL WISCONSIN AIRPORT,742,3914,18.95758814512008]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHATTANOOGA METROPOLITAN AIRPORT (LOVELL FIELD),3694,19551,18.89417421103780]
[2025-10-03 20:39:44] INFO  SQLQueries - [LAFAYETTE REGIONAL AIRPORT,2157,11426,18.87799754944863]
[2025-10-03 20:39:44] INFO  SQLQueries - [PHOENIX SKY HARBOR INTERNATIONAL AIRPORT,86798,460878,18.83318361909225]
[2025-10-03 20:39:44] INFO  SQLQueries - [HUNTSVILLE INTERNATIONAL CARL T JONES FIELD,5360,28465,18.83014227999297]
[2025-10-03 20:39:44] INFO  SQLQueries - [ALPENA COUNTY REGIONAL AIRPORT,252,1340,18.80597014925373]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHICAGO MIDWAY INTERNATIONAL AIRPORT,36278,192937,18.80302896800510]
[2025-10-03 20:39:44] INFO  SQLQueries - [PELLSTON REGIONAL AIRPORT OF EMMET COUNTY AIRPORT,354,1883,18.79978757302177]
[2025-10-03 20:39:44] INFO  SQLQueries - [NORTH PLATTE REGIONAL AIRPORT LEE BIRD FIELD,295,1570,18.78980891719745]
[2025-10-03 20:39:44] INFO  SQLQueries - [SANTA BARBARA MUNICIPAL AIRPORT,3480,18526,18.78441109791644]
[2025-10-03 20:39:44] INFO  SQLQueries - [PALM SPRINGS INTERNATIONAL AIRPORT,6812,36275,18.77877325982081]
[2025-10-03 20:39:44] INFO  SQLQueries - [AUGUSTA REGIONAL AT BUSH FIELD,2266,12097,18.73191700421592]
[2025-10-03 20:39:44] INFO  SQLQueries - [STATE COLLEGE REGIONAL AIRPORT,1422,7594,18.72530945483276]
[2025-10-03 20:39:44] INFO  SQLQueries - [JOPLIN REGIONAL AIRPORT,289,1550,18.64516129032258]
[2025-10-03 20:39:44] INFO  SQLQueries - [WORCESTER REGIONAL AIRPORT,663,3557,18.63930278324431]
[2025-10-03 20:39:44] INFO  SQLQueries - [KEARNEY REGIONAL AIRPORT,68,365,18.63013698630137]
[2025-10-03 20:39:44] INFO  SQLQueries - [MONTEREY PENINSULA AIRPORT,2050,11025,18.59410430839002]
[2025-10-03 20:39:44] INFO  SQLQueries - [WILLISTON BASIN INTERNATIONAL AIRPORT,844,4541,18.58621449020040]
[2025-10-03 20:39:44] INFO  SQLQueries - [HATTIESBURG LAUREL REGIONAL AIRPORT,280,1508,18.56763925729443]
[2025-10-03 20:39:44] INFO  SQLQueries - [DURANGO LA PLATA COUNTY AIRPORT,1769,9566,18.49257787999164]
[2025-10-03 20:39:44] INFO  SQLQueries - [SAN FRANCISCO BAY OAKLAND INTERNATIONAL AIRPORT,19298,104376,18.48892465700927]
[2025-10-03 20:39:44] INFO  SQLQueries - [MOBILE REGIONAL AIRPORT,2312,12507,18.48564803709922]
[2025-10-03 20:39:44] INFO  SQLQueries - [BRUNSWICK GOLDEN ISLES AIRPORT,362,1960,18.46938775510204]
[2025-10-03 20:39:44] INFO  SQLQueries - [SPOKANE INTERNATIONAL AIRPORT,9276,50321,18.43365592893623]
[2025-10-03 20:39:44] INFO  SQLQueries - [DICKINSON THEODORE ROOSEVELT REGIONAL AIRPORT,293,1591,18.41609050911376]
[2025-10-03 20:39:44] INFO  SQLQueries - [RAPID CITY REGIONAL AIRPORT,2194,11914,18.41530971965755]
[2025-10-03 20:39:44] INFO  SQLQueries - [MONTGOMERY REGIONAL (DANNELLY FIELD) AIRPORT,1487,8079,18.40574328506003]
[2025-10-03 20:39:44] INFO  SQLQueries - [MASON CITY MUNICIPAL AIRPORT,277,1508,18.36870026525199]
[2025-10-03 20:39:44] INFO  SQLQueries - [WILMINGTON INTERNATIONAL AIRPORT,3973,21701,18.30791207778443]
[2025-10-03 20:39:44] INFO  SQLQueries - [ARNOLD PALMER REGIONAL AIRPORT,238,1300,18.30769230769231]
[2025-10-03 20:39:44] INFO  SQLQueries - [TYLER POUNDS REGIONAL AIRPORT,476,2604,18.27956989247312]
[2025-10-03 20:39:44] INFO  SQLQueries - [DULUTH INTERNATIONAL AIRPORT,965,5283,18.26613666477380]
[2025-10-03 20:39:44] INFO  SQLQueries - [GUNNISON CRESTED BUTTE REGIONAL AIRPORT,440,2411,18.24968892575695]
[2025-10-03 20:39:44] INFO  SQLQueries - [JACKSON-MEDGAR WILEY EVERS INTERNATIONAL AIRPORT,3962,21745,18.22028052425845]
[2025-10-03 20:39:44] INFO  SQLQueries - [TEXARKANA REGIONAL AIRPORT (WEBB FIELD),383,2106,18.18613485280152]
[2025-10-03 20:39:44] INFO  SQLQueries - [GRAND JUNCTION REGIONAL AIRPORT,1815,9983,18.18090754282280]
[2025-10-03 20:39:44] INFO  SQLQueries - [PIEDMONT TRIAD INTERNATIONAL AIRPORT,5894,32422,18.17901424958362]
[2025-10-03 20:39:44] INFO  SQLQueries - [FAIRBANKS INTERNATIONAL AIRPORT,2262,12465,18.14681107099880]
[2025-10-03 20:39:44] INFO  SQLQueries - [CORPUS CHRISTI INTERNATIONAL AIRPORT,2491,13733,18.13878977645088]
[2025-10-03 20:39:44] INFO  SQLQueries - [EAST TEXAS REGIONAL AIRPORT,318,1755,18.11965811965812]
[2025-10-03 20:39:44] INFO  SQLQueries - [DAYTONA BEACH INTERNATIONAL AIRPORT,1258,6960,18.07471264367816]
[2025-10-03 20:39:44] INFO  SQLQueries - [BETHEL AIRPORT,345,1911,18.05337519623234]
[2025-10-03 20:39:44] INFO  SQLQueries - [DANIEL K INOUYE INTERNATIONAL AIRPORT,26753,148320,18.03735167206041]
[2025-10-03 20:39:44] INFO  SQLQueries - [MAHLON SWEET FIELD,3728,20707,18.00357367073936]
[2025-10-03 20:39:44] INFO  SQLQueries - [SAN ANGELO REGIONAL MATHIS FIELD,478,2665,17.93621013133208]
[2025-10-03 20:39:44] INFO  SQLQueries - [WESTERN NEB. RGNL/WILLIAM B. HEILIG AIRPORT,267,1492,17.89544235924933]
[2025-10-03 20:39:44] INFO  SQLQueries - [ELMIRA CORNING REGIONAL AIRPORT,448,2504,17.89137380191693]
[2025-10-03 20:39:44] INFO  SQLQueries - [VALLEY INTERNATIONAL AIRPORT,2393,13379,17.88623962926975]
[2025-10-03 20:39:44] INFO  SQLQueries - [TALLAHASSEE REGIONAL AIRPORT,2734,15293,17.87746027594324]
[2025-10-03 20:39:44] INFO  SQLQueries - [BANGOR INTERNATIONAL AIRPORT,2147,12063,17.79822598027025]
[2025-10-03 20:39:44] INFO  SQLQueries - [NEW YORK STEWART INTERNATIONAL AIRPORT,207,1164,17.78350515463918]
[2025-10-03 20:39:44] INFO  SQLQueries - [EASTERWOOD FIELD,472,2660,17.74436090225564]
[2025-10-03 20:39:44] INFO  SQLQueries - [PORTLAND INTERNATIONAL AIRPORT,29666,167630,17.69730955079640]
[2025-10-03 20:39:44] INFO  SQLQueries - [SOUTHWEST WYOMING REGIONAL AIRPORT,240,1358,17.67304860088365]
[2025-10-03 20:39:44] INFO  SQLQueries - [MANHATTAN REGIONAL AIRPORT,604,3421,17.65565624086524]
[2025-10-03 20:39:44] INFO  SQLQueries - [SEATTLE–TACOMA INTERNATIONAL AIRPORT,77095,437141,17.63618603608447]
[2025-10-03 20:39:44] INFO  SQLQueries - [JOHN WAYNE ORANGE COUNTY INTERNATIONAL AIRPORT,19086,108387,17.60912286528827]
[2025-10-03 20:39:44] INFO  SQLQueries - [BOISE AIR TERMINAL/GOWEN FIELD,11226,64025,17.53377586880125]
[2025-10-03 20:39:44] INFO  SQLQueries - [CENTRAL NEBRASKA REGIONAL AIRPORT,404,2305,17.52711496746204]
[2025-10-03 20:39:44] INFO  SQLQueries - [CENTRAL ILLINOIS REGIONAL AIRPORT AT BLOOMINGTON-NORMAL,1068,6135,17.40831295843521]
[2025-10-03 20:39:44] INFO  SQLQueries - [MERLE K (MUDHOLE) SMITH AIRPORT,304,1750,17.37142857142857]
[2025-10-03 20:39:44] INFO  SQLQueries - [NORMAN Y. MINETA SAN JOSE INTERNATIONAL AIRPORT,21508,123915,17.35705927450268]
[2025-10-03 20:39:44] INFO  SQLQueries - [DETROIT METROPOLITAN WAYNE COUNTY AIRPORT,54673,315739,17.31588432217749]
[2025-10-03 20:39:44] INFO  SQLQueries - [ROSWELL AIR CENTER AIRPORT,392,2266,17.29920564872021]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHEYENNE REGIONAL JERRY OLSON FIELD,232,1345,17.24907063197026]
[2025-10-03 20:39:44] INFO  SQLQueries - [HARTSFIELD JACKSON ATLANTA INTERNATIONAL AIRPORT,141531,821161,17.23547513824938]
[2025-10-03 20:39:44] INFO  SQLQueries - [BELLINGHAM INTERNATIONAL AIRPORT,1101,6388,17.23544145272386]
[2025-10-03 20:39:44] INFO  SQLQueries - [CAPE COD GATEWAY AIRPORT,82,477,17.19077568134172]
[2025-10-03 20:39:44] INFO  SQLQueries - [MELBOURNE ORLANDO INTERNATIONAL AIRPORT,1163,6776,17.16351829988194]
[2025-10-03 20:39:44] INFO  SQLQueries - [BILLINGS LOGAN INTERNATIONAL AIRPORT,2086,12181,17.12503078564978]
[2025-10-03 20:39:44] INFO  SQLQueries - [GULFPORT BILOXI INTERNATIONAL AIRPORT,1702,9943,17.11757014985417]
[2025-10-03 20:39:44] INFO  SQLQueries - [BISMARCK MUNICIPAL AIRPORT,1597,9375,17.03466666666667]
[2025-10-03 20:39:44] INFO  SQLQueries - [LIBERAL MID-AMERICA REGIONAL AIRPORT,246,1447,17.00069108500346]
[2025-10-03 20:39:44] INFO  SQLQueries - [HILTON HEAD AIRPORT,745,4387,16.98199224982904]
[2025-10-03 20:39:44] INFO  SQLQueries - [SHERIDAN COUNTY AIRPORT,284,1673,16.97549312612074]
[2025-10-03 20:39:44] INFO  SQLQueries - [TRI-STATE AIRPORT / MILTON J. FERGUSON FIELD,523,3085,16.95299837925446]
[2025-10-03 20:39:44] INFO  SQLQueries - [MISSOULA INTERNATIONAL AIRPORT,2084,12305,16.93620479479886]
[2025-10-03 20:39:44] INFO  SQLQueries - [DODGE CITY REGIONAL AIRPORT,255,1509,16.89860834990060]
[2025-10-03 20:39:44] INFO  SQLQueries - [LONG BEACH AIRPORT (DAUGHERTY FIELD),6932,41277,16.79385614264603]
[2025-10-03 20:39:44] INFO  SQLQueries - [LAREDO INTERNATIONAL AIRPORT,1088,6521,16.68455758319276]
[2025-10-03 20:39:44] INFO  SQLQueries - [WASHINGTON DULLES INTERNATIONAL AIRPORT,32373,194324,16.65929066919166]
[2025-10-03 20:39:44] INFO  SQLQueries - [PLATTSBURGH INTERNATIONAL AIRPORT,199,1195,16.65271966527197]
[2025-10-03 20:39:44] INFO  SQLQueries - [REDDING MUNICIPAL AIRPORT,636,3836,16.57977059436913]
[2025-10-03 20:39:44] INFO  SQLQueries - [ERIE INTERNATIONAL TOM RIDGE FIELD,413,2491,16.57968687274187]
[2025-10-03 20:39:44] INFO  SQLQueries - [MINNEAPOLIS–SAINT PAUL INTERNATIONAL AIRPORT / WOLD–CHAMBERLAIN FIELD,50120,302493,16.56897845569980]
[2025-10-03 20:39:44] INFO  SQLQueries - [BROWNSVILLE SOUTH PADRE ISLAND INTERNATIONAL AIRPORT,1241,7530,16.48074369189907]
[2025-10-03 20:39:44] INFO  SQLQueries - [JUNEAU INTERNATIONAL AIRPORT,1831,11149,16.42299757825814]
[2025-10-03 20:39:44] INFO  SQLQueries - [CENTRAL WYOMING REGIONAL AIRPORT,223,1358,16.42120765832106]
[2025-10-03 20:39:44] INFO  SQLQueries - [COLUMBUS METROPOLITAN AIRPORT,427,2602,16.41045349730976]
[2025-10-03 20:39:44] INFO  SQLQueries - [LAWTON FORT SILL REGIONAL AIRPORT,436,2658,16.40331075996990]
[2025-10-03 20:39:44] INFO  SQLQueries - [WICHITA FALLS MUNICIPAL AIRPORT / SHEPPARD AIR FORCE BASE,287,1750,16.40000000000000]
[2025-10-03 20:39:44] INFO  SQLQueries - [GLACIER PARK INTERNATIONAL AIRPORT,1856,11347,16.35674627654887]
[2025-10-03 20:39:44] INFO  SQLQueries - [FORT SMITH REGIONAL AIRPORT,445,2722,16.34827332843497]
[2025-10-03 20:39:44] INFO  SQLQueries - [NOME AIRPORT,286,1750,16.34285714285714]
[2025-10-03 20:39:44] INFO  SQLQueries - [LAKE CHARLES REGIONAL AIRPORT,759,4655,16.30504833512352]
[2025-10-03 20:39:44] INFO  SQLQueries - [KING SALMON AIRPORT,184,1129,16.29760850310009]
[2025-10-03 20:39:44] INFO  SQLQueries - [FORD AIRPORT,286,1756,16.28701594533030]
[2025-10-03 20:39:44] INFO  SQLQueries - [OWENSBORO DAVIESS COUNTY AIRPORT,7,43,16.27906976744186]
[2025-10-03 20:39:44] INFO  SQLQueries - [SOUTHWEST GEORGIA REGIONAL AIRPORT,325,2002,16.23376623376623]
[2025-10-03 20:39:44] INFO  SQLQueries - [GAINESVILLE REGIONAL AIRPORT,1558,9613,16.20721939040882]
[2025-10-03 20:39:44] INFO  SQLQueries - [TRI CITIES AIRPORT,2391,14828,16.12489884003237]
[2025-10-03 20:39:44] INFO  SQLQueries - [GREATER BINGHAMTON/EDWIN A LINK FIELD,189,1176,16.07142857142857]
[2025-10-03 20:39:44] INFO  SQLQueries - [NORTHEAST WYOMING REGIONAL AIRPORT,269,1675,16.05970149253731]
[2025-10-03 20:39:44] INFO  SQLQueries - [WRANGELL AIRPORT,281,1750,16.05714285714286]
[2025-10-03 20:39:44] INFO  SQLQueries - [KETCHIKAN INTERNATIONAL AIRPORT,949,5923,16.02228600371433]
[2025-10-03 20:39:44] INFO  SQLQueries - [MINOT INTERNATIONAL AIRPORT,919,5752,15.97705146036161]
[2025-10-03 20:39:44] INFO  SQLQueries - [IDAHO FALLS REGIONAL AIRPORT,1555,9743,15.96017653700092]
[2025-10-03 20:39:44] INFO  SQLQueries - [VERNAL REGIONAL AIRPORT,107,675,15.85185185185185]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHARLOTTESVILLE ALBEMARLE AIRPORT,2490,15731,15.82861865107113]
[2025-10-03 20:39:44] INFO  SQLQueries - [ELLISON ONIZUKA KONA INTERNATIONAL AIRPORT AT KEAHOLE,6324,40237,15.71687750080771]
[2025-10-03 20:39:44] INFO  SQLQueries - [YAKUTAT AIRPORT,275,1750,15.71428571428571]
[2025-10-03 20:39:44] INFO  SQLQueries - [MONROE REGIONAL AIRPORT,742,4726,15.70038087177317]
[2025-10-03 20:39:44] INFO  SQLQueries - [FAYETTEVILLE REGIONAL AIRPORT - GRANNIS FIELD,1181,7528,15.68809776833156]
[2025-10-03 20:39:44] INFO  SQLQueries - [ROBERTS FIELD,2874,18327,15.68178097888361]
[2025-10-03 20:39:44] INFO  SQLQueries - [EVANSVILLE REGIONAL AIRPORT,1255,8010,15.66791510611735]
[2025-10-03 20:39:44] INFO  SQLQueries - [CANYONLANDS REGIONAL AIRPORT,104,668,15.56886227544910]
[2025-10-03 20:39:44] INFO  SQLQueries - [ALEXANDRIA INTERNATIONAL AIRPORT,721,4663,15.46214883122453]
[2025-10-03 20:39:44] INFO  SQLQueries - [JACK BROOKS REGIONAL AIRPORT,271,1759,15.40648095508812]
[2025-10-03 20:39:44] INFO  SQLQueries - [PETERSBURG JAMES A JOHNSON AIRPORT,269,1750,15.37142857142857]
[2025-10-03 20:39:44] INFO  SQLQueries - [DOTHAN REGIONAL AIRPORT,294,1919,15.32047941636269]
[2025-10-03 20:39:44] INFO  SQLQueries - [ROGUE VALLEY INTERNATIONAL MEDFORD AIRPORT,2389,15714,15.20300369097620]
[2025-10-03 20:39:44] INFO  SQLQueries - [VICTORIA REGIONAL AIRPORT,232,1530,15.16339869281046]
[2025-10-03 20:39:44] INFO  SQLQueries - [LIHUE AIRPORT,5842,38568,15.14727235013483]
[2025-10-03 20:39:44] INFO  SQLQueries - [SALT LAKE CITY INTERNATIONAL AIRPORT,40985,270935,15.12724454204883]
[2025-10-03 20:39:44] INFO  SQLQueries - [ALBERT J ELLIS AIRPORT,986,6548,15.05803298717166]
[2025-10-03 20:39:44] INFO  SQLQueries - [RALPH WIEN MEMORIAL AIRPORT,263,1748,15.04576659038902]
[2025-10-03 20:39:44] INFO  SQLQueries - [CHICAGO ROCKFORD INTERNATIONAL AIRPORT,293,1950,15.02564102564103]
[2025-10-03 20:39:44] INFO  SQLQueries - [RHINELANDER ONEIDA COUNTY AIRPORT,278,1864,14.91416309012876]
[2025-10-03 20:39:44] INFO  SQLQueries - [TRI-CITIES REGIONAL TN/VA AIRPORT,1496,10131,14.76655808903366]
[2025-10-03 20:39:44] INFO  SQLQueries - [BEMIDJI REGIONAL AIRPORT,256,1743,14.68732071141710]
[2025-10-03 20:39:44] INFO  SQLQueries - [VALDOSTA REGIONAL AIRPORT,297,2023,14.68116658428077]
[2025-10-03 20:39:44] INFO  SQLQueries - [KAHULUI INTERNATIONAL AIRPORT,9872,67289,14.67104578757301]
[2025-10-03 20:39:44] INFO  SQLQueries - [KODIAK AIRPORT,282,1923,14.66458658346334]
[2025-10-03 20:39:44] INFO  SQLQueries - [FLAGSTAFF PULLIAM INTERNATIONAL AIRPORT,622,4263,14.59066385174760]
[2025-10-03 20:39:44] INFO  SQLQueries - [GRAND FORKS INTERNATIONAL AIRPORT,457,3139,14.55877668047149]
[2025-10-03 20:39:44] INFO  SQLQueries - [YUMA INTERNATIONAL AIRPORT / MARINE CORPS AIR STATION YUMA,612,4215,14.51957295373665]
[2025-10-03 20:39:44] INFO  SQLQueries - [HILO INTERNATIONAL AIRPORT,2427,16763,14.47831533735012]
[2025-10-03 20:39:44] INFO  SQLQueries - [FALLS INTERNATIONAL AIRPORT,222,1535,14.46254071661238]
[2025-10-03 20:39:44] INFO  SQLQueries - [DILLINGHAM AIRPORT,160,1107,14.45347786811201]
[2025-10-03 20:39:44] INFO  SQLQueries - [ST GEORGE REGIONAL AIRPORT,1068,7450,14.33557046979866]
[2025-10-03 20:39:44] INFO  SQLQueries - [NIAGARA FALLS INTERNATIONAL AIRPORT,136,950,14.31578947368421]
[2025-10-03 20:39:44] INFO  SQLQueries - [SALISBURY OCEAN CITY WICOMICO REGIONAL AIRPORT,578,4050,14.27160493827160]
[2025-10-03 20:39:44] INFO  SQLQueries - [PORTSMOUTH INTERNATIONAL AT PEASE AIRPORT,136,967,14.06411582213030]
[2025-10-03 20:39:44] INFO  SQLQueries - [BRAINERD LAKES REGIONAL AIRPORT,215,1531,14.04310907903331]
[2025-10-03 20:39:44] INFO  SQLQueries - [STILLWATER REGIONAL AIRPORT,244,1757,13.88730791121229]
[2025-10-03 20:39:44] INFO  SQLQueries - [COASTAL CAROLINA REGIONAL AIRPORT,590,4343,13.58507943817638]
[2025-10-03 20:39:44] INFO  SQLQueries - [NEWPORT NEWS WILLIAMSBURG INTERNATIONAL AIRPORT,502,3699,13.57123546904569]
[2025-10-03 20:39:44] INFO  SQLQueries - [ABERDEEN REGIONAL AIRPORT,233,1754,13.28392246294185]
[2025-10-03 20:39:44] INFO  SQLQueries - [LYNCHBURG REGIONAL AIRPORT - PRESTON GLENN FIELD,560,4262,13.13937118723604]
[2025-10-03 20:39:44] INFO  SQLQueries - [GREAT FALLS INTERNATIONAL AIRPORT,857,6534,13.11600857055403]
[2025-10-03 20:39:44] INFO  SQLQueries - [WALLA WALLA REGIONAL AIRPORT,197,1507,13.07232913072329]
[2025-10-03 20:39:44] INFO  SQLQueries - [DELTA COUNTY AIRPORT,209,1606,13.01369863013699]
[2025-10-03 20:39:44] INFO  SQLQueries - [RANGE REGIONAL AIRPORT,206,1591,12.94783155248272]
[2025-10-03 20:39:44] INFO  SQLQueries - [PITT-GREENVILLE AIRPORT,294,2275,12.92307692307692]
[2025-10-03 20:39:44] INFO  SQLQueries - [PULLMAN-MOSCOW REGIONAL AIRPORT,332,2578,12.87820015515904]
[2025-10-03 20:39:44] INFO  SQLQueries - [JAMESTOWN REGIONAL AIRPORT,200,1570,12.73885350318471]
[2025-10-03 20:39:44] INFO  SQLQueries - [DEVILS LAKE REGIONAL AIRPORT,205,1633,12.55358236374770]
[2025-10-03 20:39:44] INFO  SQLQueries - [LEWISTON NEZ PERCE COUNTY AIRPORT,277,2246,12.33303650934996]
[2025-10-03 20:39:44] INFO  SQLQueries - [FLORENCE REGIONAL AIRPORT,237,1967,12.04880528723945]
[2025-10-03 20:39:44] INFO  SQLQueries - [HELENA REGIONAL AIRPORT,525,4369,12.01647974364843]
[2025-10-03 20:39:44] INFO  SQLQueries - [GUAM, TT: GUAM INTERNATIONAL,215,1793,11.99107640825432]
[2025-10-03 20:39:44] INFO  SQLQueries - [GOLDEN TRIANGLE REGIONAL AIRPORT,223,1863,11.96994095544820]
[2025-10-03 20:39:44] INFO  SQLQueries - [FRIEDMAN MEMORIAL AIRPORT,660,5517,11.96302338227297]
[2025-10-03 20:39:44] INFO  SQLQueries - [WATERTOWN INTERNATIONAL AIRPORT,199,1665,11.95195195195195]
[2025-10-03 20:39:44] INFO  SQLQueries - [DEADHORSE AIRPORT,144,1221,11.79361179361179]
[2025-10-03 20:39:44] INFO  SQLQueries - [YAKIMA AIR TERMINAL MCALLISTER FIELD,169,1443,11.71171171171171]
[2025-10-03 20:39:44] INFO  SQLQueries - [PANGBORN MEMORIAL AIRPORT,169,1506,11.22177954847278]
[2025-10-03 20:39:44] INFO  SQLQueries - [PUEBLO MEMORIAL AIRPORT,3,27,11.11111111111111]
[2025-10-03 20:39:44] INFO  SQLQueries - [YELLOWSTONE AIRPORT,71,651,10.90629800307220]
[2025-10-03 20:39:44] INFO  SQLQueries - [DEL RIO INTERNATIONAL AIRPORT,20,184,10.86956521739130]
[2025-10-03 20:39:44] INFO  SQLQueries - [CEDAR CITY REGIONAL AIRPORT,158,1509,10.47051027170311]
[2025-10-03 20:39:44] INFO  SQLQueries - [BERT MOONEY AIRPORT,170,1648,10.31553398058252]
[2025-10-03 20:39:44] INFO  SQLQueries - [MCCLELLAN-PALOMAR AIRPORT,21,216,9.72222222222222]
[2025-10-03 20:39:44] INFO  SQLQueries - [GUSTAVUS AIRPORT,16,165,9.69696969696970]
[2025-10-03 20:39:44] INFO  SQLQueries - [ADAK AIRPORT,24,252,9.52380952380952]
[2025-10-03 20:39:44] INFO  SQLQueries - [ELKO REGIONAL AIRPORT,73,899,8.12013348164627]
[2025-10-03 20:39:44] INFO  SQLQueries - [JOSLIN FIELD MAGIC VALLEY REGIONAL AIRPORT,115,1490,7.71812080536913]
[2025-10-03 20:39:44] INFO  SQLQueries - [POCATELLO REGIONAL AIRPORT,101,1484,6.80592991913747]
[2025-10-03 20:39:44] INFO  SQLQueries - [SAINT CLOUD REGIONAL AIRPORT,24,384,6.25000000000000]
[2025-10-03 20:39:44] INFO  SQLQueries - [SAIPAN, TT: FRANCISCO C. ADA SAIPAN INTERNATIONAL,33,911,3.62239297475302]
[2025-10-03 20:39:44] INFO  SQLQueries - Task 6.4 - Monthly performance for airline 'AA'
[2025-10-03 20:39:44] INFO  CodeGenerator - Code generated in 10.9473 ms
[2025-10-03 20:39:44] INFO  DAGScheduler - Registering RDD 51 (collectAsList at SQLQueries.java:154) as input to shuffle 9
[2025-10-03 20:39:44] INFO  DAGScheduler - Got map stage job 15 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:44] INFO  DAGScheduler - Final stage: ShuffleMapStage 37 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:44] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:44] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:44] INFO  DAGScheduler - Submitting ShuffleMapStage 37 (MapPartitionsRDD[51] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:44] INFO  MemoryStore - Block broadcast_16 stored as values in memory (estimated size 15.6 KiB, free 2.2 GiB)
[2025-10-03 20:39:44] INFO  MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:44] INFO  BlockManagerInfo - Added broadcast_16_piece0 in memory on DESKTOP-618L1DH:59186 (size: 7.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:44] INFO  SparkContext - Created broadcast 16 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:44] INFO  CodeGenerator - Code generated in 13.2105 ms
[2025-10-03 20:39:44] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[51] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:44] INFO  TaskSchedulerImpl - Adding task set 37.0 with 1 tasks resource profile 0
[2025-10-03 20:39:44] INFO  TaskSetManager - Starting task 0.0 in stage 37.0 (TID 15) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:44] INFO  Executor - Running task 0.0 in stage 37.0 (TID 15)
[2025-10-03 20:39:44] INFO  DAGScheduler - Registering RDD 53 (collectAsList at SQLQueries.java:154) as input to shuffle 10
[2025-10-03 20:39:44] INFO  DAGScheduler - Got map stage job 16 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:44] INFO  DAGScheduler - Final stage: ShuffleMapStage 38 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:44] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:44] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:44] INFO  DAGScheduler - Submitting ShuffleMapStage 38 (MapPartitionsRDD[53] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:44] INFO  MemoryStore - Block broadcast_17 stored as values in memory (estimated size 14.4 KiB, free 2.2 GiB)
[2025-10-03 20:39:44] INFO  MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 2.2 GiB)
[2025-10-03 20:39:44] INFO  BlockManagerInfo - Added broadcast_17_piece0 in memory on DESKTOP-618L1DH:59186 (size: 7.5 KiB, free: 2.2 GiB)
[2025-10-03 20:39:44] INFO  SparkContext - Created broadcast 17 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:44] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[53] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:44] INFO  TaskSchedulerImpl - Adding task set 38.0 with 1 tasks resource profile 0
[2025-10-03 20:39:44] INFO  TaskSetManager - Starting task 0.0 in stage 38.0 (TID 16) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:44] INFO  Executor - Running task 0.0 in stage 38.0 (TID 16)
[2025-10-03 20:39:44] INFO  CodeGenerator - Code generated in 7.9822 ms
[2025-10-03 20:39:44] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:44] INFO  Executor - Finished task 0.0 in stage 38.0 (TID 16). 1949 bytes result sent to driver
[2025-10-03 20:39:44] INFO  TaskSetManager - Finished task 0.0 in stage 38.0 (TID 16) in 79 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:44] INFO  TaskSchedulerImpl - Removed TaskSet 38.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:44] INFO  DAGScheduler - ShuffleMapStage 38 (collectAsList at SQLQueries.java:154) finished in 0.093 s
[2025-10-03 20:39:44] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:44] INFO  DAGScheduler - running: Set(ShuffleMapStage 37)
[2025-10-03 20:39:44] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:44] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:44] INFO  CodeGenerator - Code generated in 7.2533 ms
[2025-10-03 20:39:44] INFO  CodeGenerator - Code generated in 10.1556 ms
[2025-10-03 20:39:44] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:44] INFO  Executor - Finished task 0.0 in stage 37.0 (TID 15). 1949 bytes result sent to driver
[2025-10-03 20:39:44] INFO  TaskSetManager - Finished task 0.0 in stage 37.0 (TID 15) in 277 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:44] INFO  TaskSchedulerImpl - Removed TaskSet 37.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:44] INFO  DAGScheduler - ShuffleMapStage 37 (collectAsList at SQLQueries.java:154) finished in 0.295 s
[2025-10-03 20:39:44] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:44] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:44] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:44] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:44] INFO  ShufflePartitionsUtil - For shuffle(9, 10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 29.4006 ms
[2025-10-03 20:39:45] INFO  DAGScheduler - Registering RDD 60 (collectAsList at SQLQueries.java:154) as input to shuffle 11
[2025-10-03 20:39:45] INFO  DAGScheduler - Got map stage job 17 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:45] INFO  DAGScheduler - Final stage: ShuffleMapStage 41 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:45] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 39, ShuffleMapStage 40)
[2025-10-03 20:39:45] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:45] INFO  DAGScheduler - Submitting ShuffleMapStage 41 (MapPartitionsRDD[60] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:45] INFO  MemoryStore - Block broadcast_18 stored as values in memory (estimated size 63.7 KiB, free 2.2 GiB)
[2025-10-03 20:39:45] INFO  MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 2.2 GiB)
[2025-10-03 20:39:45] INFO  BlockManagerInfo - Added broadcast_18_piece0 in memory on DESKTOP-618L1DH:59186 (size: 27.9 KiB, free: 2.2 GiB)
[2025-10-03 20:39:45] INFO  SparkContext - Created broadcast 18 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:45] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[60] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:45] INFO  TaskSchedulerImpl - Adding task set 41.0 with 1 tasks resource profile 0
[2025-10-03 20:39:45] INFO  TaskSetManager - Starting task 0.0 in stage 41.0 (TID 17) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9270 bytes) 
[2025-10-03 20:39:45] INFO  Executor - Running task 0.0 in stage 41.0 (TID 17)
[2025-10-03 20:39:45] INFO  ShuffleBlockFetcherIterator - Getting 1 (829.4 KiB) non-empty blocks including 1 (829.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:45] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 8.932 ms
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 8.8361 ms
[2025-10-03 20:39:45] INFO  ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:45] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 50.1398 ms
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 17.353 ms
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 7.035 ms
[2025-10-03 20:39:45] INFO  BlockManagerInfo - Removed broadcast_15_piece0 on DESKTOP-618L1DH:59186 in memory (size: 24.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:45] INFO  BlockManagerInfo - Removed broadcast_14_piece0 on DESKTOP-618L1DH:59186 in memory (size: 30.0 KiB, free: 2.2 GiB)
[2025-10-03 20:39:45] INFO  BlockManagerInfo - Removed broadcast_17_piece0 on DESKTOP-618L1DH:59186 in memory (size: 7.5 KiB, free: 2.2 GiB)
[2025-10-03 20:39:45] INFO  BlockManagerInfo - Removed broadcast_13_piece0 on DESKTOP-618L1DH:59186 in memory (size: 26.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:45] INFO  BlockManagerInfo - Removed broadcast_11_piece0 on DESKTOP-618L1DH:59186 in memory (size: 11.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:45] INFO  BlockManagerInfo - Removed broadcast_16_piece0 on DESKTOP-618L1DH:59186 in memory (size: 7.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:45] INFO  BlockManagerInfo - Removed broadcast_12_piece0 on DESKTOP-618L1DH:59186 in memory (size: 25.1 KiB, free: 2.2 GiB)
[2025-10-03 20:39:45] INFO  Executor - Finished task 0.0 in stage 41.0 (TID 17). 6814 bytes result sent to driver
[2025-10-03 20:39:45] INFO  TaskSetManager - Finished task 0.0 in stage 41.0 (TID 17) in 299 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:45] INFO  TaskSchedulerImpl - Removed TaskSet 41.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:45] INFO  DAGScheduler - ShuffleMapStage 41 (collectAsList at SQLQueries.java:154) finished in 0.310 s
[2025-10-03 20:39:45] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:45] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:45] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:45] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:45] INFO  ShufflePartitionsUtil - For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:45] INFO  HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 20.4873 ms
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 4.3574 ms
[2025-10-03 20:39:45] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:45] INFO  DAGScheduler - Got job 18 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:45] INFO  DAGScheduler - Final stage: ResultStage 45 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:45] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 44)
[2025-10-03 20:39:45] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:45] INFO  DAGScheduler - Submitting ResultStage 45 (MapPartitionsRDD[65] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:45] INFO  MemoryStore - Block broadcast_19 stored as values in memory (estimated size 61.4 KiB, free 2.2 GiB)
[2025-10-03 20:39:45] INFO  MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 26.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:45] INFO  BlockManagerInfo - Added broadcast_19_piece0 in memory on DESKTOP-618L1DH:59186 (size: 26.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:45] INFO  SparkContext - Created broadcast 19 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:45] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[65] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:45] INFO  TaskSchedulerImpl - Adding task set 45.0 with 1 tasks resource profile 0
[2025-10-03 20:39:45] INFO  TaskSetManager - Starting task 0.0 in stage 45.0 (TID 18) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:45] INFO  Executor - Running task 0.0 in stage 45.0 (TID 18)
[2025-10-03 20:39:45] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.0 KiB) non-empty blocks including 1 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:45] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 18.2707 ms
[2025-10-03 20:39:45] INFO  Executor - Finished task 0.0 in stage 45.0 (TID 18). 9393 bytes result sent to driver
[2025-10-03 20:39:45] INFO  TaskSetManager - Finished task 0.0 in stage 45.0 (TID 18) in 43 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:45] INFO  TaskSchedulerImpl - Removed TaskSet 45.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:45] INFO  DAGScheduler - ResultStage 45 (collectAsList at SQLQueries.java:154) finished in 0.052 s
[2025-10-03 20:39:45] INFO  DAGScheduler - Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:45] INFO  TaskSchedulerImpl - Killing all running tasks in stage 45: Stage finished
[2025-10-03 20:39:45] INFO  DAGScheduler - Job 18 finished: collectAsList at SQLQueries.java:154, took 0.058796 s
[2025-10-03 20:39:45] INFO  DAGScheduler - Registering RDD 66 (collectAsList at SQLQueries.java:154) as input to shuffle 12
[2025-10-03 20:39:45] INFO  DAGScheduler - Got map stage job 19 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:45] INFO  DAGScheduler - Final stage: ShuffleMapStage 49 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:45] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 48)
[2025-10-03 20:39:45] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:45] INFO  DAGScheduler - Submitting ShuffleMapStage 49 (MapPartitionsRDD[66] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:45] INFO  MemoryStore - Block broadcast_20 stored as values in memory (estimated size 62.9 KiB, free 2.2 GiB)
[2025-10-03 20:39:45] INFO  MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:45] INFO  BlockManagerInfo - Added broadcast_20_piece0 in memory on DESKTOP-618L1DH:59186 (size: 27.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:45] INFO  SparkContext - Created broadcast 20 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:45] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[66] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:45] INFO  TaskSchedulerImpl - Adding task set 49.0 with 1 tasks resource profile 0
[2025-10-03 20:39:45] INFO  TaskSetManager - Starting task 0.0 in stage 49.0 (TID 19) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-03 20:39:45] INFO  Executor - Running task 0.0 in stage 49.0 (TID 19)
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 7.9284 ms
[2025-10-03 20:39:45] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.0 KiB) non-empty blocks including 1 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:45] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-03 20:39:45] INFO  Executor - Finished task 0.0 in stage 49.0 (TID 19). 8264 bytes result sent to driver
[2025-10-03 20:39:45] INFO  TaskSetManager - Finished task 0.0 in stage 49.0 (TID 19) in 130 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:45] INFO  TaskSchedulerImpl - Removed TaskSet 49.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:45] INFO  DAGScheduler - ShuffleMapStage 49 (collectAsList at SQLQueries.java:154) finished in 0.153 s
[2025-10-03 20:39:45] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:45] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:45] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:45] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:45] INFO  ShufflePartitionsUtil - For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:45] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:45] INFO  DAGScheduler - Got job 20 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:45] INFO  DAGScheduler - Final stage: ResultStage 54 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:45] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 53)
[2025-10-03 20:39:45] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:45] INFO  DAGScheduler - Submitting ResultStage 54 (MapPartitionsRDD[69] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:45] INFO  MemoryStore - Block broadcast_21 stored as values in memory (estimated size 54.4 KiB, free 2.2 GiB)
[2025-10-03 20:39:45] INFO  MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 24.6 KiB, free 2.2 GiB)
[2025-10-03 20:39:45] INFO  BlockManagerInfo - Added broadcast_21_piece0 in memory on DESKTOP-618L1DH:59186 (size: 24.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:45] INFO  SparkContext - Created broadcast 21 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:45] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[69] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:45] INFO  TaskSchedulerImpl - Adding task set 54.0 with 1 tasks resource profile 0
[2025-10-03 20:39:45] INFO  TaskSetManager - Starting task 0.0 in stage 54.0 (TID 20) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:45] INFO  Executor - Running task 0.0 in stage 54.0 (TID 20)
[2025-10-03 20:39:45] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.7 KiB) non-empty blocks including 1 (2.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:45] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:45] INFO  Executor - Finished task 0.0 in stage 54.0 (TID 20). 10438 bytes result sent to driver
[2025-10-03 20:39:45] INFO  TaskSetManager - Finished task 0.0 in stage 54.0 (TID 20) in 31 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:45] INFO  TaskSchedulerImpl - Removed TaskSet 54.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:45] INFO  DAGScheduler - ResultStage 54 (collectAsList at SQLQueries.java:154) finished in 0.042 s
[2025-10-03 20:39:45] INFO  DAGScheduler - Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:45] INFO  TaskSchedulerImpl - Killing all running tasks in stage 54: Stage finished
[2025-10-03 20:39:45] INFO  DAGScheduler - Job 20 finished: collectAsList at SQLQueries.java:154, took 0.049778 s
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 13.8227 ms
[2025-10-03 20:39:45] INFO  SQLQueries - [2023,1,16691,74999,22.25496339951199]
[2025-10-03 20:39:45] INFO  SQLQueries - [2023,2,15124,71289,21.21505421593794]
[2025-10-03 20:39:45] INFO  SQLQueries - [2023,3,20810,78705,26.44050568578870]
[2025-10-03 20:39:45] INFO  SQLQueries - [2023,4,19385,77039,25.16257999195213]
[2025-10-03 20:39:45] INFO  SQLQueries - [2023,5,16502,79782,20.68386352811411]
[2025-10-03 20:39:45] INFO  SQLQueries - [2023,6,24149,80416,30.03009351372861]
[2025-10-03 20:39:45] INFO  SQLQueries - [2023,7,25955,83013,31.26618722368786]
[2025-10-03 20:39:45] INFO  SQLQueries - [2023,8,21278,85157,24.98678910717851]
[2025-10-03 20:39:45] INFO  SQLQueries - [2023,9,15570,76972,20.22813490619966]
[2025-10-03 20:39:45] INFO  SQLQueries - [2023,10,13521,81344,16.62200039339103]
[2025-10-03 20:39:45] INFO  SQLQueries - [2023,11,11533,76407,15.09416676482521]
[2025-10-03 20:39:45] INFO  SQLQueries - [2023,12,13332,75408,17.67982176957352]
[2025-10-03 20:39:45] INFO  SQLQueries - [2024,1,22292,77346,28.82114136477646]
[2025-10-03 20:39:45] INFO  SQLQueries - [2024,2,13964,74870,18.65099505810071]
[2025-10-03 20:39:45] INFO  SQLQueries - [2024,3,21978,82259,26.71804908885350]
[2025-10-03 20:39:45] INFO  SQLQueries - [2024,4,19380,81216,23.86229314420804]
[2025-10-03 20:39:45] INFO  SQLQueries - [2024,5,30736,86765,35.42442229009393]
[2025-10-03 20:39:45] INFO  SQLQueries - [2024,6,26802,85581,31.31769902197918]
[2025-10-03 20:39:45] INFO  SQLQueries - [2024,7,32526,88291,36.83954196917013]
[2025-10-03 20:39:45] INFO  SQLQueries - [2024,8,25825,85963,30.04199481172132]
[2025-10-03 20:39:45] INFO  SQLQueries - [2024,9,15485,80709,19.18621219442689]
[2025-10-03 20:39:45] INFO  SQLQueries - [2024,10,13578,86812,15.64069483481546]
[2025-10-03 20:39:45] INFO  SQLQueries - [2024,11,12529,76757,16.32294123011582]
[2025-10-03 20:39:45] INFO  SQLQueries - [2024,12,17390,77737,22.37029985721085]
[2025-10-03 20:39:45] INFO  SQLQueries - [2025,1,13860,75088,18.45834221180482]
[2025-10-03 20:39:45] INFO  SQLQueries - [2025,2,14135,69876,20.22869082374492]
[2025-10-03 20:39:45] INFO  SQLQueries - [2025,3,18743,82536,22.70887854996608]
[2025-10-03 20:39:45] INFO  SQLQueries - [2025,4,19766,82261,24.02839741797450]
[2025-10-03 20:39:45] INFO  SQLQueries - [2025,5,22398,86123,26.00699000267060]
[2025-10-03 20:39:45] INFO  SQLQueries - Task 7.1 - Total delay by cause
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 12.2211 ms
[2025-10-03 20:39:45] INFO  DAGScheduler - Registering RDD 72 (collectAsList at SQLQueries.java:154) as input to shuffle 13
[2025-10-03 20:39:45] INFO  DAGScheduler - Got map stage job 21 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:45] INFO  DAGScheduler - Final stage: ShuffleMapStage 55 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:45] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:45] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:45] INFO  DAGScheduler - Submitting ShuffleMapStage 55 (MapPartitionsRDD[72] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:45] INFO  MemoryStore - Block broadcast_22 stored as values in memory (estimated size 23.6 KiB, free 2.2 GiB)
[2025-10-03 20:39:45] INFO  MemoryStore - Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 2.2 GiB)
[2025-10-03 20:39:45] INFO  BlockManagerInfo - Added broadcast_22_piece0 in memory on DESKTOP-618L1DH:59186 (size: 9.9 KiB, free: 2.2 GiB)
[2025-10-03 20:39:45] INFO  SparkContext - Created broadcast 22 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:45] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[72] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:45] INFO  TaskSchedulerImpl - Adding task set 55.0 with 1 tasks resource profile 0
[2025-10-03 20:39:45] INFO  TaskSetManager - Starting task 0.0 in stage 55.0 (TID 21) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:45] INFO  Executor - Running task 0.0 in stage 55.0 (TID 21)
[2025-10-03 20:39:45] INFO  CodeGenerator - Code generated in 14.4415 ms
[2025-10-03 20:39:46] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:46] INFO  Executor - Finished task 0.0 in stage 55.0 (TID 21). 1845 bytes result sent to driver
[2025-10-03 20:39:46] INFO  TaskSetManager - Finished task 0.0 in stage 55.0 (TID 21) in 162 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Removed TaskSet 55.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:46] INFO  DAGScheduler - ShuffleMapStage 55 (collectAsList at SQLQueries.java:154) finished in 0.172 s
[2025-10-03 20:39:46] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:46] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:46] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:46] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 11.9305 ms
[2025-10-03 20:39:46] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:46] INFO  DAGScheduler - Got job 22 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:46] INFO  DAGScheduler - Final stage: ResultStage 57 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:46] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 56)
[2025-10-03 20:39:46] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:46] INFO  DAGScheduler - Submitting ResultStage 57 (MapPartitionsRDD[75] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:46] INFO  MemoryStore - Block broadcast_23 stored as values in memory (estimated size 20.5 KiB, free 2.2 GiB)
[2025-10-03 20:39:46] INFO  MemoryStore - Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 2.2 GiB)
[2025-10-03 20:39:46] INFO  BlockManagerInfo - Added broadcast_23_piece0 in memory on DESKTOP-618L1DH:59186 (size: 7.9 KiB, free: 2.2 GiB)
[2025-10-03 20:39:46] INFO  SparkContext - Created broadcast 23 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:46] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[75] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Adding task set 57.0 with 1 tasks resource profile 0
[2025-10-03 20:39:46] INFO  TaskSetManager - Starting task 0.0 in stage 57.0 (TID 22) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:46] INFO  Executor - Running task 0.0 in stage 57.0 (TID 22)
[2025-10-03 20:39:46] INFO  ShuffleBlockFetcherIterator - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:46] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 13.1021 ms
[2025-10-03 20:39:46] INFO  Executor - Finished task 0.0 in stage 57.0 (TID 22). 3976 bytes result sent to driver
[2025-10-03 20:39:46] INFO  TaskSetManager - Finished task 0.0 in stage 57.0 (TID 22) in 29 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Removed TaskSet 57.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:46] INFO  DAGScheduler - ResultStage 57 (collectAsList at SQLQueries.java:154) finished in 0.038 s
[2025-10-03 20:39:46] INFO  DAGScheduler - Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Killing all running tasks in stage 57: Stage finished
[2025-10-03 20:39:46] INFO  DAGScheduler - Job 22 finished: collectAsList at SQLQueries.java:154, took 0.041392 s
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 7.5035 ms
[2025-10-03 20:39:46] INFO  SQLQueries - [1169147,134101,989776,9602,1325689]
[2025-10-03 20:39:46] INFO  SQLQueries - Task 7.2 - Total delay by minutes
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 9.0324 ms
[2025-10-03 20:39:46] INFO  DAGScheduler - Registering RDD 78 (collectAsList at SQLQueries.java:154) as input to shuffle 14
[2025-10-03 20:39:46] INFO  DAGScheduler - Got map stage job 23 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:46] INFO  DAGScheduler - Final stage: ShuffleMapStage 58 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:46] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:46] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:46] INFO  DAGScheduler - Submitting ShuffleMapStage 58 (MapPartitionsRDD[78] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:46] INFO  MemoryStore - Block broadcast_24 stored as values in memory (estimated size 23.0 KiB, free 2.2 GiB)
[2025-10-03 20:39:46] INFO  MemoryStore - Block broadcast_24_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 2.2 GiB)
[2025-10-03 20:39:46] INFO  BlockManagerInfo - Added broadcast_24_piece0 in memory on DESKTOP-618L1DH:59186 (size: 9.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:46] INFO  SparkContext - Created broadcast 24 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:46] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[78] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Adding task set 58.0 with 1 tasks resource profile 0
[2025-10-03 20:39:46] INFO  TaskSetManager - Starting task 0.0 in stage 58.0 (TID 23) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:46] INFO  Executor - Running task 0.0 in stage 58.0 (TID 23)
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 17.6117 ms
[2025-10-03 20:39:46] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:46] INFO  Executor - Finished task 0.0 in stage 58.0 (TID 23). 1845 bytes result sent to driver
[2025-10-03 20:39:46] INFO  TaskSetManager - Finished task 0.0 in stage 58.0 (TID 23) in 292 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Removed TaskSet 58.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:46] INFO  DAGScheduler - ShuffleMapStage 58 (collectAsList at SQLQueries.java:154) finished in 0.324 s
[2025-10-03 20:39:46] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:46] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:46] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:46] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 10.5505 ms
[2025-10-03 20:39:46] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:46] INFO  DAGScheduler - Got job 24 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:46] INFO  DAGScheduler - Final stage: ResultStage 60 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:46] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 59)
[2025-10-03 20:39:46] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:46] INFO  DAGScheduler - Submitting ResultStage 60 (MapPartitionsRDD[81] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:46] INFO  MemoryStore - Block broadcast_25 stored as values in memory (estimated size 20.6 KiB, free 2.2 GiB)
[2025-10-03 20:39:46] INFO  MemoryStore - Block broadcast_25_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 2.2 GiB)
[2025-10-03 20:39:46] INFO  BlockManagerInfo - Added broadcast_25_piece0 in memory on DESKTOP-618L1DH:59186 (size: 7.9 KiB, free: 2.2 GiB)
[2025-10-03 20:39:46] INFO  SparkContext - Created broadcast 25 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:46] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[81] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Adding task set 60.0 with 1 tasks resource profile 0
[2025-10-03 20:39:46] INFO  TaskSetManager - Starting task 0.0 in stage 60.0 (TID 24) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:46] INFO  Executor - Running task 0.0 in stage 60.0 (TID 24)
[2025-10-03 20:39:46] INFO  ShuffleBlockFetcherIterator - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:46] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:46] INFO  BlockManagerInfo - Removed broadcast_24_piece0 on DESKTOP-618L1DH:59186 in memory (size: 9.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:46] INFO  BlockManagerInfo - Removed broadcast_18_piece0 on DESKTOP-618L1DH:59186 in memory (size: 27.9 KiB, free: 2.2 GiB)
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 29.9496 ms
[2025-10-03 20:39:46] INFO  BlockManagerInfo - Removed broadcast_19_piece0 on DESKTOP-618L1DH:59186 in memory (size: 26.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:46] INFO  Executor - Finished task 0.0 in stage 60.0 (TID 24). 3977 bytes result sent to driver
[2025-10-03 20:39:46] INFO  BlockManagerInfo - Removed broadcast_22_piece0 on DESKTOP-618L1DH:59186 in memory (size: 9.9 KiB, free: 2.2 GiB)
[2025-10-03 20:39:46] INFO  TaskSetManager - Finished task 0.0 in stage 60.0 (TID 24) in 47 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Removed TaskSet 60.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:46] INFO  DAGScheduler - ResultStage 60 (collectAsList at SQLQueries.java:154) finished in 0.057 s
[2025-10-03 20:39:46] INFO  DAGScheduler - Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Killing all running tasks in stage 60: Stage finished
[2025-10-03 20:39:46] INFO  DAGScheduler - Job 24 finished: collectAsList at SQLQueries.java:154, took 0.062769 s
[2025-10-03 20:39:46] INFO  BlockManagerInfo - Removed broadcast_21_piece0 on DESKTOP-618L1DH:59186 in memory (size: 24.6 KiB, free: 2.2 GiB)
[2025-10-03 20:39:46] INFO  BlockManagerInfo - Removed broadcast_23_piece0 on DESKTOP-618L1DH:59186 in memory (size: 7.9 KiB, free: 2.2 GiB)
[2025-10-03 20:39:46] INFO  BlockManagerInfo - Removed broadcast_20_piece0 on DESKTOP-618L1DH:59186 in memory (size: 27.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 10.3477 ms
[2025-10-03 20:39:46] INFO  SQLQueries - [8.9264373E7,1.5427864E7,4.9141353E7,451262.0,1.0410157E8]
[2025-10-03 20:39:46] INFO  SQLQueries - Task 7.3 - Average delay by minutes
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 10.7234 ms
[2025-10-03 20:39:46] INFO  DAGScheduler - Registering RDD 84 (collectAsList at SQLQueries.java:154) as input to shuffle 15
[2025-10-03 20:39:46] INFO  DAGScheduler - Got map stage job 25 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:46] INFO  DAGScheduler - Final stage: ShuffleMapStage 61 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:46] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:46] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:46] INFO  DAGScheduler - Submitting ShuffleMapStage 61 (MapPartitionsRDD[84] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:46] INFO  MemoryStore - Block broadcast_26 stored as values in memory (estimated size 18.7 KiB, free 2.2 GiB)
[2025-10-03 20:39:46] INFO  MemoryStore - Block broadcast_26_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 2.2 GiB)
[2025-10-03 20:39:46] INFO  BlockManagerInfo - Added broadcast_26_piece0 in memory on DESKTOP-618L1DH:59186 (size: 9.0 KiB, free: 2.2 GiB)
[2025-10-03 20:39:46] INFO  SparkContext - Created broadcast 26 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:46] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[84] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Adding task set 61.0 with 1 tasks resource profile 0
[2025-10-03 20:39:46] INFO  TaskSetManager - Starting task 0.0 in stage 61.0 (TID 25) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:46] INFO  Executor - Running task 0.0 in stage 61.0 (TID 25)
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 17.4417 ms
[2025-10-03 20:39:46] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:46] INFO  Executor - Finished task 0.0 in stage 61.0 (TID 25). 1845 bytes result sent to driver
[2025-10-03 20:39:46] INFO  TaskSetManager - Finished task 0.0 in stage 61.0 (TID 25) in 134 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Removed TaskSet 61.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:46] INFO  DAGScheduler - ShuffleMapStage 61 (collectAsList at SQLQueries.java:154) finished in 0.143 s
[2025-10-03 20:39:46] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:46] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:46] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:46] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 9.8667 ms
[2025-10-03 20:39:46] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:46] INFO  DAGScheduler - Got job 26 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:46] INFO  DAGScheduler - Final stage: ResultStage 63 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:46] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 62)
[2025-10-03 20:39:46] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:46] INFO  DAGScheduler - Submitting ResultStage 63 (MapPartitionsRDD[87] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:46] INFO  MemoryStore - Block broadcast_27 stored as values in memory (estimated size 15.9 KiB, free 2.2 GiB)
[2025-10-03 20:39:46] INFO  MemoryStore - Block broadcast_27_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 2.2 GiB)
[2025-10-03 20:39:46] INFO  BlockManagerInfo - Added broadcast_27_piece0 in memory on DESKTOP-618L1DH:59186 (size: 7.0 KiB, free: 2.2 GiB)
[2025-10-03 20:39:46] INFO  SparkContext - Created broadcast 27 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:46] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[87] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Adding task set 63.0 with 1 tasks resource profile 0
[2025-10-03 20:39:46] INFO  TaskSetManager - Starting task 0.0 in stage 63.0 (TID 26) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:46] INFO  Executor - Running task 0.0 in stage 63.0 (TID 26)
[2025-10-03 20:39:46] INFO  ShuffleBlockFetcherIterator - Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:46] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 9.5412 ms
[2025-10-03 20:39:46] INFO  Executor - Finished task 0.0 in stage 63.0 (TID 26). 3952 bytes result sent to driver
[2025-10-03 20:39:46] INFO  TaskSetManager - Finished task 0.0 in stage 63.0 (TID 26) in 23 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Removed TaskSet 63.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:46] INFO  DAGScheduler - ResultStage 63 (collectAsList at SQLQueries.java:154) finished in 0.029 s
[2025-10-03 20:39:46] INFO  DAGScheduler - Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:46] INFO  TaskSchedulerImpl - Killing all running tasks in stage 63: Stage finished
[2025-10-03 20:39:46] INFO  DAGScheduler - Job 26 finished: collectAsList at SQLQueries.java:154, took 0.032994 s
[2025-10-03 20:39:46] INFO  CodeGenerator - Code generated in 5.3598 ms
[2025-10-03 20:39:46] INFO  SQLQueries - [71.22849830659295]
[2025-10-03 20:39:46] INFO  SQLQueries - Task 7.4 - Yearly delay trend
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 30.0978 ms
[2025-10-03 20:39:47] INFO  DAGScheduler - Registering RDD 90 (collectAsList at SQLQueries.java:154) as input to shuffle 16
[2025-10-03 20:39:47] INFO  DAGScheduler - Got map stage job 27 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:47] INFO  DAGScheduler - Final stage: ShuffleMapStage 64 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:47] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:47] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:47] INFO  DAGScheduler - Submitting ShuffleMapStage 64 (MapPartitionsRDD[90] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:47] INFO  MemoryStore - Block broadcast_28 stored as values in memory (estimated size 65.4 KiB, free 2.2 GiB)
[2025-10-03 20:39:47] INFO  MemoryStore - Block broadcast_28_piece0 stored as bytes in memory (estimated size 25.3 KiB, free 2.2 GiB)
[2025-10-03 20:39:47] INFO  BlockManagerInfo - Added broadcast_28_piece0 in memory on DESKTOP-618L1DH:59186 (size: 25.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:47] INFO  SparkContext - Created broadcast 28 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:47] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[90] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Adding task set 64.0 with 1 tasks resource profile 0
[2025-10-03 20:39:47] INFO  TaskSetManager - Starting task 0.0 in stage 64.0 (TID 27) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:47] INFO  Executor - Running task 0.0 in stage 64.0 (TID 27)
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 42.2214 ms
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 8.9318 ms
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 11.2551 ms
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 10.4735 ms
[2025-10-03 20:39:47] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:47] INFO  Executor - Finished task 0.0 in stage 64.0 (TID 27). 2408 bytes result sent to driver
[2025-10-03 20:39:47] INFO  TaskSetManager - Finished task 0.0 in stage 64.0 (TID 27) in 417 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Removed TaskSet 64.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:47] INFO  DAGScheduler - ShuffleMapStage 64 (collectAsList at SQLQueries.java:154) finished in 0.431 s
[2025-10-03 20:39:47] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:47] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:47] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:47] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:47] INFO  ShufflePartitionsUtil - For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:47] INFO  HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 18.8952 ms
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 3.8158 ms
[2025-10-03 20:39:47] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:47] INFO  DAGScheduler - Got job 28 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:47] INFO  DAGScheduler - Final stage: ResultStage 66 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:47] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 65)
[2025-10-03 20:39:47] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:47] INFO  DAGScheduler - Submitting ResultStage 66 (MapPartitionsRDD[95] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:47] INFO  MemoryStore - Block broadcast_29 stored as values in memory (estimated size 79.7 KiB, free 2.2 GiB)
[2025-10-03 20:39:47] INFO  MemoryStore - Block broadcast_29_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:47] INFO  BlockManagerInfo - Added broadcast_29_piece0 in memory on DESKTOP-618L1DH:59186 (size: 30.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:47] INFO  SparkContext - Created broadcast 29 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:47] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[95] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Adding task set 66.0 with 1 tasks resource profile 0
[2025-10-03 20:39:47] INFO  TaskSetManager - Starting task 0.0 in stage 66.0 (TID 28) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:47] INFO  Executor - Running task 0.0 in stage 66.0 (TID 28)
[2025-10-03 20:39:47] INFO  ShuffleBlockFetcherIterator - Getting 1 (351.0 B) non-empty blocks including 1 (351.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:47] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:47] INFO  BlockManagerInfo - Removed broadcast_25_piece0 on DESKTOP-618L1DH:59186 in memory (size: 7.9 KiB, free: 2.2 GiB)
[2025-10-03 20:39:47] INFO  BlockManagerInfo - Removed broadcast_26_piece0 on DESKTOP-618L1DH:59186 in memory (size: 9.0 KiB, free: 2.2 GiB)
[2025-10-03 20:39:47] INFO  BlockManagerInfo - Removed broadcast_28_piece0 on DESKTOP-618L1DH:59186 in memory (size: 25.3 KiB, free: 2.2 GiB)
[2025-10-03 20:39:47] INFO  BlockManagerInfo - Removed broadcast_27_piece0 on DESKTOP-618L1DH:59186 in memory (size: 7.0 KiB, free: 2.2 GiB)
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 24.6189 ms
[2025-10-03 20:39:47] INFO  Executor - Finished task 0.0 in stage 66.0 (TID 28). 5136 bytes result sent to driver
[2025-10-03 20:39:47] INFO  TaskSetManager - Finished task 0.0 in stage 66.0 (TID 28) in 40 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Removed TaskSet 66.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:47] INFO  DAGScheduler - ResultStage 66 (collectAsList at SQLQueries.java:154) finished in 0.047 s
[2025-10-03 20:39:47] INFO  DAGScheduler - Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Killing all running tasks in stage 66: Stage finished
[2025-10-03 20:39:47] INFO  DAGScheduler - Job 28 finished: collectAsList at SQLQueries.java:154, took 0.051201 s
[2025-10-03 20:39:47] INFO  DAGScheduler - Registering RDD 96 (collectAsList at SQLQueries.java:154) as input to shuffle 17
[2025-10-03 20:39:47] INFO  DAGScheduler - Got map stage job 29 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:47] INFO  DAGScheduler - Final stage: ShuffleMapStage 68 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:47] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 67)
[2025-10-03 20:39:47] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:47] INFO  DAGScheduler - Submitting ShuffleMapStage 68 (MapPartitionsRDD[96] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:47] INFO  MemoryStore - Block broadcast_30 stored as values in memory (estimated size 80.0 KiB, free 2.2 GiB)
[2025-10-03 20:39:47] INFO  MemoryStore - Block broadcast_30_piece0 stored as bytes in memory (estimated size 30.4 KiB, free 2.2 GiB)
[2025-10-03 20:39:47] INFO  BlockManagerInfo - Added broadcast_30_piece0 in memory on DESKTOP-618L1DH:59186 (size: 30.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:47] INFO  SparkContext - Created broadcast 30 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:47] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[96] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Adding task set 68.0 with 1 tasks resource profile 0
[2025-10-03 20:39:47] INFO  TaskSetManager - Starting task 0.0 in stage 68.0 (TID 29) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-03 20:39:47] INFO  Executor - Running task 0.0 in stage 68.0 (TID 29)
[2025-10-03 20:39:47] INFO  ShuffleBlockFetcherIterator - Getting 1 (351.0 B) non-empty blocks including 1 (351.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:47] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:47] INFO  Executor - Finished task 0.0 in stage 68.0 (TID 29). 4990 bytes result sent to driver
[2025-10-03 20:39:47] INFO  TaskSetManager - Finished task 0.0 in stage 68.0 (TID 29) in 31 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Removed TaskSet 68.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:47] INFO  DAGScheduler - ShuffleMapStage 68 (collectAsList at SQLQueries.java:154) finished in 0.040 s
[2025-10-03 20:39:47] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:47] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:47] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:47] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:47] INFO  ShufflePartitionsUtil - For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:47] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:47] INFO  DAGScheduler - Got job 30 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:47] INFO  DAGScheduler - Final stage: ResultStage 71 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:47] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 70)
[2025-10-03 20:39:47] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:47] INFO  DAGScheduler - Submitting ResultStage 71 (MapPartitionsRDD[99] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:47] INFO  MemoryStore - Block broadcast_31 stored as values in memory (estimated size 61.6 KiB, free 2.2 GiB)
[2025-10-03 20:39:47] INFO  MemoryStore - Block broadcast_31_piece0 stored as bytes in memory (estimated size 25.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:47] INFO  BlockManagerInfo - Added broadcast_31_piece0 in memory on DESKTOP-618L1DH:59186 (size: 25.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:47] INFO  SparkContext - Created broadcast 31 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:47] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[99] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Adding task set 71.0 with 1 tasks resource profile 0
[2025-10-03 20:39:47] INFO  TaskSetManager - Starting task 0.0 in stage 71.0 (TID 30) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:47] INFO  Executor - Running task 0.0 in stage 71.0 (TID 30)
[2025-10-03 20:39:47] INFO  ShuffleBlockFetcherIterator - Getting 1 (240.0 B) non-empty blocks including 1 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:47] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:47] INFO  Executor - Finished task 0.0 in stage 71.0 (TID 30). 6380 bytes result sent to driver
[2025-10-03 20:39:47] INFO  TaskSetManager - Finished task 0.0 in stage 71.0 (TID 30) in 13 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Removed TaskSet 71.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:47] INFO  DAGScheduler - ResultStage 71 (collectAsList at SQLQueries.java:154) finished in 0.020 s
[2025-10-03 20:39:47] INFO  DAGScheduler - Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Killing all running tasks in stage 71: Stage finished
[2025-10-03 20:39:47] INFO  DAGScheduler - Job 30 finished: collectAsList at SQLQueries.java:154, took 0.024485 s
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 4.0281 ms
[2025-10-03 20:39:47] INFO  SQLQueries - [2023,1.02137544E8,1464741,69.74]
[2025-10-03 20:39:47] INFO  SQLQueries - [2024,1.10468988E8,1531462,72.15]
[2025-10-03 20:39:47] INFO  SQLQueries - [2025,4.577989E7,632112,72.44]
[2025-10-03 20:39:47] INFO  SQLQueries - Task 7.5 - Cancellations by carrier & year
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 3.2563 ms
[2025-10-03 20:39:47] INFO  DAGScheduler - Registering RDD 103 (collectAsList at SQLQueries.java:154) as input to shuffle 18
[2025-10-03 20:39:47] INFO  DAGScheduler - Got map stage job 31 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:47] INFO  DAGScheduler - Final stage: ShuffleMapStage 72 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:47] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:47] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:47] INFO  DAGScheduler - Submitting ShuffleMapStage 72 (MapPartitionsRDD[103] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:47] INFO  MemoryStore - Block broadcast_32 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:47] INFO  MemoryStore - Block broadcast_32_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:47] INFO  BlockManagerInfo - Added broadcast_32_piece0 in memory on DESKTOP-618L1DH:59186 (size: 7.8 KiB, free: 2.2 GiB)
[2025-10-03 20:39:47] INFO  SparkContext - Created broadcast 32 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:47] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[103] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Adding task set 72.0 with 1 tasks resource profile 0
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 5.3751 ms
[2025-10-03 20:39:47] INFO  TaskSetManager - Starting task 0.0 in stage 72.0 (TID 31) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:47] INFO  Executor - Running task 0.0 in stage 72.0 (TID 31)
[2025-10-03 20:39:47] INFO  DAGScheduler - Registering RDD 105 (collectAsList at SQLQueries.java:154) as input to shuffle 19
[2025-10-03 20:39:47] INFO  DAGScheduler - Got map stage job 32 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:47] INFO  DAGScheduler - Final stage: ShuffleMapStage 73 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:47] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-03 20:39:47] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:47] INFO  DAGScheduler - Submitting ShuffleMapStage 73 (MapPartitionsRDD[105] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:47] INFO  MemoryStore - Block broadcast_33 stored as values in memory (estimated size 14.9 KiB, free 2.2 GiB)
[2025-10-03 20:39:47] INFO  MemoryStore - Block broadcast_33_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 2.2 GiB)
[2025-10-03 20:39:47] INFO  BlockManagerInfo - Added broadcast_33_piece0 in memory on DESKTOP-618L1DH:59186 (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-03 20:39:47] INFO  SparkContext - Created broadcast 33 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:47] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[105] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Adding task set 73.0 with 1 tasks resource profile 0
[2025-10-03 20:39:47] INFO  TaskSetManager - Starting task 0.0 in stage 73.0 (TID 32) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-03 20:39:47] INFO  Executor - Running task 0.0 in stage 73.0 (TID 32)
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 3.6838 ms
[2025-10-03 20:39:47] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 3.1832 ms
[2025-10-03 20:39:47] INFO  CodeGenerator - Code generated in 6.1402 ms
[2025-10-03 20:39:47] INFO  Executor - Finished task 0.0 in stage 73.0 (TID 32). 1906 bytes result sent to driver
[2025-10-03 20:39:47] INFO  TaskSetManager - Finished task 0.0 in stage 73.0 (TID 32) in 64 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:47] INFO  TaskSchedulerImpl - Removed TaskSet 73.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:47] INFO  DAGScheduler - ShuffleMapStage 73 (collectAsList at SQLQueries.java:154) finished in 0.069 s
[2025-10-03 20:39:47] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:47] INFO  DAGScheduler - running: Set(ShuffleMapStage 72)
[2025-10-03 20:39:47] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:47] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:47] INFO  JDBCRDD - closed connection
[2025-10-03 20:39:48] INFO  Executor - Finished task 0.0 in stage 72.0 (TID 31). 1906 bytes result sent to driver
[2025-10-03 20:39:48] INFO  TaskSetManager - Finished task 0.0 in stage 72.0 (TID 31) in 133 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:48] INFO  TaskSchedulerImpl - Removed TaskSet 72.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:48] INFO  DAGScheduler - ShuffleMapStage 72 (collectAsList at SQLQueries.java:154) finished in 0.139 s
[2025-10-03 20:39:48] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:48] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:48] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:48] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:48] INFO  ShufflePartitionsUtil - For shuffle(18, 19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 18.5643 ms
[2025-10-03 20:39:48] INFO  DAGScheduler - Registering RDD 112 (collectAsList at SQLQueries.java:154) as input to shuffle 20
[2025-10-03 20:39:48] INFO  DAGScheduler - Got map stage job 33 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:48] INFO  DAGScheduler - Final stage: ShuffleMapStage 76 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:48] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 74, ShuffleMapStage 75)
[2025-10-03 20:39:48] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:48] INFO  DAGScheduler - Submitting ShuffleMapStage 76 (MapPartitionsRDD[112] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:48] INFO  MemoryStore - Block broadcast_34 stored as values in memory (estimated size 65.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:48] INFO  MemoryStore - Block broadcast_34_piece0 stored as bytes in memory (estimated size 28.5 KiB, free 2.2 GiB)
[2025-10-03 20:39:48] INFO  BlockManagerInfo - Added broadcast_34_piece0 in memory on DESKTOP-618L1DH:59186 (size: 28.5 KiB, free: 2.2 GiB)
[2025-10-03 20:39:48] INFO  SparkContext - Created broadcast 34 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:48] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[112] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:48] INFO  TaskSchedulerImpl - Adding task set 76.0 with 1 tasks resource profile 0
[2025-10-03 20:39:48] INFO  TaskSetManager - Starting task 0.0 in stage 76.0 (TID 33) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9270 bytes) 
[2025-10-03 20:39:48] INFO  Executor - Running task 0.0 in stage 76.0 (TID 33)
[2025-10-03 20:39:48] INFO  ShuffleBlockFetcherIterator - Getting 1 (429.4 KiB) non-empty blocks including 1 (429.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:48] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 4.4497 ms
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 4.6769 ms
[2025-10-03 20:39:48] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.0 KiB) non-empty blocks including 1 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:48] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 25.4402 ms
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 8.8394 ms
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 4.9771 ms
[2025-10-03 20:39:48] INFO  Executor - Finished task 0.0 in stage 76.0 (TID 33). 6814 bytes result sent to driver
[2025-10-03 20:39:48] INFO  TaskSetManager - Finished task 0.0 in stage 76.0 (TID 33) in 316 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:48] INFO  TaskSchedulerImpl - Removed TaskSet 76.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:48] INFO  DAGScheduler - ShuffleMapStage 76 (collectAsList at SQLQueries.java:154) finished in 0.324 s
[2025-10-03 20:39:48] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:48] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:48] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:48] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:48] INFO  ShufflePartitionsUtil - For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:48] INFO  HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 11.7094 ms
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 4.2659 ms
[2025-10-03 20:39:48] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:48] INFO  DAGScheduler - Got job 34 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:48] INFO  DAGScheduler - Final stage: ResultStage 80 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:48] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 79)
[2025-10-03 20:39:48] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:48] INFO  DAGScheduler - Submitting ResultStage 80 (MapPartitionsRDD[117] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:48] INFO  MemoryStore - Block broadcast_35 stored as values in memory (estimated size 58.8 KiB, free 2.2 GiB)
[2025-10-03 20:39:48] INFO  MemoryStore - Block broadcast_35_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 2.2 GiB)
[2025-10-03 20:39:48] INFO  BlockManagerInfo - Added broadcast_35_piece0 in memory on DESKTOP-618L1DH:59186 (size: 25.5 KiB, free: 2.2 GiB)
[2025-10-03 20:39:48] INFO  SparkContext - Created broadcast 35 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:48] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[117] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:48] INFO  TaskSchedulerImpl - Adding task set 80.0 with 1 tasks resource profile 0
[2025-10-03 20:39:48] INFO  TaskSetManager - Starting task 0.0 in stage 80.0 (TID 34) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:48] INFO  Executor - Running task 0.0 in stage 80.0 (TID 34)
[2025-10-03 20:39:48] INFO  ShuffleBlockFetcherIterator - Getting 1 (6.4 KiB) non-empty blocks including 1 (6.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:48] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 10.8808 ms
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 4.0421 ms
[2025-10-03 20:39:48] INFO  Executor - Finished task 0.0 in stage 80.0 (TID 34). 11301 bytes result sent to driver
[2025-10-03 20:39:48] INFO  TaskSetManager - Finished task 0.0 in stage 80.0 (TID 34) in 35 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:48] INFO  TaskSchedulerImpl - Removed TaskSet 80.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:48] INFO  DAGScheduler - ResultStage 80 (collectAsList at SQLQueries.java:154) finished in 0.042 s
[2025-10-03 20:39:48] INFO  DAGScheduler - Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:48] INFO  TaskSchedulerImpl - Killing all running tasks in stage 80: Stage finished
[2025-10-03 20:39:48] INFO  DAGScheduler - Job 34 finished: collectAsList at SQLQueries.java:154, took 0.046836 s
[2025-10-03 20:39:48] INFO  DAGScheduler - Registering RDD 118 (collectAsList at SQLQueries.java:154) as input to shuffle 21
[2025-10-03 20:39:48] INFO  DAGScheduler - Got map stage job 35 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:48] INFO  DAGScheduler - Final stage: ShuffleMapStage 84 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:48] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 83)
[2025-10-03 20:39:48] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:48] INFO  DAGScheduler - Submitting ShuffleMapStage 84 (MapPartitionsRDD[118] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:48] INFO  MemoryStore - Block broadcast_36 stored as values in memory (estimated size 62.4 KiB, free 2.2 GiB)
[2025-10-03 20:39:48] INFO  MemoryStore - Block broadcast_36_piece0 stored as bytes in memory (estimated size 26.2 KiB, free 2.2 GiB)
[2025-10-03 20:39:48] INFO  BlockManagerInfo - Added broadcast_36_piece0 in memory on DESKTOP-618L1DH:59186 (size: 26.2 KiB, free: 2.2 GiB)
[2025-10-03 20:39:48] INFO  SparkContext - Created broadcast 36 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:48] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[118] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:48] INFO  TaskSchedulerImpl - Adding task set 84.0 with 1 tasks resource profile 0
[2025-10-03 20:39:48] INFO  TaskSetManager - Starting task 0.0 in stage 84.0 (TID 35) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-03 20:39:48] INFO  Executor - Running task 0.0 in stage 84.0 (TID 35)
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 4.0334 ms
[2025-10-03 20:39:48] INFO  ShuffleBlockFetcherIterator - Getting 1 (6.4 KiB) non-empty blocks including 1 (6.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:48] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:48] INFO  Executor - Finished task 0.0 in stage 84.0 (TID 35). 8255 bytes result sent to driver
[2025-10-03 20:39:48] INFO  TaskSetManager - Finished task 0.0 in stage 84.0 (TID 35) in 123 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:48] INFO  TaskSchedulerImpl - Removed TaskSet 84.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:48] INFO  DAGScheduler - ShuffleMapStage 84 (collectAsList at SQLQueries.java:154) finished in 0.131 s
[2025-10-03 20:39:48] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-03 20:39:48] INFO  DAGScheduler - running: Set()
[2025-10-03 20:39:48] INFO  DAGScheduler - waiting: Set()
[2025-10-03 20:39:48] INFO  DAGScheduler - failed: Set()
[2025-10-03 20:39:48] INFO  ShufflePartitionsUtil - For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-03 20:39:48] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:154
[2025-10-03 20:39:48] INFO  DAGScheduler - Got job 36 (collectAsList at SQLQueries.java:154) with 1 output partitions
[2025-10-03 20:39:48] INFO  DAGScheduler - Final stage: ResultStage 89 (collectAsList at SQLQueries.java:154)
[2025-10-03 20:39:48] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 88)
[2025-10-03 20:39:48] INFO  DAGScheduler - Missing parents: List()
[2025-10-03 20:39:48] INFO  DAGScheduler - Submitting ResultStage 89 (MapPartitionsRDD[121] at collectAsList at SQLQueries.java:154), which has no missing parents
[2025-10-03 20:39:48] INFO  MemoryStore - Block broadcast_37 stored as values in memory (estimated size 52.4 KiB, free 2.2 GiB)
[2025-10-03 20:39:48] INFO  MemoryStore - Block broadcast_37_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 2.2 GiB)
[2025-10-03 20:39:48] INFO  BlockManagerInfo - Added broadcast_37_piece0 in memory on DESKTOP-618L1DH:59186 (size: 23.4 KiB, free: 2.2 GiB)
[2025-10-03 20:39:48] INFO  SparkContext - Created broadcast 37 from broadcast at DAGScheduler.scala:1611
[2025-10-03 20:39:48] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[121] at collectAsList at SQLQueries.java:154) (first 15 tasks are for partitions Vector(0))
[2025-10-03 20:39:48] INFO  TaskSchedulerImpl - Adding task set 89.0 with 1 tasks resource profile 0
[2025-10-03 20:39:48] INFO  TaskSetManager - Starting task 0.0 in stage 89.0 (TID 36) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-03 20:39:48] INFO  Executor - Running task 0.0 in stage 89.0 (TID 36)
[2025-10-03 20:39:48] INFO  ShuffleBlockFetcherIterator - Getting 1 (7.1 KiB) non-empty blocks including 1 (7.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-03 20:39:48] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 3.6861 ms
[2025-10-03 20:39:48] INFO  Executor - Finished task 0.0 in stage 89.0 (TID 36). 11012 bytes result sent to driver
[2025-10-03 20:39:48] INFO  TaskSetManager - Finished task 0.0 in stage 89.0 (TID 36) in 18 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-03 20:39:48] INFO  TaskSchedulerImpl - Removed TaskSet 89.0, whose tasks have all completed, from pool 
[2025-10-03 20:39:48] INFO  DAGScheduler - ResultStage 89 (collectAsList at SQLQueries.java:154) finished in 0.025 s
[2025-10-03 20:39:48] INFO  DAGScheduler - Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-03 20:39:48] INFO  TaskSchedulerImpl - Killing all running tasks in stage 89: Stage finished
[2025-10-03 20:39:48] INFO  DAGScheduler - Job 36 finished: collectAsList at SQLQueries.java:154, took 0.028856 s
[2025-10-03 20:39:48] INFO  CodeGenerator - Code generated in 5.3292 ms
[2025-10-03 20:39:48] INFO  SQLQueries - [9E,ENDEAVOR AIR INC.,2023,4233,373]
[2025-10-03 20:39:48] INFO  SQLQueries - [AA,AMERICAN AIRLINES INC.,2023,9978,2495]
[2025-10-03 20:39:48] INFO  SQLQueries - [AS,ALASKA AIRLINES INC.,2023,1977,724]
[2025-10-03 20:39:48] INFO  SQLQueries - [B6,JETBLUE AIRWAYS,2023,5763,1174]
[2025-10-03 20:39:48] INFO  SQLQueries - [C5,COMMUTEAIR LLC DBA COMMUTEAIR,2023,1027,209]
[2025-10-03 20:39:48] INFO  SQLQueries - [DL,DELTA AIRLINES INC.,2023,10016,2039]
[2025-10-03 20:39:48] INFO  SQLQueries - [F9,FRONTIER AIRLINES INC.,2023,3774,309]
[2025-10-03 20:39:48] INFO  SQLQueries - [G4,ALLEGIANT AIR,2023,782,332]
[2025-10-03 20:39:48] INFO  SQLQueries - [G7,GOJET AIRLINES LLC D/B/A UNITED EXPRESS,2023,1474,79]
[2025-10-03 20:39:48] INFO  SQLQueries - [HA,HAWAIIAN AIRLINES INC.,2023,1053,72]
[2025-10-03 20:39:48] INFO  SQLQueries - [MQ,ENVOY AIR,2023,2193,503]
[2025-10-03 20:39:48] INFO  SQLQueries - [NK,SPIRIT AIRLINES,2023,4486,547]
[2025-10-03 20:39:48] INFO  SQLQueries - [OH,PSA AIRLINES INC.,2023,2461,502]
[2025-10-03 20:39:48] INFO  SQLQueries - [OO,SKYWEST AIRLINES INC.,2023,8186,2051]
[2025-10-03 20:39:48] INFO  SQLQueries - [PT,PIEDMONT AIRLINES,2023,685,387]
[2025-10-03 20:39:48] INFO  SQLQueries - [QX,HORIZON AIR,2023,490,128]
[2025-10-03 20:39:48] INFO  SQLQueries - [UA,UNITED AIRLINES INC.,2023,10270,1910]
[2025-10-03 20:39:48] INFO  SQLQueries - [WN,SOUTHWEST AIRLINES CO.,2023,14325,2902]
[2025-10-03 20:39:48] INFO  SQLQueries - [YV,MESA AIRLINES INC.,2023,1767,295]
[2025-10-03 20:39:48] INFO  SQLQueries - [YX,REPUBLIC AIRLINE,2023,8160,622]
[2025-10-03 20:39:48] INFO  SQLQueries - [ZW,AIR WISCONSIN AIRLINES CORP,2023,797,144]
[2025-10-03 20:39:48] INFO  SQLQueries - [9E,ENDEAVOR AIR INC.,2024,4598,414]
[2025-10-03 20:39:48] INFO  SQLQueries - [AA,AMERICAN AIRLINES INC.,2024,15252,2938]
[2025-10-03 20:39:48] INFO  SQLQueries - [AS,ALASKA AIRLINES INC.,2024,4811,685]
[2025-10-03 20:39:48] INFO  SQLQueries - [B6,JETBLUE AIRWAYS,2024,3735,864]
[2025-10-03 20:39:48] INFO  SQLQueries - [C5,COMMUTEAIR LLC DBA COMMUTEAIR,2024,1465,235]
[2025-10-03 20:39:48] INFO  SQLQueries - [DL,DELTA AIRLINES INC.,2024,9147,2201]
[2025-10-03 20:39:48] INFO  SQLQueries - [F9,FRONTIER AIRLINES INC.,2024,4835,307]
[2025-10-03 20:39:48] INFO  SQLQueries - [G4,ALLEGIANT AIR,2024,2018,310]
[2025-10-03 20:39:48] INFO  SQLQueries - [G7,GOJET AIRLINES LLC D/B/A UNITED EXPRESS,2024,1100,151]
[2025-10-03 20:39:48] INFO  SQLQueries - [HA,HAWAIIAN AIRLINES INC.,2024,822,75]
[2025-10-03 20:39:48] INFO  SQLQueries - [MQ,ENVOY AIR,2024,3857,653]
[2025-10-03 20:39:48] INFO  SQLQueries - [NK,SPIRIT AIRLINES,2024,4998,472]
[2025-10-03 20:39:48] INFO  SQLQueries - [OH,PSA AIRLINES INC.,2024,3744,547]
[2025-10-03 20:39:48] INFO  SQLQueries - [OO,SKYWEST AIRLINES INC.,2024,8453,2245]
[2025-10-03 20:39:48] INFO  SQLQueries - [PT,PIEDMONT AIRLINES,2024,765,395]
[2025-10-03 20:39:48] INFO  SQLQueries - [QX,HORIZON AIR,2024,829,146]
[2025-10-03 20:39:48] INFO  SQLQueries - [UA,UNITED AIRLINES INC.,2024,12478,2155]
[2025-10-03 20:39:48] INFO  SQLQueries - [WN,SOUTHWEST AIRLINES CO.,2024,11772,3050]
[2025-10-03 20:39:48] INFO  SQLQueries - [YV,MESA AIRLINES INC.,2024,1901,291]
[2025-10-03 20:39:48] INFO  SQLQueries - [YX,REPUBLIC AIRLINE,2024,5564,583]
[2025-10-03 20:39:48] INFO  SQLQueries - [ZW,AIR WISCONSIN AIRLINES CORP,2024,764,114]
[2025-10-03 20:39:48] INFO  SQLQueries - [9E,ENDEAVOR AIR INC.,2025,1849,186]
[2025-10-03 20:39:48] INFO  SQLQueries - [AA,AMERICAN AIRLINES INC.,2025,7469,1129]
[2025-10-03 20:39:48] INFO  SQLQueries - [AS,ALASKA AIRLINES INC.,2025,919,229]
[2025-10-03 20:39:48] INFO  SQLQueries - [B6,JETBLUE AIRWAYS,2025,1084,347]
[2025-10-03 20:39:48] INFO  SQLQueries - [C5,COMMUTEAIR LLC DBA COMMUTEAIR,2025,917,97]
[2025-10-03 20:39:48] INFO  SQLQueries - [DL,DELTA AIRLINES INC.,2025,3342,928]
[2025-10-03 20:39:48] INFO  SQLQueries - [F9,FRONTIER AIRLINES INC.,2025,1341,157]
[2025-10-03 20:39:48] INFO  SQLQueries - [G4,ALLEGIANT AIR,2025,313,127]
[2025-10-03 20:39:48] INFO  SQLQueries - [G7,GOJET AIRLINES LLC D/B/A UNITED EXPRESS,2025,730,62]
[2025-10-03 20:39:48] INFO  SQLQueries - [HA,HAWAIIAN AIRLINES INC.,2025,352,41]
[2025-10-03 20:39:48] INFO  SQLQueries - [MQ,ENVOY AIR,2025,3219,270]
[2025-10-03 20:39:48] INFO  SQLQueries - [NK,SPIRIT AIRLINES,2025,1267,144]
[2025-10-03 20:39:48] INFO  SQLQueries - [OH,PSA AIRLINES INC.,2025,6176,279]
[2025-10-03 20:39:48] INFO  SQLQueries - [OO,SKYWEST AIRLINES INC.,2025,4708,1063]
[2025-10-03 20:39:48] INFO  SQLQueries - [PT,PIEDMONT AIRLINES,2025,921,212]
[2025-10-03 20:39:48] INFO  SQLQueries - [QX,HORIZON AIR,2025,496,64]
[2025-10-03 20:39:48] INFO  SQLQueries - [UA,UNITED AIRLINES INC.,2025,2464,782]
[2025-10-03 20:39:48] INFO  SQLQueries - [WN,SOUTHWEST AIRLINES CO.,2025,5806,1105]
[2025-10-03 20:39:48] INFO  SQLQueries - [YV,MESA AIRLINES INC.,2025,796,108]
[2025-10-03 20:39:48] INFO  SQLQueries - [YX,REPUBLIC AIRLINE,2025,3326,252]
[2025-10-03 20:39:48] INFO  SQLQueries - [ZW,AIR WISCONSIN AIRLINES CORP,2025,207,22]
[2025-10-03 20:39:48] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-03 20:39:48] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 20:39:48] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-03 20:39:48] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-03 20:39:48] INFO  MemoryStore - MemoryStore cleared
[2025-10-03 20:39:48] INFO  BlockManager - BlockManager stopped
[2025-10-03 20:39:48] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-03 20:39:48] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-03 20:39:48] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-03 20:39:48] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-03 20:39:48] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-deaafdbc-9f65-479e-aeb0-9183979f7db5
[2025-10-03 20:47:02] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-03 20:47:02] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-03 20:47:02] INFO  SparkContext - Java version 11.0.27
[2025-10-03 20:47:03] INFO  ResourceUtils - ==============================================================
[2025-10-03 20:47:03] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-03 20:47:03] INFO  ResourceUtils - ==============================================================
[2025-10-03 20:47:03] INFO  SparkContext - Submitted application: DataTransformationTest
[2025-10-03 20:47:03] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-03 20:47:03] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-03 20:47:03] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-03 20:47:03] INFO  SecurityManager - Changing view acls to: USER
[2025-10-03 20:47:03] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-03 20:47:03] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-03 20:47:03] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-03 20:47:03] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-03 20:47:04] INFO  Utils - Successfully started service 'sparkDriver' on port 50910.
[2025-10-03 20:47:04] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-03 20:47:04] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-03 20:47:04] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-03 20:47:04] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-03 20:47:04] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-03 20:47:04] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-99cafdab-1e2d-4d8d-b4a9-3301e4beec04
[2025-10-03 20:47:04] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-03 20:47:04] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-03 20:47:04] INFO  log - Logging initialized @3096ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-03 20:47:04] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-03 20:47:04] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-03 20:47:04] INFO  Server - Started @3388ms
[2025-10-03 20:47:04] INFO  AbstractConnector - Started ServerConnector@1de0641b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 20:47:04] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-03 20:47:04] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2cca611f{/,null,AVAILABLE,@Spark}
[2025-10-03 20:47:04] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-03 20:47:04] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-03 20:47:04] INFO  Executor - Java version 11.0.27
[2025-10-03 20:47:04] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-03 20:47:04] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1983b48a for default.
[2025-10-03 20:47:04] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50957.
[2025-10-03 20:47:04] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:50957
[2025-10-03 20:47:04] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-03 20:47:04] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 50957, None)
[2025-10-03 20:47:04] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:50957 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 50957, None)
[2025-10-03 20:47:04] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 50957, None)
[2025-10-03 20:47:04] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 50957, None)
[2025-10-03 20:47:05] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@2cca611f{/,null,STOPPED,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4b195203{/jobs,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@23444a36{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e0fdbe9{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@696b52bc{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f081b5d{/stages,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@740a0d5e{/stages/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@19f02280{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@19827608{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@14b528b6{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f930e0{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@78c262ba{/storage,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@329dc214{/storage/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@64021427{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@217dc48e{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@296edc75{/environment,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7aea704c{/environment/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@32507479{/executors,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4ae2e781{/executors/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2dd63e3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@209f3887{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b35798{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4702e7a5{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@73bb1337{/static,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1653b84e{/,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f85ee02{/api,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@33d7765a{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@56a4abd0{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5d1d9d73{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-03 20:47:05] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7a36c83a{/SQL,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7b297740{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1fe8f5e8{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6e3dd5ce{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-03 20:47:05] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@35563e4c{/static/sql,null,AVAILABLE,@Spark}
[2025-10-03 20:47:07] INFO  CodeGenerator - Code generated in 313.7412 ms
[2025-10-03 20:47:07] INFO  CodeGenerator - Code generated in 29.0035 ms
[2025-10-03 20:47:07] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-03 20:47:07] INFO  AbstractConnector - Stopped Spark@1de0641b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 20:47:07] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-03 20:47:08] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-03 20:47:08] INFO  MemoryStore - MemoryStore cleared
[2025-10-03 20:47:08] INFO  BlockManager - BlockManager stopped
[2025-10-03 20:47:08] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-03 20:47:08] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-03 20:47:08] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-03 20:47:08] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-03 20:47:08] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-3c78f92b-db20-463b-9394-116917c973a3
[2025-10-03 20:51:44] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-03 20:51:44] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-03 20:51:44] INFO  SparkContext - Java version 11.0.27
[2025-10-03 20:51:44] INFO  ResourceUtils - ==============================================================
[2025-10-03 20:51:44] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-03 20:51:44] INFO  ResourceUtils - ==============================================================
[2025-10-03 20:51:44] INFO  SparkContext - Submitted application: DataTransformationTest
[2025-10-03 20:51:44] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-03 20:51:44] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-03 20:51:44] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-03 20:51:45] INFO  SecurityManager - Changing view acls to: USER
[2025-10-03 20:51:45] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-03 20:51:45] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-03 20:51:45] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-03 20:51:45] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-03 20:51:46] INFO  Utils - Successfully started service 'sparkDriver' on port 58218.
[2025-10-03 20:51:46] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-03 20:51:46] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-03 20:51:46] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-03 20:51:46] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-03 20:51:46] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-03 20:51:46] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-a769bbf7-9d81-42bd-a133-6a77d659bfe0
[2025-10-03 20:51:46] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-03 20:51:46] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-03 20:51:46] INFO  log - Logging initialized @4465ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-03 20:51:46] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-03 20:51:46] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-03 20:51:46] INFO  Server - Started @4577ms
[2025-10-03 20:51:46] INFO  AbstractConnector - Started ServerConnector@1de0641b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 20:51:46] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2cca611f{/,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-03 20:51:46] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-03 20:51:46] INFO  Executor - Java version 11.0.27
[2025-10-03 20:51:46] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-03 20:51:46] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1983b48a for default.
[2025-10-03 20:51:46] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58265.
[2025-10-03 20:51:46] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:58265
[2025-10-03 20:51:46] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-03 20:51:46] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 58265, None)
[2025-10-03 20:51:46] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:58265 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 58265, None)
[2025-10-03 20:51:46] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 58265, None)
[2025-10-03 20:51:46] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 58265, None)
[2025-10-03 20:51:46] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@2cca611f{/,null,STOPPED,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4b195203{/jobs,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@23444a36{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e0fdbe9{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@696b52bc{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f081b5d{/stages,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@740a0d5e{/stages/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@19f02280{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@19827608{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@14b528b6{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f930e0{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@78c262ba{/storage,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@329dc214{/storage/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@64021427{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@217dc48e{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@296edc75{/environment,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7aea704c{/environment/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@32507479{/executors,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4ae2e781{/executors/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2dd63e3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@209f3887{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b35798{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4702e7a5{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@73bb1337{/static,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1653b84e{/,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f85ee02{/api,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@33d7765a{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@56a4abd0{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-03 20:51:46] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5d1d9d73{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:47] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-03 20:51:47] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-03 20:51:47] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7a36c83a{/SQL,null,AVAILABLE,@Spark}
[2025-10-03 20:51:47] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7b297740{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:47] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1fe8f5e8{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-03 20:51:47] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6e3dd5ce{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-03 20:51:47] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@35563e4c{/static/sql,null,AVAILABLE,@Spark}
[2025-10-03 20:51:50] INFO  CodeGenerator - Code generated in 236.5523 ms
[2025-10-03 20:51:50] INFO  CodeGenerator - Code generated in 37.8165 ms
[2025-10-03 20:51:50] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-03 20:51:50] INFO  AbstractConnector - Stopped Spark@1de0641b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 20:51:50] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-03 20:51:50] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-03 20:51:50] INFO  MemoryStore - MemoryStore cleared
[2025-10-03 20:51:50] INFO  BlockManager - BlockManager stopped
[2025-10-03 20:51:50] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-03 20:51:50] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-03 20:51:50] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-03 20:51:51] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-03 20:51:51] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-3b351932-6097-4431-a1d5-80e24683bed6
[2025-10-03 22:28:57] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-03 22:28:57] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-03 22:28:57] INFO  SparkContext - Java version 11.0.27
[2025-10-03 22:28:58] INFO  ResourceUtils - ==============================================================
[2025-10-03 22:28:58] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-03 22:28:58] INFO  ResourceUtils - ==============================================================
[2025-10-03 22:28:58] INFO  SparkContext - Submitted application: DataTransformationTest
[2025-10-03 22:28:58] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-03 22:28:58] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-03 22:28:58] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-03 22:28:58] INFO  SecurityManager - Changing view acls to: USER
[2025-10-03 22:28:58] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-03 22:28:58] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-03 22:28:58] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-03 22:28:58] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-03 22:28:59] INFO  Utils - Successfully started service 'sparkDriver' on port 56031.
[2025-10-03 22:28:59] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-03 22:28:59] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-03 22:28:59] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-03 22:28:59] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-03 22:28:59] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-03 22:28:59] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-cf17ee45-d6a6-42bb-9617-951be618d50d
[2025-10-03 22:28:59] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-03 22:28:59] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-03 22:28:59] INFO  log - Logging initialized @3759ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-03 22:28:59] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-03 22:28:59] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-03 22:28:59] INFO  Server - Started @3884ms
[2025-10-03 22:28:59] INFO  AbstractConnector - Started ServerConnector@3b83459e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 22:28:59] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@f1266c6{/,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-03 22:28:59] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-03 22:28:59] INFO  Executor - Java version 11.0.27
[2025-10-03 22:28:59] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-03 22:28:59] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@9b23822 for default.
[2025-10-03 22:28:59] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56078.
[2025-10-03 22:28:59] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:56078
[2025-10-03 22:28:59] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-03 22:28:59] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 56078, None)
[2025-10-03 22:28:59] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:56078 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 56078, None)
[2025-10-03 22:28:59] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 56078, None)
[2025-10-03 22:28:59] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 56078, None)
[2025-10-03 22:28:59] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@f1266c6{/,null,STOPPED,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@40943a6{/jobs,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@42679fc2{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@724bf25f{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f6cc7da{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@29f3c438{/stages,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5dbbb292{/stages/json,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1c046c92{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@643ba1ed{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@26582ca{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2c3158e0{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f731759{/storage,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@39549f33{/storage/json,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7a83ccd2{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@599a9cb2{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5e1a986c{/environment,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@46a795de{/environment/json,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2f3928ac{/executors,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@31834a2b{/executors/json,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@22ead351{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43d65a81{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7418d76e{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@11ede87f{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@44e4cb76{/static,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@446e7065{/,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b78c683{/api,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1625789b{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@c4d2c44{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-03 22:28:59] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3086f480{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-03 22:29:00] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-03 22:29:00] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-03 22:29:00] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3a0b6a{/SQL,null,AVAILABLE,@Spark}
[2025-10-03 22:29:00] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f1fa1d0{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-03 22:29:00] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2997ddfc{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-03 22:29:00] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@78d73b1b{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-03 22:29:00] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58d4238e{/static/sql,null,AVAILABLE,@Spark}
[2025-10-03 22:29:03] INFO  CodeGenerator - Code generated in 196.0967 ms
[2025-10-03 22:29:03] INFO  CodeGenerator - Code generated in 31.543 ms
[2025-10-03 22:29:03] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-03 22:29:03] INFO  AbstractConnector - Stopped Spark@3b83459e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-03 22:29:03] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-03 22:29:03] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-03 22:29:03] INFO  MemoryStore - MemoryStore cleared
[2025-10-03 22:29:03] INFO  BlockManager - BlockManager stopped
[2025-10-03 22:29:03] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-03 22:29:03] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-03 22:29:03] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-03 22:29:03] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-03 22:29:03] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-4f9e8acc-ee21-462d-a8e6-5be5a9bc7f3d
[2025-10-06 13:24:51] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-06 13:24:51] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-06 13:24:51] INFO  SparkContext - Java version 11.0.27
[2025-10-06 13:24:53] INFO  ResourceUtils - ==============================================================
[2025-10-06 13:24:53] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-06 13:24:53] INFO  ResourceUtils - ==============================================================
[2025-10-06 13:24:53] INFO  SparkContext - Submitted application: Airline Delay Data Cleaning
[2025-10-06 13:24:53] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-06 13:24:53] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-06 13:24:53] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-06 13:24:53] INFO  SecurityManager - Changing view acls to: USER
[2025-10-06 13:24:53] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-06 13:24:53] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-06 13:24:53] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-06 13:24:53] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-06 13:24:54] INFO  Utils - Successfully started service 'sparkDriver' on port 50910.
[2025-10-06 13:24:54] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-06 13:24:54] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-06 13:24:54] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-06 13:24:54] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-06 13:24:54] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-06 13:24:54] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-685dd6f6-8249-48ee-bf0f-976d83036ece
[2025-10-06 13:24:55] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-06 13:24:55] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-06 13:24:55] INFO  log - Logging initialized @5748ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-06 13:24:55] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-06 13:24:55] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-06 13:24:55] INFO  Server - Started @5932ms
[2025-10-06 13:24:55] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-06 13:24:55] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@244418a{/,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-06 13:24:55] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-06 13:24:55] INFO  Executor - Java version 11.0.27
[2025-10-06 13:24:55] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-06 13:24:55] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3d90eeb3 for default.
[2025-10-06 13:24:55] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50957.
[2025-10-06 13:24:55] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:50957
[2025-10-06 13:24:55] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-06 13:24:55] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 50957, None)
[2025-10-06 13:24:55] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:50957 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 50957, None)
[2025-10-06 13:24:55] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 50957, None)
[2025-10-06 13:24:55] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 50957, None)
[2025-10-06 13:24:55] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@244418a{/,null,STOPPED,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6cfbbff7{/jobs,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@45b32dfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@14c141c0{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@d611f1c{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@51fc862e{/stages,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@fe09383{/stages/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@f25f48a{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b2e5c0d{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5438c17a{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@429aeac1{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6b4fc2d1{/storage,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de4285e{/storage/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@634ff56{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5a484ce1{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2ffe243f{/environment,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4099209b{/environment/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1dad01fe{/executors,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3e3cd6fe{/executors/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@68b734a8{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4215e133{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@d88f893{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@48eaf42f{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2091833{/static,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1084ac45{/,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6ea246af{/api,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@17e0933c{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1dcedc93{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@38291795{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:55] INFO  DataCleaning - Loading from DB Table: bronze.raw_dataset
[2025-10-06 13:24:56] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-06 13:24:56] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-06 13:24:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6d6ac396{/SQL,null,AVAILABLE,@Spark}
[2025-10-06 13:24:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@f5a7226{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@100ad67e{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-06 13:24:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@62aeddc8{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-06 13:24:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@35bfa1bb{/static/sql,null,AVAILABLE,@Spark}
[2025-10-06 13:25:04] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_dataset
[2025-10-06 13:25:10] INFO  CodeGenerator - Code generated in 1273.6415 ms
[2025-10-06 13:25:11] INFO  DAGScheduler - Registering RDD 2 (save at DataCleaning.java:132) as input to shuffle 0
[2025-10-06 13:25:11] INFO  DAGScheduler - Got map stage job 0 (save at DataCleaning.java:132) with 1 output partitions
[2025-10-06 13:25:11] INFO  DAGScheduler - Final stage: ShuffleMapStage 0 (save at DataCleaning.java:132)
[2025-10-06 13:25:11] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-06 13:25:11] INFO  DAGScheduler - Missing parents: List()
[2025-10-06 13:25:11] INFO  DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at DataCleaning.java:132), which has no missing parents
[2025-10-06 13:25:11] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 75.7 KiB, free 2.2 GiB)
[2025-10-06 13:25:11] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-06 13:25:11] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on DESKTOP-618L1DH:50957 (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-06 13:25:11] INFO  SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1611
[2025-10-06 13:25:11] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at DataCleaning.java:132) (first 15 tasks are for partitions Vector(0))
[2025-10-06 13:25:11] INFO  TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
[2025-10-06 13:25:11] INFO  TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-06 13:25:11] INFO  Executor - Running task 0.0 in stage 0.0 (TID 0)
[2025-10-06 13:25:13] INFO  CodeGenerator - Code generated in 268.3335 ms
[2025-10-06 13:25:13] INFO  CodeGenerator - Code generated in 74.5701 ms
[2025-10-06 13:25:13] INFO  CodeGenerator - Code generated in 14.7196 ms
[2025-10-06 13:25:13] INFO  CodeGenerator - Code generated in 94.4703 ms
[2025-10-06 13:25:14] INFO  JDBCRDD - closed connection
[2025-10-06 13:25:17] INFO  Executor - Finished task 0.0 in stage 0.0 (TID 0). 2593 bytes result sent to driver
[2025-10-06 13:25:17] INFO  TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 5410 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-06 13:25:17] INFO  TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[2025-10-06 13:25:17] INFO  DAGScheduler - ShuffleMapStage 0 (save at DataCleaning.java:132) finished in 6.115 s
[2025-10-06 13:25:17] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-06 13:25:17] INFO  DAGScheduler - running: Set()
[2025-10-06 13:25:17] INFO  DAGScheduler - waiting: Set()
[2025-10-06 13:25:17] INFO  DAGScheduler - failed: Set()
[2025-10-06 13:25:17] INFO  ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-06 13:25:17] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:17] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-06 13:25:17] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-06 13:25:17] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:17] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-06 13:25:17] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-06 13:25:17] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:18] INFO  CodeGenerator - Code generated in 203.0661 ms
[2025-10-06 13:25:18] INFO  SparkContext - Starting job: save at DataCleaning.java:132
[2025-10-06 13:25:18] INFO  DAGScheduler - Got job 1 (save at DataCleaning.java:132) with 1 output partitions
[2025-10-06 13:25:18] INFO  DAGScheduler - Final stage: ResultStage 2 (save at DataCleaning.java:132)
[2025-10-06 13:25:18] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
[2025-10-06 13:25:18] INFO  DAGScheduler - Missing parents: List()
[2025-10-06 13:25:18] INFO  DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[6] at save at DataCleaning.java:132), which has no missing parents
[2025-10-06 13:25:18] INFO  MemoryStore - Block broadcast_1 stored as values in memory (estimated size 288.9 KiB, free 2.2 GiB)
[2025-10-06 13:25:18] INFO  MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 102.8 KiB, free 2.2 GiB)
[2025-10-06 13:25:18] INFO  BlockManagerInfo - Added broadcast_1_piece0 in memory on DESKTOP-618L1DH:50957 (size: 102.8 KiB, free: 2.2 GiB)
[2025-10-06 13:25:18] INFO  SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1611
[2025-10-06 13:25:18] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at save at DataCleaning.java:132) (first 15 tasks are for partitions Vector(0))
[2025-10-06 13:25:18] INFO  TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
[2025-10-06 13:25:18] INFO  TaskSetManager - Starting task 0.0 in stage 2.0 (TID 1) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9387 bytes) 
[2025-10-06 13:25:18] INFO  Executor - Running task 0.0 in stage 2.0 (TID 1)
[2025-10-06 13:25:18] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-06 13:25:18] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-06 13:25:18] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:18] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-06 13:25:18] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-06 13:25:18] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:18] INFO  CodecConfig - Compression: SNAPPY
[2025-10-06 13:25:18] INFO  CodecConfig - Compression: SNAPPY
[2025-10-06 13:25:18] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-06 13:25:18] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "year",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "month",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "airport",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "isSigned" : false,
      "scale" : 0
    }
  }, {
    "name" : "airport_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_flights",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_del15",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "weather_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "nas_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "security_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "late_aircraft_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_cancelled",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_diverted",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "weather_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "nas_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "security_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "late_aircraft_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 year;
  optional int32 month;
  optional binary carrier (STRING);
  optional binary carrier_name (STRING);
  optional binary airport (STRING);
  optional binary airport_name (STRING);
  optional int32 arr_flights;
  optional double arr_del15;
  optional double carrier_ct;
  optional double weather_ct;
  optional double nas_ct;
  optional double security_ct;
  optional double late_aircraft_ct;
  optional double arr_cancelled;
  optional double arr_diverted;
  optional double arr_delay;
  optional double carrier_delay;
  optional double weather_delay;
  optional double nas_delay;
  optional double security_delay;
  optional double late_aircraft_delay;
  optional int32 date (DATE);
}

       
[2025-10-06 13:25:19] INFO  CodecPool - Got brand-new compressor [.snappy]
[2025-10-06 13:25:19] INFO  ShuffleBlockFetcherIterator - Getting 1 (1055.0 KiB) non-empty blocks including 1 (1055.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:19] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 25 ms
[2025-10-06 13:25:19] INFO  CodeGenerator - Code generated in 122.123 ms
[2025-10-06 13:25:19] INFO  ShuffleBlockFetcherIterator - Getting 1 (1053.2 KiB) non-empty blocks including 1 (1053.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:19] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-06 13:25:19] INFO  ShuffleBlockFetcherIterator - Getting 1 (1035.9 KiB) non-empty blocks including 1 (1035.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:19] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-06 13:25:20] INFO  ShuffleBlockFetcherIterator - Getting 1 (1031.9 KiB) non-empty blocks including 1 (1031.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:20] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-06 13:25:20] INFO  ShuffleBlockFetcherIterator - Getting 1 (1642.7 KiB) non-empty blocks including 1 (1642.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:20] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-06 13:25:20] INFO  FileOutputCommitter - Saved output of task 'attempt_202510061325184280398635990946908_0002_m_000000_1' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/silver/cleaned_dataset/_temporary/0/task_202510061325184280398635990946908_0002_m_000000
[2025-10-06 13:25:20] INFO  SparkHadoopMapRedUtil - attempt_202510061325184280398635990946908_0002_m_000000_1: Committed. Elapsed time: 3 ms.
[2025-10-06 13:25:20] INFO  Executor - Finished task 0.0 in stage 2.0 (TID 1). 6005 bytes result sent to driver
[2025-10-06 13:25:20] INFO  TaskSetManager - Finished task 0.0 in stage 2.0 (TID 1) in 2119 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-06 13:25:20] INFO  TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[2025-10-06 13:25:20] INFO  DAGScheduler - ResultStage 2 (save at DataCleaning.java:132) finished in 2.415 s
[2025-10-06 13:25:20] INFO  DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-06 13:25:20] INFO  TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
[2025-10-06 13:25:20] INFO  DAGScheduler - Job 1 finished: save at DataCleaning.java:132, took 2.454531 s
[2025-10-06 13:25:20] INFO  FileFormatWriter - Start to commit write Job 8b9045af-b948-4e2a-b44c-4a470f6e536e.
[2025-10-06 13:25:20] INFO  FileFormatWriter - Write Job 8b9045af-b948-4e2a-b44c-4a470f6e536e committed. Elapsed time: 17 ms.
[2025-10-06 13:25:20] INFO  FileFormatWriter - Finished processing stats for write job 8b9045af-b948-4e2a-b44c-4a470f6e536e.
[2025-10-06 13:25:20] INFO  DataCleaning - Overwriting DB Table: silver.cleaned_dataset
[2025-10-06 13:25:21] WARN  SparkStringUtils - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2025-10-06 13:25:21] INFO  DAGScheduler - Registering RDD 9 (save at DataCleaning.java:143) as input to shuffle 1
[2025-10-06 13:25:21] INFO  DAGScheduler - Got map stage job 2 (save at DataCleaning.java:143) with 1 output partitions
[2025-10-06 13:25:21] INFO  DAGScheduler - Final stage: ShuffleMapStage 3 (save at DataCleaning.java:143)
[2025-10-06 13:25:21] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-06 13:25:21] INFO  DAGScheduler - Missing parents: List()
[2025-10-06 13:25:21] INFO  DAGScheduler - Submitting ShuffleMapStage 3 (MapPartitionsRDD[9] at save at DataCleaning.java:143), which has no missing parents
[2025-10-06 13:25:21] INFO  MemoryStore - Block broadcast_2 stored as values in memory (estimated size 75.7 KiB, free 2.2 GiB)
[2025-10-06 13:25:21] INFO  MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-06 13:25:21] INFO  BlockManagerInfo - Added broadcast_2_piece0 in memory on DESKTOP-618L1DH:50957 (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-06 13:25:21] INFO  SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1611
[2025-10-06 13:25:21] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[9] at save at DataCleaning.java:143) (first 15 tasks are for partitions Vector(0))
[2025-10-06 13:25:21] INFO  TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
[2025-10-06 13:25:21] INFO  TaskSetManager - Starting task 0.0 in stage 3.0 (TID 2) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-06 13:25:21] INFO  Executor - Running task 0.0 in stage 3.0 (TID 2)
[2025-10-06 13:25:21] INFO  BlockManagerInfo - Removed broadcast_1_piece0 on DESKTOP-618L1DH:50957 in memory (size: 102.8 KiB, free: 2.2 GiB)
[2025-10-06 13:25:21] INFO  JDBCRDD - closed connection
[2025-10-06 13:25:22] INFO  Executor - Finished task 0.0 in stage 3.0 (TID 2). 2507 bytes result sent to driver
[2025-10-06 13:25:22] INFO  TaskSetManager - Finished task 0.0 in stage 3.0 (TID 2) in 775 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-06 13:25:22] INFO  TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[2025-10-06 13:25:22] INFO  DAGScheduler - ShuffleMapStage 3 (save at DataCleaning.java:143) finished in 0.793 s
[2025-10-06 13:25:22] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-06 13:25:22] INFO  DAGScheduler - running: Set()
[2025-10-06 13:25:22] INFO  DAGScheduler - waiting: Set()
[2025-10-06 13:25:22] INFO  DAGScheduler - failed: Set()
[2025-10-06 13:25:22] INFO  ShufflePartitionsUtil - For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-06 13:25:22] INFO  SparkContext - Starting job: save at DataCleaning.java:143
[2025-10-06 13:25:22] INFO  DAGScheduler - Got job 3 (save at DataCleaning.java:143) with 5 output partitions
[2025-10-06 13:25:22] INFO  DAGScheduler - Final stage: ResultStage 5 (save at DataCleaning.java:143)
[2025-10-06 13:25:22] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 4)
[2025-10-06 13:25:22] INFO  DAGScheduler - Missing parents: List()
[2025-10-06 13:25:22] INFO  DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[14] at save at DataCleaning.java:143), which has no missing parents
[2025-10-06 13:25:22] INFO  MemoryStore - Block broadcast_3 stored as values in memory (estimated size 95.5 KiB, free 2.2 GiB)
[2025-10-06 13:25:22] INFO  MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 2.2 GiB)
[2025-10-06 13:25:22] INFO  BlockManagerInfo - Added broadcast_3_piece0 in memory on DESKTOP-618L1DH:50957 (size: 34.8 KiB, free: 2.2 GiB)
[2025-10-06 13:25:22] INFO  SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1611
[2025-10-06 13:25:22] INFO  DAGScheduler - Submitting 5 missing tasks from ResultStage 5 (MapPartitionsRDD[14] at save at DataCleaning.java:143) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
[2025-10-06 13:25:22] INFO  TaskSchedulerImpl - Adding task set 5.0 with 5 tasks resource profile 0
[2025-10-06 13:25:22] INFO  TaskSetManager - Starting task 0.0 in stage 5.0 (TID 3) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-06 13:25:22] INFO  TaskSetManager - Starting task 1.0 in stage 5.0 (TID 4) (DESKTOP-618L1DH, executor driver, partition 1, NODE_LOCAL, 8999 bytes) 
[2025-10-06 13:25:22] INFO  TaskSetManager - Starting task 2.0 in stage 5.0 (TID 5) (DESKTOP-618L1DH, executor driver, partition 2, NODE_LOCAL, 8999 bytes) 
[2025-10-06 13:25:22] INFO  TaskSetManager - Starting task 3.0 in stage 5.0 (TID 6) (DESKTOP-618L1DH, executor driver, partition 3, NODE_LOCAL, 8999 bytes) 
[2025-10-06 13:25:22] INFO  TaskSetManager - Starting task 4.0 in stage 5.0 (TID 7) (DESKTOP-618L1DH, executor driver, partition 4, NODE_LOCAL, 8999 bytes) 
[2025-10-06 13:25:22] INFO  Executor - Running task 0.0 in stage 5.0 (TID 3)
[2025-10-06 13:25:22] INFO  Executor - Running task 1.0 in stage 5.0 (TID 4)
[2025-10-06 13:25:22] INFO  Executor - Running task 2.0 in stage 5.0 (TID 5)
[2025-10-06 13:25:22] INFO  Executor - Running task 3.0 in stage 5.0 (TID 6)
[2025-10-06 13:25:22] INFO  Executor - Running task 4.0 in stage 5.0 (TID 7)
[2025-10-06 13:25:22] INFO  ShuffleBlockFetcherIterator - Getting 1 (1035.9 KiB) non-empty blocks including 1 (1035.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:22] INFO  ShuffleBlockFetcherIterator - Getting 1 (1642.7 KiB) non-empty blocks including 1 (1642.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:22] INFO  ShuffleBlockFetcherIterator - Getting 1 (1053.2 KiB) non-empty blocks including 1 (1053.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:22] INFO  ShuffleBlockFetcherIterator - Getting 1 (1055.0 KiB) non-empty blocks including 1 (1055.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:22] INFO  ShuffleBlockFetcherIterator - Getting 1 (1031.9 KiB) non-empty blocks including 1 (1031.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:22] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-06 13:25:22] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-06 13:25:22] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-06 13:25:22] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-06 13:25:22] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-06 13:25:23] INFO  CodeGenerator - Code generated in 23.5855 ms
[2025-10-06 13:25:23] INFO  BlockManagerInfo - Removed broadcast_2_piece0 on DESKTOP-618L1DH:50957 in memory (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-06 13:25:23] INFO  BlockManagerInfo - Removed broadcast_0_piece0 on DESKTOP-618L1DH:50957 in memory (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-06 13:25:29] INFO  Executor - Finished task 3.0 in stage 5.0 (TID 6). 4794 bytes result sent to driver
[2025-10-06 13:25:29] INFO  Executor - Finished task 1.0 in stage 5.0 (TID 4). 4794 bytes result sent to driver
[2025-10-06 13:25:29] INFO  TaskSetManager - Finished task 3.0 in stage 5.0 (TID 6) in 7163 ms on DESKTOP-618L1DH (executor driver) (1/5)
[2025-10-06 13:25:29] INFO  TaskSetManager - Finished task 1.0 in stage 5.0 (TID 4) in 7172 ms on DESKTOP-618L1DH (executor driver) (2/5)
[2025-10-06 13:25:29] INFO  Executor - Finished task 0.0 in stage 5.0 (TID 3). 4751 bytes result sent to driver
[2025-10-06 13:25:29] INFO  TaskSetManager - Finished task 0.0 in stage 5.0 (TID 3) in 7182 ms on DESKTOP-618L1DH (executor driver) (3/5)
[2025-10-06 13:25:29] INFO  Executor - Finished task 2.0 in stage 5.0 (TID 5). 4751 bytes result sent to driver
[2025-10-06 13:25:29] INFO  TaskSetManager - Finished task 2.0 in stage 5.0 (TID 5) in 7261 ms on DESKTOP-618L1DH (executor driver) (4/5)
[2025-10-06 13:25:33] INFO  Executor - Finished task 4.0 in stage 5.0 (TID 7). 4751 bytes result sent to driver
[2025-10-06 13:25:33] INFO  TaskSetManager - Finished task 4.0 in stage 5.0 (TID 7) in 11174 ms on DESKTOP-618L1DH (executor driver) (5/5)
[2025-10-06 13:25:33] INFO  TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[2025-10-06 13:25:33] INFO  DAGScheduler - ResultStage 5 (save at DataCleaning.java:143) finished in 11.220 s
[2025-10-06 13:25:33] INFO  DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-06 13:25:33] INFO  TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
[2025-10-06 13:25:33] INFO  DAGScheduler - Job 3 finished: save at DataCleaning.java:143, took 11.237584 s
[2025-10-06 13:25:33] INFO  DAGScheduler - Registering RDD 17 (count at DataCleaning.java:41) as input to shuffle 2
[2025-10-06 13:25:33] INFO  DAGScheduler - Got map stage job 4 (count at DataCleaning.java:41) with 1 output partitions
[2025-10-06 13:25:33] INFO  DAGScheduler - Final stage: ShuffleMapStage 6 (count at DataCleaning.java:41)
[2025-10-06 13:25:33] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-06 13:25:33] INFO  DAGScheduler - Missing parents: List()
[2025-10-06 13:25:33] INFO  DAGScheduler - Submitting ShuffleMapStage 6 (MapPartitionsRDD[17] at count at DataCleaning.java:41), which has no missing parents
[2025-10-06 13:25:33] INFO  MemoryStore - Block broadcast_4 stored as values in memory (estimated size 75.7 KiB, free 2.2 GiB)
[2025-10-06 13:25:33] INFO  MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-06 13:25:33] INFO  BlockManagerInfo - Added broadcast_4_piece0 in memory on DESKTOP-618L1DH:50957 (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-06 13:25:33] INFO  SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1611
[2025-10-06 13:25:33] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[17] at count at DataCleaning.java:41) (first 15 tasks are for partitions Vector(0))
[2025-10-06 13:25:33] INFO  TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
[2025-10-06 13:25:33] INFO  TaskSetManager - Starting task 0.0 in stage 6.0 (TID 8) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-06 13:25:33] INFO  Executor - Running task 0.0 in stage 6.0 (TID 8)
[2025-10-06 13:25:34] INFO  JDBCRDD - closed connection
[2025-10-06 13:25:37] INFO  Executor - Finished task 0.0 in stage 6.0 (TID 8). 2550 bytes result sent to driver
[2025-10-06 13:25:37] INFO  TaskSetManager - Finished task 0.0 in stage 6.0 (TID 8) in 4038 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-06 13:25:37] INFO  TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[2025-10-06 13:25:37] INFO  DAGScheduler - ShuffleMapStage 6 (count at DataCleaning.java:41) finished in 4.054 s
[2025-10-06 13:25:37] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-06 13:25:37] INFO  DAGScheduler - running: Set()
[2025-10-06 13:25:37] INFO  DAGScheduler - waiting: Set()
[2025-10-06 13:25:37] INFO  DAGScheduler - failed: Set()
[2025-10-06 13:25:37] INFO  ShufflePartitionsUtil - For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-06 13:25:38] INFO  CodeGenerator - Code generated in 141.5785 ms
[2025-10-06 13:25:38] INFO  DAGScheduler - Registering RDD 20 (count at DataCleaning.java:41) as input to shuffle 3
[2025-10-06 13:25:38] INFO  DAGScheduler - Got map stage job 5 (count at DataCleaning.java:41) with 5 output partitions
[2025-10-06 13:25:38] INFO  DAGScheduler - Final stage: ShuffleMapStage 8 (count at DataCleaning.java:41)
[2025-10-06 13:25:38] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 7)
[2025-10-06 13:25:38] INFO  DAGScheduler - Missing parents: List()
[2025-10-06 13:25:38] INFO  DAGScheduler - Submitting ShuffleMapStage 8 (MapPartitionsRDD[20] at count at DataCleaning.java:41), which has no missing parents
[2025-10-06 13:25:38] INFO  MemoryStore - Block broadcast_5 stored as values in memory (estimated size 76.1 KiB, free 2.2 GiB)
[2025-10-06 13:25:38] INFO  MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.1 KiB, free 2.2 GiB)
[2025-10-06 13:25:38] INFO  BlockManagerInfo - Added broadcast_5_piece0 in memory on DESKTOP-618L1DH:50957 (size: 29.1 KiB, free: 2.2 GiB)
[2025-10-06 13:25:38] INFO  SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1611
[2025-10-06 13:25:38] INFO  DAGScheduler - Submitting 5 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[20] at count at DataCleaning.java:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
[2025-10-06 13:25:38] INFO  TaskSchedulerImpl - Adding task set 8.0 with 5 tasks resource profile 0
[2025-10-06 13:25:38] INFO  TaskSetManager - Starting task 0.0 in stage 8.0 (TID 9) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-06 13:25:38] INFO  TaskSetManager - Starting task 1.0 in stage 8.0 (TID 10) (DESKTOP-618L1DH, executor driver, partition 1, NODE_LOCAL, 8988 bytes) 
[2025-10-06 13:25:38] INFO  TaskSetManager - Starting task 2.0 in stage 8.0 (TID 11) (DESKTOP-618L1DH, executor driver, partition 2, NODE_LOCAL, 8988 bytes) 
[2025-10-06 13:25:38] INFO  TaskSetManager - Starting task 3.0 in stage 8.0 (TID 12) (DESKTOP-618L1DH, executor driver, partition 3, NODE_LOCAL, 8988 bytes) 
[2025-10-06 13:25:38] INFO  TaskSetManager - Starting task 4.0 in stage 8.0 (TID 13) (DESKTOP-618L1DH, executor driver, partition 4, NODE_LOCAL, 8988 bytes) 
[2025-10-06 13:25:38] INFO  Executor - Running task 0.0 in stage 8.0 (TID 9)
[2025-10-06 13:25:38] INFO  Executor - Running task 1.0 in stage 8.0 (TID 10)
[2025-10-06 13:25:38] INFO  Executor - Running task 2.0 in stage 8.0 (TID 11)
[2025-10-06 13:25:38] INFO  Executor - Running task 3.0 in stage 8.0 (TID 12)
[2025-10-06 13:25:38] INFO  Executor - Running task 4.0 in stage 8.0 (TID 13)
[2025-10-06 13:25:38] INFO  ShuffleBlockFetcherIterator - Getting 1 (1055.0 KiB) non-empty blocks including 1 (1055.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:38] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-06 13:25:38] INFO  ShuffleBlockFetcherIterator - Getting 1 (1035.9 KiB) non-empty blocks including 1 (1035.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:38] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 11 ms
[2025-10-06 13:25:38] INFO  ShuffleBlockFetcherIterator - Getting 1 (1053.2 KiB) non-empty blocks including 1 (1053.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:38] INFO  ShuffleBlockFetcherIterator - Getting 1 (1642.7 KiB) non-empty blocks including 1 (1642.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:38] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 15 ms
[2025-10-06 13:25:38] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 19 ms
[2025-10-06 13:25:38] INFO  ShuffleBlockFetcherIterator - Getting 1 (1031.9 KiB) non-empty blocks including 1 (1031.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:38] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 14 ms
[2025-10-06 13:25:39] INFO  CodeGenerator - Code generated in 682.7891 ms
[2025-10-06 13:25:39] INFO  BlockManagerInfo - Removed broadcast_4_piece0 on DESKTOP-618L1DH:50957 in memory (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-06 13:25:39] INFO  BlockManagerInfo - Removed broadcast_3_piece0 on DESKTOP-618L1DH:50957 in memory (size: 34.8 KiB, free: 2.2 GiB)
[2025-10-06 13:25:39] INFO  Executor - Finished task 2.0 in stage 8.0 (TID 11). 5466 bytes result sent to driver
[2025-10-06 13:25:39] INFO  TaskSetManager - Finished task 2.0 in stage 8.0 (TID 11) in 1541 ms on DESKTOP-618L1DH (executor driver) (1/5)
[2025-10-06 13:25:39] INFO  Executor - Finished task 3.0 in stage 8.0 (TID 12). 5423 bytes result sent to driver
[2025-10-06 13:25:39] INFO  TaskSetManager - Finished task 3.0 in stage 8.0 (TID 12) in 1564 ms on DESKTOP-618L1DH (executor driver) (2/5)
[2025-10-06 13:25:39] INFO  Executor - Finished task 1.0 in stage 8.0 (TID 10). 5466 bytes result sent to driver
[2025-10-06 13:25:39] INFO  TaskSetManager - Finished task 1.0 in stage 8.0 (TID 10) in 1581 ms on DESKTOP-618L1DH (executor driver) (3/5)
[2025-10-06 13:25:39] INFO  Executor - Finished task 0.0 in stage 8.0 (TID 9). 5509 bytes result sent to driver
[2025-10-06 13:25:39] INFO  TaskSetManager - Finished task 0.0 in stage 8.0 (TID 9) in 1695 ms on DESKTOP-618L1DH (executor driver) (4/5)
[2025-10-06 13:25:40] INFO  Executor - Finished task 4.0 in stage 8.0 (TID 13). 5423 bytes result sent to driver
[2025-10-06 13:25:40] INFO  TaskSetManager - Finished task 4.0 in stage 8.0 (TID 13) in 1730 ms on DESKTOP-618L1DH (executor driver) (5/5)
[2025-10-06 13:25:40] INFO  TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[2025-10-06 13:25:40] INFO  DAGScheduler - ShuffleMapStage 8 (count at DataCleaning.java:41) finished in 1.802 s
[2025-10-06 13:25:40] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-06 13:25:40] INFO  DAGScheduler - running: Set()
[2025-10-06 13:25:40] INFO  DAGScheduler - waiting: Set()
[2025-10-06 13:25:40] INFO  DAGScheduler - failed: Set()
[2025-10-06 13:25:40] INFO  CodeGenerator - Code generated in 44.317 ms
[2025-10-06 13:25:40] INFO  SparkContext - Starting job: count at DataCleaning.java:41
[2025-10-06 13:25:40] INFO  DAGScheduler - Got job 6 (count at DataCleaning.java:41) with 1 output partitions
[2025-10-06 13:25:40] INFO  DAGScheduler - Final stage: ResultStage 11 (count at DataCleaning.java:41)
[2025-10-06 13:25:40] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 10)
[2025-10-06 13:25:40] INFO  DAGScheduler - Missing parents: List()
[2025-10-06 13:25:40] INFO  DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[23] at count at DataCleaning.java:41), which has no missing parents
[2025-10-06 13:25:40] INFO  MemoryStore - Block broadcast_6 stored as values in memory (estimated size 12.5 KiB, free 2.2 GiB)
[2025-10-06 13:25:40] INFO  MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
[2025-10-06 13:25:40] INFO  BlockManagerInfo - Added broadcast_6_piece0 in memory on DESKTOP-618L1DH:50957 (size: 5.9 KiB, free: 2.2 GiB)
[2025-10-06 13:25:40] INFO  SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-10-06 13:25:40] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[23] at count at DataCleaning.java:41) (first 15 tasks are for partitions Vector(0))
[2025-10-06 13:25:40] INFO  TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
[2025-10-06 13:25:40] INFO  TaskSetManager - Starting task 0.0 in stage 11.0 (TID 14) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-06 13:25:40] INFO  Executor - Running task 0.0 in stage 11.0 (TID 14)
[2025-10-06 13:25:40] INFO  ShuffleBlockFetcherIterator - Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-06 13:25:40] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-06 13:25:40] INFO  CodeGenerator - Code generated in 17.0452 ms
[2025-10-06 13:25:40] INFO  Executor - Finished task 0.0 in stage 11.0 (TID 14). 4038 bytes result sent to driver
[2025-10-06 13:25:40] INFO  TaskSetManager - Finished task 0.0 in stage 11.0 (TID 14) in 116 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-06 13:25:40] INFO  TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
[2025-10-06 13:25:40] INFO  DAGScheduler - ResultStage 11 (count at DataCleaning.java:41) finished in 0.131 s
[2025-10-06 13:25:40] INFO  DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-06 13:25:40] INFO  TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
[2025-10-06 13:25:40] INFO  DAGScheduler - Job 6 finished: count at DataCleaning.java:41, took 0.165709 s
[2025-10-06 13:25:40] INFO  DataCleaning - Cleaned dataset stored in silver layer. Row count = 54619
[2025-10-06 13:25:40] INFO  DataCleaning - Loading from DB Table: bronze.carrier_lookup
[2025-10-06 13:25:40] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_carrier_lookup
[2025-10-06 13:25:40] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:40] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-06 13:25:40] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-06 13:25:40] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:40] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-06 13:25:40] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-06 13:25:40] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:40] INFO  CodeGenerator - Code generated in 16.8669 ms
[2025-10-06 13:25:40] INFO  SparkContext - Starting job: save at DataCleaning.java:132
[2025-10-06 13:25:40] INFO  DAGScheduler - Got job 7 (save at DataCleaning.java:132) with 1 output partitions
[2025-10-06 13:25:40] INFO  DAGScheduler - Final stage: ResultStage 12 (save at DataCleaning.java:132)
[2025-10-06 13:25:40] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-06 13:25:40] INFO  DAGScheduler - Missing parents: List()
[2025-10-06 13:25:40] INFO  DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[27] at save at DataCleaning.java:132), which has no missing parents
[2025-10-06 13:25:40] INFO  MemoryStore - Block broadcast_7 stored as values in memory (estimated size 213.2 KiB, free 2.2 GiB)
[2025-10-06 13:25:40] INFO  MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 2.2 GiB)
[2025-10-06 13:25:40] INFO  BlockManagerInfo - Added broadcast_7_piece0 in memory on DESKTOP-618L1DH:50957 (size: 77.2 KiB, free: 2.2 GiB)
[2025-10-06 13:25:40] INFO  SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-10-06 13:25:40] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[27] at save at DataCleaning.java:132) (first 15 tasks are for partitions Vector(0))
[2025-10-06 13:25:40] INFO  TaskSchedulerImpl - Adding task set 12.0 with 1 tasks resource profile 0
[2025-10-06 13:25:40] INFO  TaskSetManager - Starting task 0.0 in stage 12.0 (TID 15) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9121 bytes) 
[2025-10-06 13:25:40] INFO  BlockManagerInfo - Removed broadcast_6_piece0 on DESKTOP-618L1DH:50957 in memory (size: 5.9 KiB, free: 2.2 GiB)
[2025-10-06 13:25:40] INFO  Executor - Running task 0.0 in stage 12.0 (TID 15)
[2025-10-06 13:25:40] INFO  BlockManagerInfo - Removed broadcast_5_piece0 on DESKTOP-618L1DH:50957 in memory (size: 29.1 KiB, free: 2.2 GiB)
[2025-10-06 13:25:41] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-06 13:25:41] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-06 13:25:41] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:41] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-06 13:25:41] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-06 13:25:41] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:41] INFO  CodecConfig - Compression: SNAPPY
[2025-10-06 13:25:41] INFO  CodecConfig - Compression: SNAPPY
[2025-10-06 13:25:41] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-06 13:25:41] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "carrier",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary carrier (STRING);
  optional binary carrier_name (STRING);
}

       
[2025-10-06 13:25:41] INFO  CodeGenerator - Code generated in 20.6768 ms
[2025-10-06 13:25:41] INFO  JDBCRDD - closed connection
[2025-10-06 13:25:41] INFO  FileOutputCommitter - Saved output of task 'attempt_20251006132540193423906686901987_0012_m_000000_15' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/silver/cleaned_carrier_lookup/_temporary/0/task_20251006132540193423906686901987_0012_m_000000
[2025-10-06 13:25:41] INFO  SparkHadoopMapRedUtil - attempt_20251006132540193423906686901987_0012_m_000000_15: Committed. Elapsed time: 15 ms.
[2025-10-06 13:25:41] INFO  Executor - Finished task 0.0 in stage 12.0 (TID 15). 2484 bytes result sent to driver
[2025-10-06 13:25:41] INFO  TaskSetManager - Finished task 0.0 in stage 12.0 (TID 15) in 280 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-06 13:25:41] INFO  TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool 
[2025-10-06 13:25:41] INFO  DAGScheduler - ResultStage 12 (save at DataCleaning.java:132) finished in 0.502 s
[2025-10-06 13:25:41] INFO  DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-06 13:25:41] INFO  TaskSchedulerImpl - Killing all running tasks in stage 12: Stage finished
[2025-10-06 13:25:41] INFO  DAGScheduler - Job 7 finished: save at DataCleaning.java:132, took 0.512452 s
[2025-10-06 13:25:41] INFO  FileFormatWriter - Start to commit write Job c4218fe0-068e-4826-8589-1e89bc61bb54.
[2025-10-06 13:25:41] INFO  FileFormatWriter - Write Job c4218fe0-068e-4826-8589-1e89bc61bb54 committed. Elapsed time: 78 ms.
[2025-10-06 13:25:41] INFO  FileFormatWriter - Finished processing stats for write job c4218fe0-068e-4826-8589-1e89bc61bb54.
[2025-10-06 13:25:41] INFO  DataCleaning - Overwriting DB Table: silver.cleaned_carrier_lookup
[2025-10-06 13:25:41] INFO  SparkContext - Starting job: save at DataCleaning.java:143
[2025-10-06 13:25:41] INFO  DAGScheduler - Got job 8 (save at DataCleaning.java:143) with 1 output partitions
[2025-10-06 13:25:41] INFO  DAGScheduler - Final stage: ResultStage 13 (save at DataCleaning.java:143)
[2025-10-06 13:25:41] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-06 13:25:41] INFO  DAGScheduler - Missing parents: List()
[2025-10-06 13:25:41] INFO  DAGScheduler - Submitting ResultStage 13 (MapPartitionsRDD[32] at save at DataCleaning.java:143), which has no missing parents
[2025-10-06 13:25:41] INFO  MemoryStore - Block broadcast_8 stored as values in memory (estimated size 28.1 KiB, free 2.2 GiB)
[2025-10-06 13:25:41] INFO  MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.2 KiB, free 2.2 GiB)
[2025-10-06 13:25:41] INFO  BlockManagerInfo - Added broadcast_8_piece0 in memory on DESKTOP-618L1DH:50957 (size: 13.2 KiB, free: 2.2 GiB)
[2025-10-06 13:25:41] INFO  SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-10-06 13:25:41] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[32] at save at DataCleaning.java:143) (first 15 tasks are for partitions Vector(0))
[2025-10-06 13:25:41] INFO  TaskSchedulerImpl - Adding task set 13.0 with 1 tasks resource profile 0
[2025-10-06 13:25:41] INFO  TaskSetManager - Starting task 0.0 in stage 13.0 (TID 16) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) 
[2025-10-06 13:25:41] INFO  Executor - Running task 0.0 in stage 13.0 (TID 16)
[2025-10-06 13:25:41] INFO  CodeGenerator - Code generated in 21.7443 ms
[2025-10-06 13:25:41] INFO  JDBCRDD - closed connection
[2025-10-06 13:25:41] INFO  Executor - Finished task 0.0 in stage 13.0 (TID 16). 1273 bytes result sent to driver
[2025-10-06 13:25:41] INFO  TaskSetManager - Finished task 0.0 in stage 13.0 (TID 16) in 222 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-06 13:25:41] INFO  TaskSchedulerImpl - Removed TaskSet 13.0, whose tasks have all completed, from pool 
[2025-10-06 13:25:41] INFO  DAGScheduler - ResultStage 13 (save at DataCleaning.java:143) finished in 0.254 s
[2025-10-06 13:25:41] INFO  DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-06 13:25:41] INFO  TaskSchedulerImpl - Killing all running tasks in stage 13: Stage finished
[2025-10-06 13:25:41] INFO  DAGScheduler - Job 8 finished: save at DataCleaning.java:143, took 0.261645 s
[2025-10-06 13:25:41] INFO  DataCleaning - Loading from DB Table: bronze.airport_lookup
[2025-10-06 13:25:42] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_airport_lookup
[2025-10-06 13:25:42] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:42] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-06 13:25:42] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-06 13:25:42] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:42] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-06 13:25:42] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-06 13:25:42] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:42] INFO  CodeGenerator - Code generated in 16.7654 ms
[2025-10-06 13:25:42] INFO  SparkContext - Starting job: save at DataCleaning.java:132
[2025-10-06 13:25:42] INFO  DAGScheduler - Got job 9 (save at DataCleaning.java:132) with 1 output partitions
[2025-10-06 13:25:42] INFO  DAGScheduler - Final stage: ResultStage 14 (save at DataCleaning.java:132)
[2025-10-06 13:25:42] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-06 13:25:42] INFO  DAGScheduler - Missing parents: List()
[2025-10-06 13:25:42] INFO  DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[36] at save at DataCleaning.java:132), which has no missing parents
[2025-10-06 13:25:42] INFO  MemoryStore - Block broadcast_9 stored as values in memory (estimated size 213.9 KiB, free 2.2 GiB)
[2025-10-06 13:25:42] INFO  MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 2.2 GiB)
[2025-10-06 13:25:42] INFO  BlockManagerInfo - Added broadcast_9_piece0 in memory on DESKTOP-618L1DH:50957 (size: 77.2 KiB, free: 2.2 GiB)
[2025-10-06 13:25:42] INFO  SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-10-06 13:25:42] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[36] at save at DataCleaning.java:132) (first 15 tasks are for partitions Vector(0))
[2025-10-06 13:25:42] INFO  TaskSchedulerImpl - Adding task set 14.0 with 1 tasks resource profile 0
[2025-10-06 13:25:42] INFO  BlockManagerInfo - Removed broadcast_8_piece0 on DESKTOP-618L1DH:50957 in memory (size: 13.2 KiB, free: 2.2 GiB)
[2025-10-06 13:25:42] INFO  TaskSetManager - Starting task 0.0 in stage 14.0 (TID 17) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9121 bytes) 
[2025-10-06 13:25:42] INFO  Executor - Running task 0.0 in stage 14.0 (TID 17)
[2025-10-06 13:25:42] INFO  BlockManagerInfo - Removed broadcast_7_piece0 on DESKTOP-618L1DH:50957 in memory (size: 77.2 KiB, free: 2.2 GiB)
[2025-10-06 13:25:42] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-06 13:25:42] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-06 13:25:42] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:42] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-06 13:25:42] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-06 13:25:42] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-06 13:25:42] INFO  CodecConfig - Compression: SNAPPY
[2025-10-06 13:25:42] INFO  CodecConfig - Compression: SNAPPY
[2025-10-06 13:25:42] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-06 13:25:42] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "iso_country",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "iata_code",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary iso_country (STRING);
  optional binary name (STRING);
  optional binary iata_code (STRING);
}

       
[2025-10-06 13:25:42] INFO  CodeGenerator - Code generated in 40.7095 ms
[2025-10-06 13:25:42] INFO  JDBCRDD - closed connection
[2025-10-06 13:25:42] INFO  FileOutputCommitter - Saved output of task 'attempt_20251006132542450793048517306542_0014_m_000000_17' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/silver/cleaned_airport_lookup/_temporary/0/task_20251006132542450793048517306542_0014_m_000000
[2025-10-06 13:25:42] INFO  SparkHadoopMapRedUtil - attempt_20251006132542450793048517306542_0014_m_000000_17: Committed. Elapsed time: 8 ms.
[2025-10-06 13:25:42] INFO  Executor - Finished task 0.0 in stage 14.0 (TID 17). 2484 bytes result sent to driver
[2025-10-06 13:25:42] INFO  TaskSetManager - Finished task 0.0 in stage 14.0 (TID 17) in 323 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-06 13:25:42] INFO  TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool 
[2025-10-06 13:25:42] INFO  DAGScheduler - ResultStage 14 (save at DataCleaning.java:132) finished in 0.500 s
[2025-10-06 13:25:42] INFO  DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-06 13:25:42] INFO  TaskSchedulerImpl - Killing all running tasks in stage 14: Stage finished
[2025-10-06 13:25:42] INFO  DAGScheduler - Job 9 finished: save at DataCleaning.java:132, took 0.512334 s
[2025-10-06 13:25:42] INFO  FileFormatWriter - Start to commit write Job 012c21d3-f9e7-4f8e-9fbc-d9c75bbe8277.
[2025-10-06 13:25:42] INFO  FileFormatWriter - Write Job 012c21d3-f9e7-4f8e-9fbc-d9c75bbe8277 committed. Elapsed time: 42 ms.
[2025-10-06 13:25:42] INFO  FileFormatWriter - Finished processing stats for write job 012c21d3-f9e7-4f8e-9fbc-d9c75bbe8277.
[2025-10-06 13:25:42] INFO  DataCleaning - Overwriting DB Table: silver.cleaned_airport_lookup
[2025-10-06 13:25:42] INFO  SparkContext - Starting job: save at DataCleaning.java:143
[2025-10-06 13:25:42] INFO  DAGScheduler - Got job 10 (save at DataCleaning.java:143) with 1 output partitions
[2025-10-06 13:25:42] INFO  DAGScheduler - Final stage: ResultStage 15 (save at DataCleaning.java:143)
[2025-10-06 13:25:42] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-06 13:25:42] INFO  DAGScheduler - Missing parents: List()
[2025-10-06 13:25:42] INFO  DAGScheduler - Submitting ResultStage 15 (MapPartitionsRDD[41] at save at DataCleaning.java:143), which has no missing parents
[2025-10-06 13:25:43] INFO  MemoryStore - Block broadcast_10 stored as values in memory (estimated size 29.2 KiB, free 2.2 GiB)
[2025-10-06 13:25:43] INFO  MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 2.2 GiB)
[2025-10-06 13:25:43] INFO  BlockManagerInfo - Added broadcast_10_piece0 in memory on DESKTOP-618L1DH:50957 (size: 13.4 KiB, free: 2.2 GiB)
[2025-10-06 13:25:43] INFO  SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1611
[2025-10-06 13:25:43] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[41] at save at DataCleaning.java:143) (first 15 tasks are for partitions Vector(0))
[2025-10-06 13:25:43] INFO  TaskSchedulerImpl - Adding task set 15.0 with 1 tasks resource profile 0
[2025-10-06 13:25:43] INFO  TaskSetManager - Starting task 0.0 in stage 15.0 (TID 18) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) 
[2025-10-06 13:25:43] INFO  Executor - Running task 0.0 in stage 15.0 (TID 18)
[2025-10-06 13:25:43] INFO  CodeGenerator - Code generated in 15.0058 ms
[2025-10-06 13:25:43] WARN  WadlFeature - JAX-B API not found . WADL feature is disabled.
[2025-10-06 13:25:44] INFO  JDBCRDD - closed connection
[2025-10-06 13:25:44] INFO  Executor - Finished task 0.0 in stage 15.0 (TID 18). 1230 bytes result sent to driver
[2025-10-06 13:25:44] INFO  TaskSetManager - Finished task 0.0 in stage 15.0 (TID 18) in 1675 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-06 13:25:44] INFO  TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
[2025-10-06 13:25:44] INFO  DAGScheduler - ResultStage 15 (save at DataCleaning.java:143) finished in 1.706 s
[2025-10-06 13:25:44] INFO  DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-06 13:25:44] INFO  TaskSchedulerImpl - Killing all running tasks in stage 15: Stage finished
[2025-10-06 13:25:44] INFO  DAGScheduler - Job 10 finished: save at DataCleaning.java:143, took 1.719939 s
[2025-10-06 13:25:44] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-06 13:25:44] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-06 13:25:45] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-06 13:25:45] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-06 13:25:45] INFO  MemoryStore - MemoryStore cleared
[2025-10-06 13:25:45] INFO  BlockManager - BlockManager stopped
[2025-10-06 13:25:45] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-06 13:25:45] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-06 13:25:45] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-06 13:25:45] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-06 13:25:45] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-680f9ca7-565e-40c2-ae25-3d04cf6c5f0d
[2025-10-07 19:47:09] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-07 19:47:09] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-07 19:47:09] INFO  SparkContext - Java version 11.0.27
[2025-10-07 19:47:09] INFO  ResourceUtils - ==============================================================
[2025-10-07 19:47:09] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-07 19:47:09] INFO  ResourceUtils - ==============================================================
[2025-10-07 19:47:09] INFO  SparkContext - Submitted application: Airline SQL Queries
[2025-10-07 19:47:09] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-07 19:47:09] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-07 19:47:09] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-07 19:47:09] INFO  SecurityManager - Changing view acls to: USER
[2025-10-07 19:47:09] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-07 19:47:09] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-07 19:47:09] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-07 19:47:09] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-07 19:47:10] INFO  Utils - Successfully started service 'sparkDriver' on port 62581.
[2025-10-07 19:47:10] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-07 19:47:10] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-07 19:47:10] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-07 19:47:10] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-07 19:47:10] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-07 19:47:10] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-d7c57d2b-c789-4cd3-9fba-0d9ad5f96684
[2025-10-07 19:47:10] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-07 19:47:10] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-07 19:47:10] INFO  log - Logging initialized @3228ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-07 19:47:10] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-07 19:47:10] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-07 19:47:10] INFO  Server - Started @3362ms
[2025-10-07 19:47:10] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-07 19:47:10] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-07 19:47:10] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@36c281ed{/,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-07 19:47:11] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-07 19:47:11] INFO  Executor - Java version 11.0.27
[2025-10-07 19:47:11] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-07 19:47:11] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@ceddaf8 for default.
[2025-10-07 19:47:11] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62628.
[2025-10-07 19:47:11] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:62628
[2025-10-07 19:47:11] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-07 19:47:11] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 62628, None)
[2025-10-07 19:47:11] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:62628 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 62628, None)
[2025-10-07 19:47:11] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 62628, None)
[2025-10-07 19:47:11] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 62628, None)
[2025-10-07 19:47:11] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@36c281ed{/,null,STOPPED,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6cfbbff7{/jobs,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@45b32dfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@14c141c0{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@d611f1c{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@51fc862e{/stages,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@fe09383{/stages/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@f25f48a{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b2e5c0d{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5438c17a{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@429aeac1{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6b4fc2d1{/storage,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de4285e{/storage/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@634ff56{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5a484ce1{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2ffe243f{/environment,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4099209b{/environment/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1dad01fe{/executors,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3e3cd6fe{/executors/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@68b734a8{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4215e133{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@d88f893{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@48eaf42f{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2091833{/static,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1084ac45{/,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6ea246af{/api,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@17e0933c{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1dcedc93{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@38291795{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  SQLQueries - Loading table: fact_flight_performance
[2025-10-07 19:47:11] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-07 19:47:11] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6d6ac396{/SQL,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@f5a7226{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@100ad67e{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@62aeddc8{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-07 19:47:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@35bfa1bb{/static/sql,null,AVAILABLE,@Spark}
[2025-10-07 19:47:14] INFO  SQLQueries - Loading table: dim_carrier
[2025-10-07 19:47:14] INFO  SQLQueries - Loading table: dim_airport
[2025-10-07 19:47:15] INFO  SQLQueries - Task 6.1 - % of delayed flights
[2025-10-07 19:47:16] INFO  CodeGenerator - Code generated in 227.3923 ms
[2025-10-07 19:47:16] INFO  DAGScheduler - Registering RDD 2 (collectAsList at SQLQueries.java:160) as input to shuffle 0
[2025-10-07 19:47:16] INFO  DAGScheduler - Got map stage job 0 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:16] INFO  DAGScheduler - Final stage: ShuffleMapStage 0 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:16] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:16] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:16] INFO  DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:16] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 17.8 KiB, free 2.2 GiB)
[2025-10-07 19:47:16] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 2.2 GiB)
[2025-10-07 19:47:16] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on DESKTOP-618L1DH:62628 (size: 8.5 KiB, free: 2.2 GiB)
[2025-10-07 19:47:16] INFO  SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:16] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:16] INFO  TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
[2025-10-07 19:47:16] INFO  TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:16] INFO  Executor - Running task 0.0 in stage 0.0 (TID 0)
[2025-10-07 19:47:16] INFO  CodeGenerator - Code generated in 21.1988 ms
[2025-10-07 19:47:16] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:16] INFO  Executor - Finished task 0.0 in stage 0.0 (TID 0). 1931 bytes result sent to driver
[2025-10-07 19:47:16] INFO  TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 467 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:16] INFO  TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:16] INFO  DAGScheduler - ShuffleMapStage 0 (collectAsList at SQLQueries.java:160) finished in 0.697 s
[2025-10-07 19:47:16] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:16] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:16] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:16] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:16] INFO  CodeGenerator - Code generated in 41.6429 ms
[2025-10-07 19:47:16] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:16] INFO  DAGScheduler - Got job 1 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:16] INFO  DAGScheduler - Final stage: ResultStage 2 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:16] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
[2025-10-07 19:47:16] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:16] INFO  DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[5] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:17] INFO  MemoryStore - Block broadcast_1 stored as values in memory (estimated size 17.4 KiB, free 2.2 GiB)
[2025-10-07 19:47:17] INFO  MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 2.2 GiB)
[2025-10-07 19:47:17] INFO  BlockManagerInfo - Added broadcast_1_piece0 in memory on DESKTOP-618L1DH:62628 (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-07 19:47:17] INFO  SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:17] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:17] INFO  TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
[2025-10-07 19:47:17] INFO  TaskSetManager - Starting task 0.0 in stage 2.0 (TID 1) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:17] INFO  Executor - Running task 0.0 in stage 2.0 (TID 1)
[2025-10-07 19:47:17] INFO  ShuffleBlockFetcherIterator - Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:17] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 15 ms
[2025-10-07 19:47:17] INFO  CodeGenerator - Code generated in 27.1483 ms
[2025-10-07 19:47:17] INFO  Executor - Finished task 0.0 in stage 2.0 (TID 1). 4051 bytes result sent to driver
[2025-10-07 19:47:17] INFO  TaskSetManager - Finished task 0.0 in stage 2.0 (TID 1) in 156 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:17] INFO  TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:17] INFO  DAGScheduler - ResultStage 2 (collectAsList at SQLQueries.java:160) finished in 0.176 s
[2025-10-07 19:47:17] INFO  DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:17] INFO  TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
[2025-10-07 19:47:17] INFO  DAGScheduler - Job 1 finished: collectAsList at SQLQueries.java:160, took 0.206116 s
[2025-10-07 19:47:18] INFO  BlockManagerInfo - Removed broadcast_0_piece0 on DESKTOP-618L1DH:62628 in memory (size: 8.5 KiB, free: 2.2 GiB)
[2025-10-07 19:47:18] INFO  BlockManagerInfo - Removed broadcast_1_piece0 on DESKTOP-618L1DH:62628 in memory (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-07 19:47:18] INFO  CodeGenerator - Code generated in 39.9465 ms
[2025-10-07 19:47:18] INFO  SQLQueries - [20.19719614257616]
[2025-10-07 19:47:18] INFO  SQLQueries - Task 6.2 - On-time performance by carrier
[2025-10-07 19:47:18] INFO  CodeGenerator - Code generated in 8.4076 ms
[2025-10-07 19:47:18] INFO  DAGScheduler - Registering RDD 9 (collectAsList at SQLQueries.java:160) as input to shuffle 1
[2025-10-07 19:47:18] INFO  DAGScheduler - Got map stage job 2 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:18] INFO  DAGScheduler - Final stage: ShuffleMapStage 3 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:18] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:18] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:18] INFO  DAGScheduler - Submitting ShuffleMapStage 3 (MapPartitionsRDD[9] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:18] INFO  CodeGenerator - Code generated in 8.8419 ms
[2025-10-07 19:47:18] INFO  MemoryStore - Block broadcast_2 stored as values in memory (estimated size 14.8 KiB, free 2.2 GiB)
[2025-10-07 19:47:18] INFO  MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 2.2 GiB)
[2025-10-07 19:47:18] INFO  BlockManagerInfo - Added broadcast_2_piece0 in memory on DESKTOP-618L1DH:62628 (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-07 19:47:18] INFO  SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:18] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[9] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:18] INFO  TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
[2025-10-07 19:47:18] INFO  DAGScheduler - Registering RDD 11 (collectAsList at SQLQueries.java:160) as input to shuffle 2
[2025-10-07 19:47:18] INFO  DAGScheduler - Got map stage job 3 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:18] INFO  TaskSetManager - Starting task 0.0 in stage 3.0 (TID 2) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:18] INFO  DAGScheduler - Final stage: ShuffleMapStage 4 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:18] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:18] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:18] INFO  Executor - Running task 0.0 in stage 3.0 (TID 2)
[2025-10-07 19:47:18] INFO  DAGScheduler - Submitting ShuffleMapStage 4 (MapPartitionsRDD[11] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:18] INFO  MemoryStore - Block broadcast_3 stored as values in memory (estimated size 14.5 KiB, free 2.2 GiB)
[2025-10-07 19:47:18] INFO  MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
[2025-10-07 19:47:18] INFO  BlockManagerInfo - Added broadcast_3_piece0 in memory on DESKTOP-618L1DH:62628 (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-07 19:47:18] INFO  SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:18] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[11] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:18] INFO  TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
[2025-10-07 19:47:18] INFO  TaskSetManager - Starting task 0.0 in stage 4.0 (TID 3) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:18] INFO  Executor - Running task 0.0 in stage 4.0 (TID 3)
[2025-10-07 19:47:18] INFO  CodeGenerator - Code generated in 10.8025 ms
[2025-10-07 19:47:18] INFO  CodeGenerator - Code generated in 15.5453 ms
[2025-10-07 19:47:18] INFO  CodeGenerator - Code generated in 11.1236 ms
[2025-10-07 19:47:18] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:18] INFO  Executor - Finished task 0.0 in stage 4.0 (TID 3). 1949 bytes result sent to driver
[2025-10-07 19:47:18] INFO  TaskSetManager - Finished task 0.0 in stage 4.0 (TID 3) in 225 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:18] INFO  TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:18] INFO  DAGScheduler - ShuffleMapStage 4 (collectAsList at SQLQueries.java:160) finished in 0.241 s
[2025-10-07 19:47:18] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:18] INFO  DAGScheduler - running: Set(ShuffleMapStage 3)
[2025-10-07 19:47:18] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:18] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:18] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:18] INFO  Executor - Finished task 0.0 in stage 3.0 (TID 2). 1906 bytes result sent to driver
[2025-10-07 19:47:18] INFO  TaskSetManager - Finished task 0.0 in stage 3.0 (TID 2) in 349 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:18] INFO  TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:18] INFO  DAGScheduler - ShuffleMapStage 3 (collectAsList at SQLQueries.java:160) finished in 0.371 s
[2025-10-07 19:47:18] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:18] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:18] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:18] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:19] INFO  ShufflePartitionsUtil - For shuffle(1, 2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 100.5607 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 15.9742 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 12.1655 ms
[2025-10-07 19:47:19] INFO  DAGScheduler - Registering RDD 18 (collectAsList at SQLQueries.java:160) as input to shuffle 3
[2025-10-07 19:47:19] INFO  DAGScheduler - Got map stage job 4 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:19] INFO  DAGScheduler - Final stage: ShuffleMapStage 7 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:19] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 6)
[2025-10-07 19:47:19] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:19] INFO  DAGScheduler - Submitting ShuffleMapStage 7 (MapPartitionsRDD[18] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:19] INFO  MemoryStore - Block broadcast_4 stored as values in memory (estimated size 62.1 KiB, free 2.2 GiB)
[2025-10-07 19:47:19] INFO  MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.3 KiB, free 2.2 GiB)
[2025-10-07 19:47:19] INFO  BlockManagerInfo - Added broadcast_4_piece0 in memory on DESKTOP-618L1DH:62628 (size: 27.3 KiB, free: 2.2 GiB)
[2025-10-07 19:47:19] INFO  SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:19] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[18] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:19] INFO  TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
[2025-10-07 19:47:19] INFO  TaskSetManager - Starting task 0.0 in stage 7.0 (TID 4) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9270 bytes) 
[2025-10-07 19:47:19] INFO  Executor - Running task 0.0 in stage 7.0 (TID 4)
[2025-10-07 19:47:19] INFO  ShuffleBlockFetcherIterator - Getting 1 (510.6 KiB) non-empty blocks including 1 (510.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:19] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 3 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 12.8267 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 25.3824 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 12.2755 ms
[2025-10-07 19:47:19] INFO  ShuffleBlockFetcherIterator - Getting 1 (1738.0 B) non-empty blocks including 1 (1738.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:19] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 13.1785 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 46.324 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 9.7453 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 5.8789 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 7.6806 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 7.0748 ms
[2025-10-07 19:47:19] INFO  Executor - Finished task 0.0 in stage 7.0 (TID 4). 6814 bytes result sent to driver
[2025-10-07 19:47:19] INFO  TaskSetManager - Finished task 0.0 in stage 7.0 (TID 4) in 477 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:19] INFO  TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:19] INFO  DAGScheduler - ShuffleMapStage 7 (collectAsList at SQLQueries.java:160) finished in 0.493 s
[2025-10-07 19:47:19] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:19] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:19] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:19] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:19] INFO  ShufflePartitionsUtil - For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:19] INFO  HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 13.1305 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 7.2813 ms
[2025-10-07 19:47:19] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:19] INFO  DAGScheduler - Got job 5 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:19] INFO  DAGScheduler - Final stage: ResultStage 11 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:19] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 10)
[2025-10-07 19:47:19] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:19] INFO  DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[23] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:19] INFO  MemoryStore - Block broadcast_5 stored as values in memory (estimated size 59.8 KiB, free 2.2 GiB)
[2025-10-07 19:47:19] INFO  MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 26.5 KiB, free 2.2 GiB)
[2025-10-07 19:47:19] INFO  BlockManagerInfo - Added broadcast_5_piece0 in memory on DESKTOP-618L1DH:62628 (size: 26.5 KiB, free: 2.2 GiB)
[2025-10-07 19:47:19] INFO  SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:19] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[23] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:19] INFO  TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
[2025-10-07 19:47:19] INFO  TaskSetManager - Starting task 0.0 in stage 11.0 (TID 5) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:19] INFO  Executor - Running task 0.0 in stage 11.0 (TID 5)
[2025-10-07 19:47:19] INFO  ShuffleBlockFetcherIterator - Getting 1 (2030.0 B) non-empty blocks including 1 (2030.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:19] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-07 19:47:19] INFO  CodeGenerator - Code generated in 18.8241 ms
[2025-10-07 19:47:20] INFO  CodeGenerator - Code generated in 4.4604 ms
[2025-10-07 19:47:20] INFO  Executor - Finished task 0.0 in stage 11.0 (TID 5). 9276 bytes result sent to driver
[2025-10-07 19:47:20] INFO  TaskSetManager - Finished task 0.0 in stage 11.0 (TID 5) in 71 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:20] INFO  TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:20] INFO  DAGScheduler - ResultStage 11 (collectAsList at SQLQueries.java:160) finished in 0.083 s
[2025-10-07 19:47:20] INFO  DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:20] INFO  TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
[2025-10-07 19:47:20] INFO  DAGScheduler - Job 5 finished: collectAsList at SQLQueries.java:160, took 0.092796 s
[2025-10-07 19:47:20] INFO  DAGScheduler - Registering RDD 24 (collectAsList at SQLQueries.java:160) as input to shuffle 4
[2025-10-07 19:47:20] INFO  DAGScheduler - Got map stage job 6 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:20] INFO  DAGScheduler - Final stage: ShuffleMapStage 15 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:20] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 14)
[2025-10-07 19:47:20] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:20] INFO  DAGScheduler - Submitting ShuffleMapStage 15 (MapPartitionsRDD[24] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:20] INFO  MemoryStore - Block broadcast_6 stored as values in memory (estimated size 61.7 KiB, free 2.2 GiB)
[2025-10-07 19:47:20] INFO  MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 2.2 GiB)
[2025-10-07 19:47:20] INFO  BlockManagerInfo - Added broadcast_6_piece0 in memory on DESKTOP-618L1DH:62628 (size: 27.2 KiB, free: 2.2 GiB)
[2025-10-07 19:47:20] INFO  SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:20] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[24] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:20] INFO  TaskSchedulerImpl - Adding task set 15.0 with 1 tasks resource profile 0
[2025-10-07 19:47:20] INFO  TaskSetManager - Starting task 0.0 in stage 15.0 (TID 6) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-07 19:47:20] INFO  Executor - Running task 0.0 in stage 15.0 (TID 6)
[2025-10-07 19:47:20] INFO  CodeGenerator - Code generated in 7.078 ms
[2025-10-07 19:47:20] INFO  ShuffleBlockFetcherIterator - Getting 1 (2030.0 B) non-empty blocks including 1 (2030.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:20] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-07 19:47:20] INFO  Executor - Finished task 0.0 in stage 15.0 (TID 6). 8256 bytes result sent to driver
[2025-10-07 19:47:20] INFO  TaskSetManager - Finished task 0.0 in stage 15.0 (TID 6) in 129 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:20] INFO  TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:20] INFO  DAGScheduler - ShuffleMapStage 15 (collectAsList at SQLQueries.java:160) finished in 0.161 s
[2025-10-07 19:47:20] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:20] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:20] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:20] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:20] INFO  ShufflePartitionsUtil - For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:20] INFO  CodeGenerator - Code generated in 8.3846 ms
[2025-10-07 19:47:20] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:20] INFO  DAGScheduler - Got job 7 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:20] INFO  DAGScheduler - Final stage: ResultStage 20 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:20] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 19)
[2025-10-07 19:47:20] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:20] INFO  DAGScheduler - Submitting ResultStage 20 (MapPartitionsRDD[27] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:20] INFO  MemoryStore - Block broadcast_7 stored as values in memory (estimated size 53.2 KiB, free 2.2 GiB)
[2025-10-07 19:47:20] INFO  MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 2.2 GiB)
[2025-10-07 19:47:20] INFO  BlockManagerInfo - Added broadcast_7_piece0 in memory on DESKTOP-618L1DH:62628 (size: 24.1 KiB, free: 2.2 GiB)
[2025-10-07 19:47:20] INFO  SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:20] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[27] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:20] INFO  TaskSchedulerImpl - Adding task set 20.0 with 1 tasks resource profile 0
[2025-10-07 19:47:20] INFO  TaskSetManager - Starting task 0.0 in stage 20.0 (TID 7) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:20] INFO  Executor - Running task 0.0 in stage 20.0 (TID 7)
[2025-10-07 19:47:20] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.6 KiB) non-empty blocks including 1 (2.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:20] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-07 19:47:20] INFO  CodeGenerator - Code generated in 9.8336 ms
[2025-10-07 19:47:20] INFO  CodeGenerator - Code generated in 4.611 ms
[2025-10-07 19:47:20] INFO  BlockManagerInfo - Removed broadcast_4_piece0 on DESKTOP-618L1DH:62628 in memory (size: 27.3 KiB, free: 2.2 GiB)
[2025-10-07 19:47:20] INFO  CodeGenerator - Code generated in 35.1743 ms
[2025-10-07 19:47:20] INFO  BlockManagerInfo - Removed broadcast_3_piece0 on DESKTOP-618L1DH:62628 in memory (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-07 19:47:20] INFO  BlockManagerInfo - Removed broadcast_2_piece0 on DESKTOP-618L1DH:62628 in memory (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-07 19:47:20] INFO  BlockManagerInfo - Removed broadcast_5_piece0 on DESKTOP-618L1DH:62628 in memory (size: 26.5 KiB, free: 2.2 GiB)
[2025-10-07 19:47:20] INFO  BlockManagerInfo - Removed broadcast_6_piece0 on DESKTOP-618L1DH:62628 in memory (size: 27.2 KiB, free: 2.2 GiB)
[2025-10-07 19:47:20] INFO  Executor - Finished task 0.0 in stage 20.0 (TID 7). 10629 bytes result sent to driver
[2025-10-07 19:47:20] INFO  TaskSetManager - Finished task 0.0 in stage 20.0 (TID 7) in 102 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:20] INFO  TaskSchedulerImpl - Removed TaskSet 20.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:20] INFO  DAGScheduler - ResultStage 20 (collectAsList at SQLQueries.java:160) finished in 0.111 s
[2025-10-07 19:47:20] INFO  DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:20] INFO  TaskSchedulerImpl - Killing all running tasks in stage 20: Stage finished
[2025-10-07 19:47:20] INFO  DAGScheduler - Job 7 finished: collectAsList at SQLQueries.java:160, took 0.126052 s
[2025-10-07 19:47:20] INFO  CodeGenerator - Code generated in 10.2542 ms
[2025-10-07 19:47:20] INFO  SQLQueries - [FRONTIER AIRLINES INC.,134798,469465,28.71310960348482]
[2025-10-07 19:47:20] INFO  SQLQueries - [JETBLUE AIRWAYS,166188,611706,27.16795323243519]
[2025-10-07 19:47:20] INFO  SQLQueries - [SPIRIT AIRLINES,153800,614625,25.02338824486475]
[2025-10-07 19:47:20] INFO  SQLQueries - [AMERICAN AIRLINES INC.,555237,2320721,23.92519393757371]
[2025-10-07 19:47:20] INFO  SQLQueries - [ALLEGIANT AIR,66907,286825,23.32676719253900]
[2025-10-07 19:47:20] INFO  SQLQueries - [AIR WISCONSIN AIRLINES CORP,28051,121114,23.16082368677444]
[2025-10-07 19:47:20] INFO  SQLQueries - [PSA AIRLINES INC.,108984,528192,20.63340603416939]
[2025-10-07 19:47:20] INFO  SQLQueries - [SOUTHWEST AIRLINES CO.,702221,3423263,20.51320625964175]
[2025-10-07 19:47:20] INFO  SQLQueries - [ALASKA AIRLINES INC.,119750,585342,20.45812533527408]
[2025-10-07 19:47:20] INFO  SQLQueries - [MESA AIRLINES INC.,43553,213281,20.42047814854582]
[2025-10-07 19:47:20] INFO  SQLQueries - [UNITED AIRLINES INC.,357510,1811355,19.73715809435478]
[2025-10-07 19:47:20] INFO  SQLQueries - [GOJET AIRLINES LLC D/B/A UNITED EXPRESS,24900,128046,19.44613654467926]
[2025-10-07 19:47:20] INFO  SQLQueries - [ENVOY AIR,121004,623120,19.41905250994993]
[2025-10-07 19:47:20] INFO  SQLQueries - [HAWAIIAN AIRLINES INC.,36053,192555,18.72348160265898]
[2025-10-07 19:47:20] INFO  SQLQueries - [SKYWEST AIRLINES INC.,314058,1757526,17.86932312807890]
[2025-10-07 19:47:20] INFO  SQLQueries - [DELTA AIRLINES INC.,410005,2400405,17.08065930540888]
[2025-10-07 19:47:20] INFO  SQLQueries - [COMMUTEAIR LLC DBA COMMUTEAIR,29666,176790,16.78036088014028]
[2025-10-07 19:47:20] INFO  SQLQueries - [ENDEAVOR AIR INC.,78713,498682,15.78420717010038]
[2025-10-07 19:47:20] INFO  SQLQueries - [PIEDMONT AIRLINES,42639,271336,15.71446472270543]
[2025-10-07 19:47:20] INFO  SQLQueries - [HORIZON AIR,29214,190509,15.33470859644426]
[2025-10-07 19:47:20] INFO  SQLQueries - [REPUBLIC AIRLINE,104347,736041,14.17679178197954]
[2025-10-07 19:47:20] INFO  SQLQueries - Task 6.3 - On-time performance by airport
[2025-10-07 19:47:20] INFO  DAGScheduler - Registering RDD 31 (collectAsList at SQLQueries.java:160) as input to shuffle 5
[2025-10-07 19:47:20] INFO  DAGScheduler - Got map stage job 8 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:20] INFO  DAGScheduler - Final stage: ShuffleMapStage 21 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:20] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:20] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:20] INFO  DAGScheduler - Submitting ShuffleMapStage 21 (MapPartitionsRDD[31] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:20] INFO  MemoryStore - Block broadcast_8 stored as values in memory (estimated size 14.8 KiB, free 2.2 GiB)
[2025-10-07 19:47:20] INFO  MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 2.2 GiB)
[2025-10-07 19:47:20] INFO  BlockManagerInfo - Added broadcast_8_piece0 in memory on DESKTOP-618L1DH:62628 (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-07 19:47:20] INFO  SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:20] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[31] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:20] INFO  TaskSchedulerImpl - Adding task set 21.0 with 1 tasks resource profile 0
[2025-10-07 19:47:20] INFO  DAGScheduler - Registering RDD 33 (collectAsList at SQLQueries.java:160) as input to shuffle 6
[2025-10-07 19:47:20] INFO  TaskSetManager - Starting task 0.0 in stage 21.0 (TID 8) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:20] INFO  DAGScheduler - Got map stage job 9 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:20] INFO  DAGScheduler - Final stage: ShuffleMapStage 22 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:20] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:20] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:20] INFO  Executor - Running task 0.0 in stage 21.0 (TID 8)
[2025-10-07 19:47:20] INFO  DAGScheduler - Submitting ShuffleMapStage 22 (MapPartitionsRDD[33] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:20] INFO  MemoryStore - Block broadcast_9 stored as values in memory (estimated size 14.5 KiB, free 2.2 GiB)
[2025-10-07 19:47:20] INFO  MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
[2025-10-07 19:47:20] INFO  BlockManagerInfo - Added broadcast_9_piece0 in memory on DESKTOP-618L1DH:62628 (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-07 19:47:20] INFO  SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:20] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[33] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:20] INFO  TaskSchedulerImpl - Adding task set 22.0 with 1 tasks resource profile 0
[2025-10-07 19:47:20] INFO  TaskSetManager - Starting task 0.0 in stage 22.0 (TID 9) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:20] INFO  Executor - Running task 0.0 in stage 22.0 (TID 9)
[2025-10-07 19:47:20] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:20] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:21] INFO  Executor - Finished task 0.0 in stage 22.0 (TID 9). 1906 bytes result sent to driver
[2025-10-07 19:47:21] INFO  TaskSetManager - Finished task 0.0 in stage 22.0 (TID 9) in 433 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Removed TaskSet 22.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:21] INFO  DAGScheduler - ShuffleMapStage 22 (collectAsList at SQLQueries.java:160) finished in 0.445 s
[2025-10-07 19:47:21] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:21] INFO  DAGScheduler - running: Set(ShuffleMapStage 21)
[2025-10-07 19:47:21] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:21] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:21] INFO  Executor - Finished task 0.0 in stage 21.0 (TID 8). 1949 bytes result sent to driver
[2025-10-07 19:47:21] INFO  TaskSetManager - Finished task 0.0 in stage 21.0 (TID 8) in 488 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Removed TaskSet 21.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:21] INFO  DAGScheduler - ShuffleMapStage 21 (collectAsList at SQLQueries.java:160) finished in 0.501 s
[2025-10-07 19:47:21] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:21] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:21] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:21] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:21] INFO  ShufflePartitionsUtil - For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:21] INFO  SparkContext - Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-07 19:47:21] INFO  DAGScheduler - Got job 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-10-07 19:47:21] INFO  DAGScheduler - Final stage: ResultStage 24 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-10-07 19:47:21] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 23)
[2025-10-07 19:47:21] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:21] INFO  DAGScheduler - Submitting ResultStage 24 (MapPartitionsRDD[35] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-10-07 19:47:21] INFO  MemoryStore - Block broadcast_10 stored as values in memory (estimated size 8.2 KiB, free 2.2 GiB)
[2025-10-07 19:47:21] INFO  MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 2.2 GiB)
[2025-10-07 19:47:21] INFO  BlockManagerInfo - Added broadcast_10_piece0 in memory on DESKTOP-618L1DH:62628 (size: 4.2 KiB, free: 2.2 GiB)
[2025-10-07 19:47:21] INFO  SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:21] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[35] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Adding task set 24.0 with 1 tasks resource profile 0
[2025-10-07 19:47:21] INFO  TaskSetManager - Starting task 0.0 in stage 24.0 (TID 10) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9018 bytes) 
[2025-10-07 19:47:21] INFO  Executor - Running task 0.0 in stage 24.0 (TID 10)
[2025-10-07 19:47:21] INFO  ShuffleBlockFetcherIterator - Getting 1 (25.3 KiB) non-empty blocks including 1 (25.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:21] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-07 19:47:21] INFO  Executor - Finished task 0.0 in stage 24.0 (TID 10). 13829 bytes result sent to driver
[2025-10-07 19:47:21] INFO  TaskSetManager - Finished task 0.0 in stage 24.0 (TID 10) in 9 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Removed TaskSet 24.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:21] INFO  DAGScheduler - ResultStage 24 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.014 s
[2025-10-07 19:47:21] INFO  DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Killing all running tasks in stage 24: Stage finished
[2025-10-07 19:47:21] INFO  DAGScheduler - Job 10 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.017364 s
[2025-10-07 19:47:21] INFO  CodeGenerator - Code generated in 3.768 ms
[2025-10-07 19:47:21] INFO  MemoryStore - Block broadcast_11 stored as values in memory (estimated size 1026.9 KiB, free 2.2 GiB)
[2025-10-07 19:47:21] INFO  MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 2.2 GiB)
[2025-10-07 19:47:21] INFO  BlockManagerInfo - Added broadcast_11_piece0 in memory on DESKTOP-618L1DH:62628 (size: 11.2 KiB, free: 2.2 GiB)
[2025-10-07 19:47:21] INFO  SparkContext - Created broadcast 11 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-10-07 19:47:21] INFO  ShufflePartitionsUtil - For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:21] INFO  CodeGenerator - Code generated in 18.3402 ms
[2025-10-07 19:47:21] INFO  DAGScheduler - Registering RDD 38 (collectAsList at SQLQueries.java:160) as input to shuffle 7
[2025-10-07 19:47:21] INFO  DAGScheduler - Got map stage job 11 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:21] INFO  DAGScheduler - Final stage: ShuffleMapStage 26 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:21] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 25)
[2025-10-07 19:47:21] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:21] INFO  DAGScheduler - Submitting ShuffleMapStage 26 (MapPartitionsRDD[38] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:21] INFO  MemoryStore - Block broadcast_12 stored as values in memory (estimated size 56.0 KiB, free 2.2 GiB)
[2025-10-07 19:47:21] INFO  MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 25.1 KiB, free 2.2 GiB)
[2025-10-07 19:47:21] INFO  BlockManagerInfo - Added broadcast_12_piece0 in memory on DESKTOP-618L1DH:62628 (size: 25.1 KiB, free: 2.2 GiB)
[2025-10-07 19:47:21] INFO  SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:21] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[38] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Adding task set 26.0 with 1 tasks resource profile 0
[2025-10-07 19:47:21] INFO  TaskSetManager - Starting task 0.0 in stage 26.0 (TID 11) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9007 bytes) 
[2025-10-07 19:47:21] INFO  Executor - Running task 0.0 in stage 26.0 (TID 11)
[2025-10-07 19:47:21] INFO  ShuffleBlockFetcherIterator - Getting 1 (575.5 KiB) non-empty blocks including 1 (575.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:21] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-07 19:47:21] INFO  CodeGenerator - Code generated in 19.9858 ms
[2025-10-07 19:47:21] INFO  Executor - Finished task 0.0 in stage 26.0 (TID 11). 6634 bytes result sent to driver
[2025-10-07 19:47:21] INFO  TaskSetManager - Finished task 0.0 in stage 26.0 (TID 11) in 225 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Removed TaskSet 26.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:21] INFO  DAGScheduler - ShuffleMapStage 26 (collectAsList at SQLQueries.java:160) finished in 0.241 s
[2025-10-07 19:47:21] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:21] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:21] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:21] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:21] INFO  ShufflePartitionsUtil - For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:21] INFO  HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-10-07 19:47:21] INFO  CodeGenerator - Code generated in 12.5341 ms
[2025-10-07 19:47:21] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:21] INFO  DAGScheduler - Got job 12 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:21] INFO  DAGScheduler - Final stage: ResultStage 29 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:21] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 28)
[2025-10-07 19:47:21] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:21] INFO  DAGScheduler - Submitting ResultStage 29 (MapPartitionsRDD[43] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:21] INFO  MemoryStore - Block broadcast_13 stored as values in memory (estimated size 60.8 KiB, free 2.2 GiB)
[2025-10-07 19:47:21] INFO  MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 26.8 KiB, free 2.2 GiB)
[2025-10-07 19:47:21] INFO  BlockManagerInfo - Added broadcast_13_piece0 in memory on DESKTOP-618L1DH:62628 (size: 26.8 KiB, free: 2.2 GiB)
[2025-10-07 19:47:21] INFO  SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:21] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[43] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Adding task set 29.0 with 1 tasks resource profile 0
[2025-10-07 19:47:21] INFO  TaskSetManager - Starting task 0.0 in stage 29.0 (TID 12) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:21] INFO  Executor - Running task 0.0 in stage 29.0 (TID 12)
[2025-10-07 19:47:21] INFO  ShuffleBlockFetcherIterator - Getting 1 (28.1 KiB) non-empty blocks including 1 (28.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:21] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-07 19:47:21] INFO  CodeGenerator - Code generated in 16.0114 ms
[2025-10-07 19:47:21] INFO  Executor - Finished task 0.0 in stage 29.0 (TID 12). 25989 bytes result sent to driver
[2025-10-07 19:47:21] INFO  TaskSetManager - Finished task 0.0 in stage 29.0 (TID 12) in 64 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Removed TaskSet 29.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:21] INFO  DAGScheduler - ResultStage 29 (collectAsList at SQLQueries.java:160) finished in 0.070 s
[2025-10-07 19:47:21] INFO  DAGScheduler - Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Killing all running tasks in stage 29: Stage finished
[2025-10-07 19:47:21] INFO  DAGScheduler - Job 12 finished: collectAsList at SQLQueries.java:160, took 0.077904 s
[2025-10-07 19:47:21] INFO  DAGScheduler - Registering RDD 44 (collectAsList at SQLQueries.java:160) as input to shuffle 8
[2025-10-07 19:47:21] INFO  DAGScheduler - Got map stage job 13 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:21] INFO  DAGScheduler - Final stage: ShuffleMapStage 32 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:21] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 31)
[2025-10-07 19:47:21] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:21] INFO  DAGScheduler - Submitting ShuffleMapStage 32 (MapPartitionsRDD[44] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:21] INFO  MemoryStore - Block broadcast_14 stored as values in memory (estimated size 70.8 KiB, free 2.2 GiB)
[2025-10-07 19:47:21] INFO  MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 2.2 GiB)
[2025-10-07 19:47:21] INFO  BlockManagerInfo - Added broadcast_14_piece0 in memory on DESKTOP-618L1DH:62628 (size: 30.0 KiB, free: 2.2 GiB)
[2025-10-07 19:47:21] INFO  SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:21] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[44] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Adding task set 32.0 with 1 tasks resource profile 0
[2025-10-07 19:47:21] INFO  TaskSetManager - Starting task 0.0 in stage 32.0 (TID 13) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-07 19:47:21] INFO  Executor - Running task 0.0 in stage 32.0 (TID 13)
[2025-10-07 19:47:21] INFO  ShuffleBlockFetcherIterator - Getting 1 (28.1 KiB) non-empty blocks including 1 (28.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:21] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-07 19:47:21] INFO  BlockManagerInfo - Removed broadcast_13_piece0 on DESKTOP-618L1DH:62628 in memory (size: 26.8 KiB, free: 2.2 GiB)
[2025-10-07 19:47:21] INFO  BlockManagerInfo - Removed broadcast_8_piece0 on DESKTOP-618L1DH:62628 in memory (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-07 19:47:21] INFO  BlockManagerInfo - Removed broadcast_9_piece0 on DESKTOP-618L1DH:62628 in memory (size: 7.6 KiB, free: 2.2 GiB)
[2025-10-07 19:47:21] INFO  BlockManagerInfo - Removed broadcast_7_piece0 on DESKTOP-618L1DH:62628 in memory (size: 24.1 KiB, free: 2.2 GiB)
[2025-10-07 19:47:21] INFO  BlockManagerInfo - Removed broadcast_10_piece0 on DESKTOP-618L1DH:62628 in memory (size: 4.2 KiB, free: 2.2 GiB)
[2025-10-07 19:47:21] INFO  BlockManagerInfo - Removed broadcast_12_piece0 on DESKTOP-618L1DH:62628 in memory (size: 25.1 KiB, free: 2.2 GiB)
[2025-10-07 19:47:21] INFO  Executor - Finished task 0.0 in stage 32.0 (TID 13). 8258 bytes result sent to driver
[2025-10-07 19:47:21] INFO  TaskSetManager - Finished task 0.0 in stage 32.0 (TID 13) in 281 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Removed TaskSet 32.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:21] INFO  DAGScheduler - ShuffleMapStage 32 (collectAsList at SQLQueries.java:160) finished in 0.295 s
[2025-10-07 19:47:21] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:21] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:21] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:21] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:21] INFO  ShufflePartitionsUtil - For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:21] INFO  CodeGenerator - Code generated in 13.1077 ms
[2025-10-07 19:47:21] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:21] INFO  DAGScheduler - Got job 14 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:21] INFO  DAGScheduler - Final stage: ResultStage 36 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:21] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 35)
[2025-10-07 19:47:21] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:21] INFO  DAGScheduler - Submitting ResultStage 36 (MapPartitionsRDD[47] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:21] INFO  MemoryStore - Block broadcast_15 stored as values in memory (estimated size 54.4 KiB, free 2.2 GiB)
[2025-10-07 19:47:21] INFO  MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 2.2 GiB)
[2025-10-07 19:47:21] INFO  BlockManagerInfo - Added broadcast_15_piece0 in memory on DESKTOP-618L1DH:62628 (size: 24.8 KiB, free: 2.2 GiB)
[2025-10-07 19:47:21] INFO  SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:21] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[47] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:21] INFO  TaskSchedulerImpl - Adding task set 36.0 with 1 tasks resource profile 0
[2025-10-07 19:47:21] INFO  TaskSetManager - Starting task 0.0 in stage 36.0 (TID 14) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:21] INFO  Executor - Running task 0.0 in stage 36.0 (TID 14)
[2025-10-07 19:47:21] INFO  ShuffleBlockFetcherIterator - Getting 1 (37.0 KiB) non-empty blocks including 1 (37.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:21] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 3 ms
[2025-10-07 19:47:21] INFO  CodeGenerator - Code generated in 16.1997 ms
[2025-10-07 19:47:22] INFO  Executor - Finished task 0.0 in stage 36.0 (TID 14). 27916 bytes result sent to driver
[2025-10-07 19:47:22] INFO  TaskSetManager - Finished task 0.0 in stage 36.0 (TID 14) in 66 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:22] INFO  TaskSchedulerImpl - Removed TaskSet 36.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:22] INFO  DAGScheduler - ResultStage 36 (collectAsList at SQLQueries.java:160) finished in 0.085 s
[2025-10-07 19:47:22] INFO  DAGScheduler - Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:22] INFO  TaskSchedulerImpl - Killing all running tasks in stage 36: Stage finished
[2025-10-07 19:47:22] INFO  DAGScheduler - Job 14 finished: collectAsList at SQLQueries.java:160, took 0.096454 s
[2025-10-07 19:47:22] INFO  SQLQueries - [JACK EDWARDS NATIONAL AIRPORT,7,19,36.84210526315789]
[2025-10-07 19:47:22] INFO  SQLQueries - [PONCE, PR: MERCEDITA,772,2259,34.17441345728198]
[2025-10-07 19:47:22] INFO  SQLQueries - [AGUADILLA, PR: RAFAEL HERNANDEZ,2066,6277,32.91381233073124]
[2025-10-07 19:47:22] INFO  SQLQueries - [PROVO-UTAH LAKE INTERNATIONAL AIRPORT,1820,5563,32.71616034513752]
[2025-10-07 19:47:22] INFO  SQLQueries - [ORLANDO SANFORD INTERNATIONAL AIRPORT,6542,23059,28.37070124463333]
[2025-10-07 19:47:22] INFO  SQLQueries - [HAGERSTOWN REGIONAL RICHARD A HENSON FIELD,170,609,27.91461412151067]
[2025-10-07 19:47:22] INFO  SQLQueries - [SAN JUAN, PR: LUIS MUNOZ MARIN INTERNATIONAL,23125,83895,27.56421717623220]
[2025-10-07 19:47:22] INFO  SQLQueries - [CONCORD-PADGETT REGIONAL AIRPORT,485,1760,27.55681818181818]
[2025-10-07 19:47:22] INFO  SQLQueries - [ASPEN-PITKIN COUNTY AIRPORT (SARDY FIELD),4950,18067,27.39801848674379]
[2025-10-07 19:47:22] INFO  SQLQueries - [HOUGHTON COUNTY MEMORIAL AIRPORT,473,1737,27.23085780080599]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHIPPEWA VALLEY REGIONAL AIRPORT,79,292,27.05479452054795]
[2025-10-07 19:47:22] INFO  SQLQueries - [TRENTON MERCER AIRPORT,1239,4616,26.84142114384749]
[2025-10-07 19:47:22] INFO  SQLQueries - [PRESQUE ISLE INTERNATIONAL AIRPORT,363,1357,26.75018422991894]
[2025-10-07 19:47:22] INFO  SQLQueries - [PUNTA GORDA AIRPORT,4233,16116,26.26582278481013]
[2025-10-07 19:47:22] INFO  SQLQueries - [STOCKTON METROPOLITAN AIRPORT,319,1240,25.72580645161290]
[2025-10-07 19:47:22] INFO  SQLQueries - [PALM BEACH INTERNATIONAL AIRPORT,18378,71475,25.71248688352571]
[2025-10-07 19:47:22] INFO  SQLQueries - [BISHOP INTERNATIONAL AIRPORT,1891,7382,25.61636412896234]
[2025-10-07 19:47:22] INFO  SQLQueries - [SAN FRANCISCO INTERNATIONAL AIRPORT,84394,334989,25.19306604097448]
[2025-10-07 19:47:22] INFO  SQLQueries - [FORT LAUDERDALE HOLLYWOOD INTERNATIONAL AIRPORT,55335,220499,25.09535190635785]
[2025-10-07 19:47:22] INFO  SQLQueries - [SANTA MARIA PUBLIC AIRPORT CAPTAIN G ALLAN HANCOCK FIELD,64,256,25.00000000000000]
[2025-10-07 19:47:22] INFO  SQLQueries - [FOUR CORNERS REGIONAL AIRPORT,6,24,25.00000000000000]
[2025-10-07 19:47:22] INFO  SQLQueries - [PAGO PAGO, TT: PAGO PAGO INTERNATIONAL,76,306,24.83660130718954]
[2025-10-07 19:47:22] INFO  SQLQueries - [LEA COUNTY REGIONAL AIRPORT,407,1645,24.74164133738602]
[2025-10-07 19:47:22] INFO  SQLQueries - [WILEY POST WILL ROGERS MEMORIAL AIRPORT,237,972,24.38271604938272]
[2025-10-07 19:47:22] INFO  SQLQueries - [ST. PETERSBURG CLEARWATER INTERNATIONAL AIRPORT,4869,20031,24.30732364834507]
[2025-10-07 19:47:22] INFO  SQLQueries - [ORLANDO INTERNATIONAL AIRPORT,95270,392415,24.27786909266975]
[2025-10-07 19:47:22] INFO  SQLQueries - [AKRON CANTON REGIONAL AIRPORT,2055,8596,23.90646812470917]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHRISTIANSTED, VI: HENRY E. ROHLSEN,695,2928,23.73633879781421]
[2025-10-07 19:47:22] INFO  SQLQueries - [LINCOLN AIRPORT,1499,6316,23.73337555414820]
[2025-10-07 19:47:22] INFO  SQLQueries - [LONG ISLAND MAC ARTHUR AIRPORT,2814,11880,23.68686868686869]
[2025-10-07 19:47:22] INFO  SQLQueries - [YELLOWSTONE REGIONAL AIRPORT,487,2068,23.54932301740812]
[2025-10-07 19:47:22] INFO  SQLQueries - [APPLETON INTERNATIONAL AIRPORT,4095,17442,23.47781217750258]
[2025-10-07 19:47:22] INFO  SQLQueries - [WESTCHESTER COUNTY AIRPORT,7106,30355,23.40965244605502]
[2025-10-07 19:47:22] INFO  SQLQueries - [WILKES BARRE SCRANTON INTERNATIONAL AIRPORT,1666,7132,23.35950644980370]
[2025-10-07 19:47:22] INFO  SQLQueries - [TAMPA INTERNATIONAL AIRPORT,44908,192272,23.35649496546559]
[2025-10-07 19:47:22] INFO  SQLQueries - [EASTERN SIERRA REGIONAL AIRPORT,163,701,23.25249643366619]
[2025-10-07 19:47:22] INFO  SQLQueries - [JACKSONVILLE INTERNATIONAL AIRPORT,16770,72698,23.06803488404083]
[2025-10-07 19:47:22] INFO  SQLQueries - [HARRY REID INTERNATIONAL AIRPORT,106470,461852,23.05283943774196]
[2025-10-07 19:47:22] INFO  SQLQueries - [EAGLE COUNTY REGIONAL AIRPORT,2103,9213,22.82644089873006]
[2025-10-07 19:47:22] INFO  SQLQueries - [MIAMI INTERNATIONAL AIRPORT,59802,262331,22.79639081923219]
[2025-10-07 19:47:22] INFO  SQLQueries - [SAN DIEGO INTERNATIONAL AIRPORT,51510,226264,22.76544213838702]
[2025-10-07 19:47:22] INFO  SQLQueries - [CITY OF COLORADO SPRINGS MUNICIPAL AIRPORT,6908,30436,22.69680641345775]
[2025-10-07 19:47:22] INFO  SQLQueries - [LOGAN INTERNATIONAL AIRPORT,77962,345511,22.56425989331743]
[2025-10-07 19:47:22] INFO  SQLQueries - [MCALLEN MILLER INTERNATIONAL AIRPORT,3061,13587,22.52888790755870]
[2025-10-07 19:47:22] INFO  SQLQueries - [WICHITA EISENHOWER NATIONAL AIRPORT,6160,27358,22.51626580890416]
[2025-10-07 19:47:22] INFO  SQLQueries - [BRADLEY INTERNATIONAL AIRPORT,12767,56725,22.50683120317320]
[2025-10-07 19:47:22] INFO  SQLQueries - [SAN ANTONIO INTERNATIONAL AIRPORT,22444,99978,22.44893876652864]
[2025-10-07 19:47:22] INFO  SQLQueries - [SOUTHWEST OREGON REGIONAL AIRPORT,185,825,22.42424242424242]
[2025-10-07 19:47:22] INFO  SQLQueries - [DALLAS FORT WORTH INTERNATIONAL AIRPORT,164622,734327,22.41807804969721]
[2025-10-07 19:47:22] INFO  SQLQueries - [YEAGER AIRPORT,1899,8478,22.39915074309979]
[2025-10-07 19:47:22] INFO  SQLQueries - [BUFFALO NIAGARA INTERNATIONAL AIRPORT,12914,57676,22.39059574172966]
[2025-10-07 19:47:22] INFO  SQLQueries - [NORTH CENTRAL WEST VIRGINIA AIRPORT,111,497,22.33400402414487]
[2025-10-07 19:47:22] INFO  SQLQueries - [LOUIS ARMSTRONG NEW ORLEANS INTERNATIONAL AIRPORT,27502,123279,22.30874682630456]
[2025-10-07 19:47:22] INFO  SQLQueries - [SOUTHWEST FLORIDA INTERNATIONAL AIRPORT,19148,85888,22.29415052160954]
[2025-10-07 19:47:22] INFO  SQLQueries - [DES MOINES INTERNATIONAL AIRPORT,8540,38505,22.17893780028568]
[2025-10-07 19:47:22] INFO  SQLQueries - [PENSACOLA INTERNATIONAL AIRPORT,7233,32723,22.10371909665984]
[2025-10-07 19:47:22] INFO  SQLQueries - [AUSTIN BERGSTROM INTERNATIONAL AIRPORT,47257,214301,22.05169364585326]
[2025-10-07 19:47:22] INFO  SQLQueries - [MEMPHIS INTERNATIONAL AIRPORT,12929,58697,22.02667938736222]
[2025-10-07 19:47:22] INFO  SQLQueries - [ROCHESTER INTERNATIONAL AIRPORT,1099,4996,21.99759807846277]
[2025-10-07 19:47:22] INFO  SQLQueries - [BILL & HILLARY CLINTON NATIONAL AIRPORT/ADAMS FIELD,7583,34554,21.94536088441280]
[2025-10-07 19:47:22] INFO  SQLQueries - [SPRINGFIELD BRANSON NATIONAL AIRPORT,5356,24516,21.84695708924784]
[2025-10-07 19:47:22] INFO  SQLQueries - [ALBANY INTERNATIONAL AIRPORT,8170,37521,21.77447296180805]
[2025-10-07 19:47:22] INFO  SQLQueries - [JOHN F KENNEDY INTERNATIONAL AIRPORT,66721,306626,21.75973335594503]
[2025-10-07 19:47:22] INFO  SQLQueries - [WILL ROGERS WORLD AIRPORT,12565,57759,21.75418549490123]
[2025-10-07 19:47:22] INFO  SQLQueries - [GENERAL MITCHELL INTERNATIONAL AIRPORT,15500,71289,21.74248481532915]
[2025-10-07 19:47:22] INFO  SQLQueries - [SARASOTA BRADENTON INTERNATIONAL AIRPORT,8775,40517,21.65757583236666]
[2025-10-07 19:47:22] INFO  SQLQueries - [RICKENBACKER INTERNATIONAL AIRPORT,510,2355,21.65605095541401]
[2025-10-07 19:47:22] INFO  SQLQueries - [THE EASTERN IOWA AIRPORT,4296,19869,21.62162162162162]
[2025-10-07 19:47:22] INFO  SQLQueries - [FORT DODGE REGIONAL AIRPORT,326,1508,21.61803713527851]
[2025-10-07 19:47:22] INFO  SQLQueries - [SOUTH BEND REGIONAL AIRPORT,3418,15835,21.58509630565204]
[2025-10-07 19:47:22] INFO  SQLQueries - [BIRMINGHAM-SHUTTLESWORTH INTERNATIONAL AIRPORT,9663,44790,21.57401205626256]
[2025-10-07 19:47:22] INFO  SQLQueries - [NEWARK LIBERTY INTERNATIONAL AIRPORT,75019,347746,21.57292966705584]
[2025-10-07 19:47:22] INFO  SQLQueries - [ATLANTIC CITY INTERNATIONAL AIRPORT,1539,7136,21.56670403587444]
[2025-10-07 19:47:22] INFO  SQLQueries - [RICHMOND INTERNATIONAL AIRPORT,12337,57386,21.49827484055345]
[2025-10-07 19:47:22] INFO  SQLQueries - [RALEIGH DURHAM INTERNATIONAL AIRPORT,31661,147317,21.49174908530584]
[2025-10-07 19:47:22] INFO  SQLQueries - [MORGANTOWN MUNICIPAL AIRPORT WALTER L. (BILL) HART FIELD,73,340,21.47058823529412]
[2025-10-07 19:47:22] INFO  SQLQueries - [GENERAL WAYNE A. DOWNING PEORIA INTERNATIONAL AIRPORT,2390,11136,21.46192528735632]
[2025-10-07 19:47:22] INFO  SQLQueries - [MCGHEE TYSON AIRPORT,9724,45309,21.46151978635591]
[2025-10-07 19:47:22] INFO  SQLQueries - [QUAD CITY INTERNATIONAL AIRPORT,2530,11798,21.44431259535514]
[2025-10-07 19:47:22] INFO  SQLQueries - [DANE COUNTY REGIONAL TRUAX FIELD,6623,30887,21.44267814938324]
[2025-10-07 19:47:22] INFO  SQLQueries - [SEATTLE PAINE FIELD INTERNATIONAL AIRPORT,1824,8507,21.44116609850711]
[2025-10-07 19:47:22] INFO  SQLQueries - [EL PASO INTERNATIONAL AIRPORT,10092,47215,21.37456316848459]
[2025-10-07 19:47:22] INFO  SQLQueries - [MBS INTERNATIONAL AIRPORT,1083,5078,21.32729421031902]
[2025-10-07 19:47:22] INFO  SQLQueries - [NORFOLK INTERNATIONAL AIRPORT,11598,54384,21.32612533097970]
[2025-10-07 19:47:22] INFO  SQLQueries - [YAMPA VALLEY AIRPORT,1362,6392,21.30788485607009]
[2025-10-07 19:47:22] INFO  SQLQueries - [THEODORE FRANCIS GREEN STATE AIRPORT,8489,39861,21.29650535611249]
[2025-10-07 19:47:22] INFO  SQLQueries - [LUBBOCK PRESTON SMITH INTERNATIONAL AIRPORT,3680,17306,21.26430139835895]
[2025-10-07 19:47:22] INFO  SQLQueries - [GERALD R. FORD INTERNATIONAL AIRPORT,9765,45962,21.24581175753884]
[2025-10-07 19:47:22] INFO  SQLQueries - [PHILADELPHIA INTERNATIONAL AIRPORT,59166,279423,21.17434856829967]
[2025-10-07 19:47:22] INFO  SQLQueries - [JOHN MURTHA JOHNSTOWN CAMBRIA COUNTY AIRPORT,372,1759,21.14837976122797]
[2025-10-07 19:47:22] INFO  SQLQueries - [COLUMBIA REGIONAL AIRPORT,998,4722,21.13511224057603]
[2025-10-07 19:47:22] INFO  SQLQueries - [CAPITAL CITY AIRPORT,1056,5005,21.09890109890110]
[2025-10-07 19:47:22] INFO  SQLQueries - [EPPLEY AIRFIELD,12111,57480,21.06993736951983]
[2025-10-07 19:47:22] INFO  SQLQueries - [TULSA INTERNATIONAL AIRPORT,9437,44873,21.03046375325920]
[2025-10-07 19:47:22] INFO  SQLQueries - [SALINA MUNICIPAL AIRPORT,373,1774,21.02593010146561]
[2025-10-07 19:47:22] INFO  SQLQueries - [SAVANNAH HILTON HEAD INTERNATIONAL AIRPORT,10401,49503,21.01084782740440]
[2025-10-07 19:47:22] INFO  SQLQueries - [CLEVELAND HOPKINS INTERNATIONAL AIRPORT,21969,104820,20.95878649112765]
[2025-10-07 19:47:22] INFO  SQLQueries - [KANSAS CITY INTERNATIONAL AIRPORT,25623,122285,20.95351024246637]
[2025-10-07 19:47:22] INFO  SQLQueries - [MONTROSE REGIONAL AIRPORT,1462,6992,20.90961098398169]
[2025-10-07 19:47:22] INFO  SQLQueries - [NORTHWEST FLORIDA BEACHES INTERNATIONAL AIRPORT,4353,20854,20.87369329625012]
[2025-10-07 19:47:22] INFO  SQLQueries - [SYRACUSE HANCOCK INTERNATIONAL AIRPORT,8029,38494,20.85779602015899]
[2025-10-07 19:47:22] INFO  SQLQueries - [FRESNO YOSEMITE INTERNATIONAL AIRPORT,5913,28353,20.85493598560999]
[2025-10-07 19:47:22] INFO  SQLQueries - [CINCINNATI NORTHERN KENTUCKY INTERNATIONAL AIRPORT,21606,103613,20.85259571675369]
[2025-10-07 19:47:22] INFO  SQLQueries - [PRESCOTT INTERNATIONAL AIRPORT - ERNEST A. LOVE FIELD,366,1756,20.84282460136674]
[2025-10-07 19:47:22] INFO  SQLQueries - [JAMES M COX DAYTON INTERNATIONAL AIRPORT,5053,24261,20.82766580107992]
[2025-10-07 19:47:22] INFO  SQLQueries - [ASHEVILLE REGIONAL AIRPORT,6257,30107,20.78254226591822]
[2025-10-07 19:47:22] INFO  SQLQueries - [SIOUX GATEWAY AIRPORT / BRIGADIER GENERAL BUD DAY FIELD,365,1758,20.76222980659841]
[2025-10-07 19:47:22] INFO  SQLQueries - [SIOUX FALLS REGIONAL AIRPORT / JOE FOSS FIELD,3997,19258,20.75501090455914]
[2025-10-07 19:47:22] INFO  SQLQueries - [LA CROSSE REGIONAL AIRPORT,484,2343,20.65727699530516]
[2025-10-07 19:47:22] INFO  SQLQueries - [DECATUR AIRPORT,418,2025,20.64197530864198]
[2025-10-07 19:47:22] INFO  SQLQueries - [AUSTIN STRAUBEL INTERNATIONAL AIRPORT,2599,12599,20.62862131915231]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHARLESTON INTERNATIONAL AIRPORT,12901,62664,20.58757819481680]
[2025-10-07 19:47:22] INFO  SQLQueries - [DESTIN-FORT WALTON BEACH AIRPORT,4722,22939,20.58502986180740]
[2025-10-07 19:47:22] INFO  SQLQueries - [ONTARIO INTERNATIONAL AIRPORT,12701,61722,20.57775185509219]
[2025-10-07 19:47:22] INFO  SQLQueries - [FORT WAYNE INTERNATIONAL AIRPORT,3288,15989,20.56413784476828]
[2025-10-07 19:47:22] INFO  SQLQueries - [MESA GATEWAY AIRPORT,2956,14384,20.55061179087875]
[2025-10-07 19:47:22] INFO  SQLQueries - [RONALD REAGAN WASHINGTON NATIONAL AIRPORT,71495,347972,20.54619337188050]
[2025-10-07 19:47:22] INFO  SQLQueries - [MARQUETTE/SAWYER INTERNATIONAL AIRPORT,470,2292,20.50610820244328]
[2025-10-07 19:47:22] INFO  SQLQueries - [KEY FIELD / MERIDIAN REGIONAL AIRPORT,320,1570,20.38216560509554]
[2025-10-07 19:47:22] INFO  SQLQueries - [EUGENE F. KRANZ TOLEDO EXPRESS AIRPORT,198,972,20.37037037037037]
[2025-10-07 19:47:22] INFO  SQLQueries - [CASPER-NATRONA COUNTY INTERNATIONAL AIRPORT,1090,5357,20.34720925891357]
[2025-10-07 19:47:22] INFO  SQLQueries - [ALBUQUERQUE INTERNATIONAL SUNPORT,12133,59752,20.30559646539028]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHERRY CAPITAL AIRPORT,2479,12212,20.29970520799214]
[2025-10-07 19:47:22] INFO  SQLQueries - [WATERLOO REGIONAL AIRPORT,331,1640,20.18292682926829]
[2025-10-07 19:47:22] INFO  SQLQueries - [ABRAHAM LINCOLN CAPITAL AIRPORT,385,1910,20.15706806282723]
[2025-10-07 19:47:22] INFO  SQLQueries - [INDIANAPOLIS INTERNATIONAL AIRPORT,23181,115079,20.14355355885957]
[2025-10-07 19:47:22] INFO  SQLQueries - [SITKA ROCKY GUTIERREZ AIRPORT,667,3312,20.13888888888889]
[2025-10-07 19:47:22] INFO  SQLQueries - [SANTA FE MUNICIPAL AIRPORT,1517,7540,20.11936339522546]
[2025-10-07 19:47:22] INFO  SQLQueries - [JACKSON HOLE AIRPORT,2654,13196,20.11215519854501]
[2025-10-07 19:47:22] INFO  SQLQueries - [SAN LUIS COUNTY REGIONAL AIRPORT,2591,12885,20.10865347303066]
[2025-10-07 19:47:22] INFO  SQLQueries - [DENVER INTERNATIONAL AIRPORT,148452,739089,20.08580833972634]
[2025-10-07 19:47:22] INFO  SQLQueries - [RICK HUSBAND AMARILLO INTERNATIONAL AIRPORT,2846,14174,20.07901792013546]
[2025-10-07 19:47:22] INFO  SQLQueries - [KILLEEN REGIONAL AIRPORT / ROBERT GRAY ARMY AIRFIELD,858,4278,20.05610098176718]
[2025-10-07 19:47:22] INFO  SQLQueries - [MANCHESTER-BOSTON REGIONAL AIRPORT,3521,17563,20.04782781984855]
[2025-10-07 19:47:22] INFO  SQLQueries - [MARTHA'S VINEYARD AIRPORT,453,2263,20.01767565178966]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHICAGO O'HARE INTERNATIONAL AIRPORT,150062,749680,20.01680717105965]
[2025-10-07 19:47:22] INFO  SQLQueries - [FREDERICK DOUGLASS GREATER ROCHESTER INTERNATIONAL AIRPORT,7694,38468,20.00103982530935]
[2025-10-07 19:47:22] INFO  SQLQueries - [ITHACA TOMPKINS REGIONAL AIRPORT,698,3492,19.98854524627721]
[2025-10-07 19:47:22] INFO  SQLQueries - [GARDEN CITY REGIONAL AIRPORT,351,1757,19.97723392145703]
[2025-10-07 19:47:22] INFO  SQLQueries - [ABILENE REGIONAL AIRPORT,767,3849,19.92725383216420]
[2025-10-07 19:47:22] INFO  SQLQueries - [GREENVILLE SPARTANBURG INTERNATIONAL AIRPORT,7779,39064,19.91347532254761]
[2025-10-07 19:47:22] INFO  SQLQueries - [PITTSBURGH INTERNATIONAL AIRPORT,21352,107286,19.90194433570084]
[2025-10-07 19:47:22] INFO  SQLQueries - [TED STEVENS ANCHORAGE INTERNATIONAL AIRPORT,10334,52039,19.85818328561271]
[2025-10-07 19:47:22] INFO  SQLQueries - [LOUISVILLE MUHAMMAD ALI INTERNATIONAL AIRPORT,12443,62774,19.82190078695001]
[2025-10-07 19:47:22] INFO  SQLQueries - [LEHIGH VALLEY INTERNATIONAL AIRPORT,2216,11195,19.79455113890130]
[2025-10-07 19:47:22] INFO  SQLQueries - [JOHN GLENN COLUMBUS INTERNATIONAL AIRPORT,20888,105540,19.79154822815994]
[2025-10-07 19:47:22] INFO  SQLQueries - [SCOTT AFB/MIDAMERICA AIRPORT,513,2599,19.73836090804155]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHARLOTTE DOUGLAS INTERNATIONAL AIRPORT,114355,579930,19.71875916058835]
[2025-10-07 19:47:22] INFO  SQLQueries - [ROANOKE–BLACKSBURG REGIONAL AIRPORT,3233,16408,19.70380302291565]
[2025-10-07 19:47:22] INFO  SQLQueries - [BATON ROUGE METROPOLITAN AIRPORT,3032,15409,19.67681225257966]
[2025-10-07 19:47:22] INFO  SQLQueries - [BOZEMAN YELLOWSTONE INTERNATIONAL AIRPORT,5027,25573,19.65745121808157]
[2025-10-07 19:47:22] INFO  SQLQueries - [CALIFORNIA REDWOOD COAST-HUMBOLDT COUNTY AIRPORT,814,4143,19.64759835867729]
[2025-10-07 19:47:22] INFO  SQLQueries - [TUCSON INTERNATIONAL AIRPORT / MORRIS AIR NATIONAL GUARD BASE,9056,46166,19.61616774249448]
[2025-10-07 19:47:22] INFO  SQLQueries - [DALLAS LOVE FIELD,34705,177019,19.60524011546783]
[2025-10-07 19:47:22] INFO  SQLQueries - [NASHVILLE INTERNATIONAL AIRPORT,47143,240480,19.60370924817033]
[2025-10-07 19:47:22] INFO  SQLQueries - [BLUE GRASS AIRPORT,4561,23310,19.56670956670957]
[2025-10-07 19:47:22] INFO  SQLQueries - [RENO TAHOE INTERNATIONAL AIRPORT,10128,51802,19.55136867302421]
[2025-10-07 19:47:22] INFO  SQLQueries - [KEY WEST INTERNATIONAL AIRPORT,3672,18787,19.54543035077447]
[2025-10-07 19:47:22] INFO  SQLQueries - [LARAMIE REGIONAL AIRPORT,295,1510,19.53642384105960]
[2025-10-07 19:47:22] INFO  SQLQueries - [NORTHWEST ARKANSAS NATIONAL AIRPORT,6926,35471,19.52580981646979]
[2025-10-07 19:47:22] INFO  SQLQueries - [WACO REGIONAL AIRPORT,509,2608,19.51687116564417]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHARLOTTE AMALIE, VI: CYRIL E KING,2471,12685,19.47970043358297]
[2025-10-07 19:47:22] INFO  SQLQueries - [MYRTLE BEACH INTERNATIONAL AIRPORT,7177,36899,19.45039160952871]
[2025-10-07 19:47:22] INFO  SQLQueries - [HAYS REGIONAL AIRPORT,322,1657,19.43270971635486]
[2025-10-07 19:47:22] INFO  SQLQueries - [WILLIAM P HOBBY AIRPORT,26112,134520,19.41123996431757]
[2025-10-07 19:47:22] INFO  SQLQueries - [KALAMAZOO BATTLE CREEK INTERNATIONAL AIRPORT,825,4260,19.36619718309859]
[2025-10-07 19:47:22] INFO  SQLQueries - [COLUMBIA METROPOLITAN AIRPORT,4656,24047,19.36208258826465]
[2025-10-07 19:47:22] INFO  SQLQueries - [BURLINGTON INTERNATIONAL AIRPORT,4157,21482,19.35108462899171]
[2025-10-07 19:47:22] INFO  SQLQueries - [HARRISBURG INTERNATIONAL AIRPORT,4211,21775,19.33869115958668]
[2025-10-07 19:47:22] INFO  SQLQueries - [LAGUARDIA AIRPORT,76645,397625,19.27569946557686]
[2025-10-07 19:47:22] INFO  SQLQueries - [GEORGE BUSH INTERCONTINENTAL HOUSTON AIRPORT,75754,393258,19.26318091431071]
[2025-10-07 19:47:22] INFO  SQLQueries - [HOLLYWOOD BURBANK AIRPORT,14152,73473,19.26149742082125]
[2025-10-07 19:47:22] INFO  SQLQueries - [LOS ANGELES INTERNATIONAL AIRPORT,90764,471376,19.25511693425206]
[2025-10-07 19:47:22] INFO  SQLQueries - [HECTOR INTERNATIONAL AIRPORT,3175,16549,19.18544927185933]
[2025-10-07 19:47:22] INFO  SQLQueries - [PORTLAND INTERNATIONAL JETPORT,5553,28959,19.17538589039677]
[2025-10-07 19:47:22] INFO  SQLQueries - [NANTUCKET MEMORIAL AIRPORT,750,3912,19.17177914110429]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHARLES M. SCHULZ SONOMA COUNTY AIRPORT,1918,10006,19.16849890065960]
[2025-10-07 19:47:22] INFO  SQLQueries - [ST. LOUIS LAMBERT INTERNATIONAL AIRPORT,30902,161278,19.16070387777626]
[2025-10-07 19:47:22] INFO  SQLQueries - [SACRAMENTO INTERNATIONAL AIRPORT,25763,134516,19.15236849148057]
[2025-10-07 19:47:22] INFO  SQLQueries - [BALTIMORE/WASHINGTON INTERNATIONAL THURGOOD MARSHALL AIRPORT,44661,233297,19.14340947376091]
[2025-10-07 19:47:22] INFO  SQLQueries - [MIDLAND INTERNATIONAL AIR AND SPACE PORT,4847,25354,19.11729904551550]
[2025-10-07 19:47:22] INFO  SQLQueries - [UNIVERSITY OF ILLINOIS WILLARD AIRPORT,719,3764,19.10201912858661]
[2025-10-07 19:47:22] INFO  SQLQueries - [MEADOWS FIELD,1261,6616,19.05985489721886]
[2025-10-07 19:47:22] INFO  SQLQueries - [SHREVEPORT REGIONAL AIRPORT,2703,14235,18.98840885142255]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHIPPEWA COUNTY INTERNATIONAL AIRPORT,336,1772,18.96162528216704]
[2025-10-07 19:47:22] INFO  SQLQueries - [CENTRAL WISCONSIN AIRPORT,742,3914,18.95758814512008]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHATTANOOGA METROPOLITAN AIRPORT (LOVELL FIELD),3694,19551,18.89417421103780]
[2025-10-07 19:47:22] INFO  SQLQueries - [LAFAYETTE REGIONAL AIRPORT,2157,11426,18.87799754944863]
[2025-10-07 19:47:22] INFO  SQLQueries - [PHOENIX SKY HARBOR INTERNATIONAL AIRPORT,86798,460878,18.83318361909225]
[2025-10-07 19:47:22] INFO  SQLQueries - [HUNTSVILLE INTERNATIONAL CARL T JONES FIELD,5360,28465,18.83014227999297]
[2025-10-07 19:47:22] INFO  SQLQueries - [ALPENA COUNTY REGIONAL AIRPORT,252,1340,18.80597014925373]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHICAGO MIDWAY INTERNATIONAL AIRPORT,36278,192937,18.80302896800510]
[2025-10-07 19:47:22] INFO  SQLQueries - [PELLSTON REGIONAL AIRPORT OF EMMET COUNTY AIRPORT,354,1883,18.79978757302177]
[2025-10-07 19:47:22] INFO  SQLQueries - [NORTH PLATTE REGIONAL AIRPORT LEE BIRD FIELD,295,1570,18.78980891719745]
[2025-10-07 19:47:22] INFO  SQLQueries - [SANTA BARBARA MUNICIPAL AIRPORT,3480,18526,18.78441109791644]
[2025-10-07 19:47:22] INFO  SQLQueries - [PALM SPRINGS INTERNATIONAL AIRPORT,6812,36275,18.77877325982081]
[2025-10-07 19:47:22] INFO  SQLQueries - [AUGUSTA REGIONAL AT BUSH FIELD,2266,12097,18.73191700421592]
[2025-10-07 19:47:22] INFO  SQLQueries - [STATE COLLEGE REGIONAL AIRPORT,1422,7594,18.72530945483276]
[2025-10-07 19:47:22] INFO  SQLQueries - [JOPLIN REGIONAL AIRPORT,289,1550,18.64516129032258]
[2025-10-07 19:47:22] INFO  SQLQueries - [WORCESTER REGIONAL AIRPORT,663,3557,18.63930278324431]
[2025-10-07 19:47:22] INFO  SQLQueries - [KEARNEY REGIONAL AIRPORT,68,365,18.63013698630137]
[2025-10-07 19:47:22] INFO  SQLQueries - [MONTEREY PENINSULA AIRPORT,2050,11025,18.59410430839002]
[2025-10-07 19:47:22] INFO  SQLQueries - [WILLISTON BASIN INTERNATIONAL AIRPORT,844,4541,18.58621449020040]
[2025-10-07 19:47:22] INFO  SQLQueries - [HATTIESBURG LAUREL REGIONAL AIRPORT,280,1508,18.56763925729443]
[2025-10-07 19:47:22] INFO  SQLQueries - [DURANGO LA PLATA COUNTY AIRPORT,1769,9566,18.49257787999164]
[2025-10-07 19:47:22] INFO  SQLQueries - [SAN FRANCISCO BAY OAKLAND INTERNATIONAL AIRPORT,19298,104376,18.48892465700927]
[2025-10-07 19:47:22] INFO  SQLQueries - [MOBILE REGIONAL AIRPORT,2312,12507,18.48564803709922]
[2025-10-07 19:47:22] INFO  SQLQueries - [BRUNSWICK GOLDEN ISLES AIRPORT,362,1960,18.46938775510204]
[2025-10-07 19:47:22] INFO  SQLQueries - [SPOKANE INTERNATIONAL AIRPORT,9276,50321,18.43365592893623]
[2025-10-07 19:47:22] INFO  SQLQueries - [DICKINSON THEODORE ROOSEVELT REGIONAL AIRPORT,293,1591,18.41609050911376]
[2025-10-07 19:47:22] INFO  SQLQueries - [RAPID CITY REGIONAL AIRPORT,2194,11914,18.41530971965755]
[2025-10-07 19:47:22] INFO  SQLQueries - [MONTGOMERY REGIONAL (DANNELLY FIELD) AIRPORT,1487,8079,18.40574328506003]
[2025-10-07 19:47:22] INFO  SQLQueries - [MASON CITY MUNICIPAL AIRPORT,277,1508,18.36870026525199]
[2025-10-07 19:47:22] INFO  SQLQueries - [WILMINGTON INTERNATIONAL AIRPORT,3973,21701,18.30791207778443]
[2025-10-07 19:47:22] INFO  SQLQueries - [ARNOLD PALMER REGIONAL AIRPORT,238,1300,18.30769230769231]
[2025-10-07 19:47:22] INFO  SQLQueries - [TYLER POUNDS REGIONAL AIRPORT,476,2604,18.27956989247312]
[2025-10-07 19:47:22] INFO  SQLQueries - [DULUTH INTERNATIONAL AIRPORT,965,5283,18.26613666477380]
[2025-10-07 19:47:22] INFO  SQLQueries - [GUNNISON CRESTED BUTTE REGIONAL AIRPORT,440,2411,18.24968892575695]
[2025-10-07 19:47:22] INFO  SQLQueries - [JACKSON-MEDGAR WILEY EVERS INTERNATIONAL AIRPORT,3962,21745,18.22028052425845]
[2025-10-07 19:47:22] INFO  SQLQueries - [TEXARKANA REGIONAL AIRPORT (WEBB FIELD),383,2106,18.18613485280152]
[2025-10-07 19:47:22] INFO  SQLQueries - [GRAND JUNCTION REGIONAL AIRPORT,1815,9983,18.18090754282280]
[2025-10-07 19:47:22] INFO  SQLQueries - [PIEDMONT TRIAD INTERNATIONAL AIRPORT,5894,32422,18.17901424958362]
[2025-10-07 19:47:22] INFO  SQLQueries - [FAIRBANKS INTERNATIONAL AIRPORT,2262,12465,18.14681107099880]
[2025-10-07 19:47:22] INFO  SQLQueries - [CORPUS CHRISTI INTERNATIONAL AIRPORT,2491,13733,18.13878977645088]
[2025-10-07 19:47:22] INFO  SQLQueries - [EAST TEXAS REGIONAL AIRPORT,318,1755,18.11965811965812]
[2025-10-07 19:47:22] INFO  SQLQueries - [DAYTONA BEACH INTERNATIONAL AIRPORT,1258,6960,18.07471264367816]
[2025-10-07 19:47:22] INFO  SQLQueries - [BETHEL AIRPORT,345,1911,18.05337519623234]
[2025-10-07 19:47:22] INFO  SQLQueries - [DANIEL K INOUYE INTERNATIONAL AIRPORT,26753,148320,18.03735167206041]
[2025-10-07 19:47:22] INFO  SQLQueries - [MAHLON SWEET FIELD,3728,20707,18.00357367073936]
[2025-10-07 19:47:22] INFO  SQLQueries - [SAN ANGELO REGIONAL MATHIS FIELD,478,2665,17.93621013133208]
[2025-10-07 19:47:22] INFO  SQLQueries - [WESTERN NEB. RGNL/WILLIAM B. HEILIG AIRPORT,267,1492,17.89544235924933]
[2025-10-07 19:47:22] INFO  SQLQueries - [ELMIRA CORNING REGIONAL AIRPORT,448,2504,17.89137380191693]
[2025-10-07 19:47:22] INFO  SQLQueries - [VALLEY INTERNATIONAL AIRPORT,2393,13379,17.88623962926975]
[2025-10-07 19:47:22] INFO  SQLQueries - [TALLAHASSEE REGIONAL AIRPORT,2734,15293,17.87746027594324]
[2025-10-07 19:47:22] INFO  SQLQueries - [BANGOR INTERNATIONAL AIRPORT,2147,12063,17.79822598027025]
[2025-10-07 19:47:22] INFO  SQLQueries - [NEW YORK STEWART INTERNATIONAL AIRPORT,207,1164,17.78350515463918]
[2025-10-07 19:47:22] INFO  SQLQueries - [EASTERWOOD FIELD,472,2660,17.74436090225564]
[2025-10-07 19:47:22] INFO  SQLQueries - [PORTLAND INTERNATIONAL AIRPORT,29666,167630,17.69730955079640]
[2025-10-07 19:47:22] INFO  SQLQueries - [SOUTHWEST WYOMING REGIONAL AIRPORT,240,1358,17.67304860088365]
[2025-10-07 19:47:22] INFO  SQLQueries - [MANHATTAN REGIONAL AIRPORT,604,3421,17.65565624086524]
[2025-10-07 19:47:22] INFO  SQLQueries - [SEATTLE–TACOMA INTERNATIONAL AIRPORT,77095,437141,17.63618603608447]
[2025-10-07 19:47:22] INFO  SQLQueries - [JOHN WAYNE ORANGE COUNTY INTERNATIONAL AIRPORT,19086,108387,17.60912286528827]
[2025-10-07 19:47:22] INFO  SQLQueries - [BOISE AIR TERMINAL/GOWEN FIELD,11226,64025,17.53377586880125]
[2025-10-07 19:47:22] INFO  SQLQueries - [CENTRAL NEBRASKA REGIONAL AIRPORT,404,2305,17.52711496746204]
[2025-10-07 19:47:22] INFO  SQLQueries - [CENTRAL ILLINOIS REGIONAL AIRPORT AT BLOOMINGTON-NORMAL,1068,6135,17.40831295843521]
[2025-10-07 19:47:22] INFO  SQLQueries - [MERLE K (MUDHOLE) SMITH AIRPORT,304,1750,17.37142857142857]
[2025-10-07 19:47:22] INFO  SQLQueries - [NORMAN Y. MINETA SAN JOSE INTERNATIONAL AIRPORT,21508,123915,17.35705927450268]
[2025-10-07 19:47:22] INFO  SQLQueries - [DETROIT METROPOLITAN WAYNE COUNTY AIRPORT,54673,315739,17.31588432217749]
[2025-10-07 19:47:22] INFO  SQLQueries - [ROSWELL AIR CENTER AIRPORT,392,2266,17.29920564872021]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHEYENNE REGIONAL JERRY OLSON FIELD,232,1345,17.24907063197026]
[2025-10-07 19:47:22] INFO  SQLQueries - [HARTSFIELD JACKSON ATLANTA INTERNATIONAL AIRPORT,141531,821161,17.23547513824938]
[2025-10-07 19:47:22] INFO  SQLQueries - [BELLINGHAM INTERNATIONAL AIRPORT,1101,6388,17.23544145272386]
[2025-10-07 19:47:22] INFO  SQLQueries - [CAPE COD GATEWAY AIRPORT,82,477,17.19077568134172]
[2025-10-07 19:47:22] INFO  SQLQueries - [MELBOURNE ORLANDO INTERNATIONAL AIRPORT,1163,6776,17.16351829988194]
[2025-10-07 19:47:22] INFO  SQLQueries - [BILLINGS LOGAN INTERNATIONAL AIRPORT,2086,12181,17.12503078564978]
[2025-10-07 19:47:22] INFO  SQLQueries - [GULFPORT BILOXI INTERNATIONAL AIRPORT,1702,9943,17.11757014985417]
[2025-10-07 19:47:22] INFO  SQLQueries - [BISMARCK MUNICIPAL AIRPORT,1597,9375,17.03466666666667]
[2025-10-07 19:47:22] INFO  SQLQueries - [LIBERAL MID-AMERICA REGIONAL AIRPORT,246,1447,17.00069108500346]
[2025-10-07 19:47:22] INFO  SQLQueries - [HILTON HEAD AIRPORT,745,4387,16.98199224982904]
[2025-10-07 19:47:22] INFO  SQLQueries - [SHERIDAN COUNTY AIRPORT,284,1673,16.97549312612074]
[2025-10-07 19:47:22] INFO  SQLQueries - [TRI-STATE AIRPORT / MILTON J. FERGUSON FIELD,523,3085,16.95299837925446]
[2025-10-07 19:47:22] INFO  SQLQueries - [MISSOULA INTERNATIONAL AIRPORT,2084,12305,16.93620479479886]
[2025-10-07 19:47:22] INFO  SQLQueries - [DODGE CITY REGIONAL AIRPORT,255,1509,16.89860834990060]
[2025-10-07 19:47:22] INFO  SQLQueries - [LONG BEACH AIRPORT (DAUGHERTY FIELD),6932,41277,16.79385614264603]
[2025-10-07 19:47:22] INFO  SQLQueries - [LAREDO INTERNATIONAL AIRPORT,1088,6521,16.68455758319276]
[2025-10-07 19:47:22] INFO  SQLQueries - [WASHINGTON DULLES INTERNATIONAL AIRPORT,32373,194324,16.65929066919166]
[2025-10-07 19:47:22] INFO  SQLQueries - [PLATTSBURGH INTERNATIONAL AIRPORT,199,1195,16.65271966527197]
[2025-10-07 19:47:22] INFO  SQLQueries - [REDDING MUNICIPAL AIRPORT,636,3836,16.57977059436913]
[2025-10-07 19:47:22] INFO  SQLQueries - [ERIE INTERNATIONAL TOM RIDGE FIELD,413,2491,16.57968687274187]
[2025-10-07 19:47:22] INFO  SQLQueries - [MINNEAPOLIS–SAINT PAUL INTERNATIONAL AIRPORT / WOLD–CHAMBERLAIN FIELD,50120,302493,16.56897845569980]
[2025-10-07 19:47:22] INFO  SQLQueries - [BROWNSVILLE SOUTH PADRE ISLAND INTERNATIONAL AIRPORT,1241,7530,16.48074369189907]
[2025-10-07 19:47:22] INFO  SQLQueries - [JUNEAU INTERNATIONAL AIRPORT,1831,11149,16.42299757825814]
[2025-10-07 19:47:22] INFO  SQLQueries - [CENTRAL WYOMING REGIONAL AIRPORT,223,1358,16.42120765832106]
[2025-10-07 19:47:22] INFO  SQLQueries - [COLUMBUS METROPOLITAN AIRPORT,427,2602,16.41045349730976]
[2025-10-07 19:47:22] INFO  SQLQueries - [LAWTON FORT SILL REGIONAL AIRPORT,436,2658,16.40331075996990]
[2025-10-07 19:47:22] INFO  SQLQueries - [WICHITA FALLS MUNICIPAL AIRPORT / SHEPPARD AIR FORCE BASE,287,1750,16.40000000000000]
[2025-10-07 19:47:22] INFO  SQLQueries - [GLACIER PARK INTERNATIONAL AIRPORT,1856,11347,16.35674627654887]
[2025-10-07 19:47:22] INFO  SQLQueries - [FORT SMITH REGIONAL AIRPORT,445,2722,16.34827332843497]
[2025-10-07 19:47:22] INFO  SQLQueries - [NOME AIRPORT,286,1750,16.34285714285714]
[2025-10-07 19:47:22] INFO  SQLQueries - [LAKE CHARLES REGIONAL AIRPORT,759,4655,16.30504833512352]
[2025-10-07 19:47:22] INFO  SQLQueries - [KING SALMON AIRPORT,184,1129,16.29760850310009]
[2025-10-07 19:47:22] INFO  SQLQueries - [FORD AIRPORT,286,1756,16.28701594533030]
[2025-10-07 19:47:22] INFO  SQLQueries - [OWENSBORO DAVIESS COUNTY AIRPORT,7,43,16.27906976744186]
[2025-10-07 19:47:22] INFO  SQLQueries - [SOUTHWEST GEORGIA REGIONAL AIRPORT,325,2002,16.23376623376623]
[2025-10-07 19:47:22] INFO  SQLQueries - [GAINESVILLE REGIONAL AIRPORT,1558,9613,16.20721939040882]
[2025-10-07 19:47:22] INFO  SQLQueries - [TRI CITIES AIRPORT,2391,14828,16.12489884003237]
[2025-10-07 19:47:22] INFO  SQLQueries - [GREATER BINGHAMTON/EDWIN A LINK FIELD,189,1176,16.07142857142857]
[2025-10-07 19:47:22] INFO  SQLQueries - [NORTHEAST WYOMING REGIONAL AIRPORT,269,1675,16.05970149253731]
[2025-10-07 19:47:22] INFO  SQLQueries - [WRANGELL AIRPORT,281,1750,16.05714285714286]
[2025-10-07 19:47:22] INFO  SQLQueries - [KETCHIKAN INTERNATIONAL AIRPORT,949,5923,16.02228600371433]
[2025-10-07 19:47:22] INFO  SQLQueries - [MINOT INTERNATIONAL AIRPORT,919,5752,15.97705146036161]
[2025-10-07 19:47:22] INFO  SQLQueries - [IDAHO FALLS REGIONAL AIRPORT,1555,9743,15.96017653700092]
[2025-10-07 19:47:22] INFO  SQLQueries - [VERNAL REGIONAL AIRPORT,107,675,15.85185185185185]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHARLOTTESVILLE ALBEMARLE AIRPORT,2490,15731,15.82861865107113]
[2025-10-07 19:47:22] INFO  SQLQueries - [ELLISON ONIZUKA KONA INTERNATIONAL AIRPORT AT KEAHOLE,6324,40237,15.71687750080771]
[2025-10-07 19:47:22] INFO  SQLQueries - [YAKUTAT AIRPORT,275,1750,15.71428571428571]
[2025-10-07 19:47:22] INFO  SQLQueries - [MONROE REGIONAL AIRPORT,742,4726,15.70038087177317]
[2025-10-07 19:47:22] INFO  SQLQueries - [FAYETTEVILLE REGIONAL AIRPORT - GRANNIS FIELD,1181,7528,15.68809776833156]
[2025-10-07 19:47:22] INFO  SQLQueries - [ROBERTS FIELD,2874,18327,15.68178097888361]
[2025-10-07 19:47:22] INFO  SQLQueries - [EVANSVILLE REGIONAL AIRPORT,1255,8010,15.66791510611735]
[2025-10-07 19:47:22] INFO  SQLQueries - [CANYONLANDS REGIONAL AIRPORT,104,668,15.56886227544910]
[2025-10-07 19:47:22] INFO  SQLQueries - [ALEXANDRIA INTERNATIONAL AIRPORT,721,4663,15.46214883122453]
[2025-10-07 19:47:22] INFO  SQLQueries - [JACK BROOKS REGIONAL AIRPORT,271,1759,15.40648095508812]
[2025-10-07 19:47:22] INFO  SQLQueries - [PETERSBURG JAMES A JOHNSON AIRPORT,269,1750,15.37142857142857]
[2025-10-07 19:47:22] INFO  SQLQueries - [DOTHAN REGIONAL AIRPORT,294,1919,15.32047941636269]
[2025-10-07 19:47:22] INFO  SQLQueries - [ROGUE VALLEY INTERNATIONAL MEDFORD AIRPORT,2389,15714,15.20300369097620]
[2025-10-07 19:47:22] INFO  SQLQueries - [VICTORIA REGIONAL AIRPORT,232,1530,15.16339869281046]
[2025-10-07 19:47:22] INFO  SQLQueries - [LIHUE AIRPORT,5842,38568,15.14727235013483]
[2025-10-07 19:47:22] INFO  SQLQueries - [SALT LAKE CITY INTERNATIONAL AIRPORT,40985,270935,15.12724454204883]
[2025-10-07 19:47:22] INFO  SQLQueries - [ALBERT J ELLIS AIRPORT,986,6548,15.05803298717166]
[2025-10-07 19:47:22] INFO  SQLQueries - [RALPH WIEN MEMORIAL AIRPORT,263,1748,15.04576659038902]
[2025-10-07 19:47:22] INFO  SQLQueries - [CHICAGO ROCKFORD INTERNATIONAL AIRPORT,293,1950,15.02564102564103]
[2025-10-07 19:47:22] INFO  SQLQueries - [RHINELANDER ONEIDA COUNTY AIRPORT,278,1864,14.91416309012876]
[2025-10-07 19:47:22] INFO  SQLQueries - [TRI-CITIES REGIONAL TN/VA AIRPORT,1496,10131,14.76655808903366]
[2025-10-07 19:47:22] INFO  SQLQueries - [BEMIDJI REGIONAL AIRPORT,256,1743,14.68732071141710]
[2025-10-07 19:47:22] INFO  SQLQueries - [VALDOSTA REGIONAL AIRPORT,297,2023,14.68116658428077]
[2025-10-07 19:47:22] INFO  SQLQueries - [KAHULUI INTERNATIONAL AIRPORT,9872,67289,14.67104578757301]
[2025-10-07 19:47:22] INFO  SQLQueries - [KODIAK AIRPORT,282,1923,14.66458658346334]
[2025-10-07 19:47:22] INFO  SQLQueries - [FLAGSTAFF PULLIAM INTERNATIONAL AIRPORT,622,4263,14.59066385174760]
[2025-10-07 19:47:22] INFO  SQLQueries - [GRAND FORKS INTERNATIONAL AIRPORT,457,3139,14.55877668047149]
[2025-10-07 19:47:22] INFO  SQLQueries - [YUMA INTERNATIONAL AIRPORT / MARINE CORPS AIR STATION YUMA,612,4215,14.51957295373665]
[2025-10-07 19:47:22] INFO  SQLQueries - [HILO INTERNATIONAL AIRPORT,2427,16763,14.47831533735012]
[2025-10-07 19:47:22] INFO  SQLQueries - [FALLS INTERNATIONAL AIRPORT,222,1535,14.46254071661238]
[2025-10-07 19:47:22] INFO  SQLQueries - [DILLINGHAM AIRPORT,160,1107,14.45347786811201]
[2025-10-07 19:47:22] INFO  SQLQueries - [ST GEORGE REGIONAL AIRPORT,1068,7450,14.33557046979866]
[2025-10-07 19:47:22] INFO  SQLQueries - [NIAGARA FALLS INTERNATIONAL AIRPORT,136,950,14.31578947368421]
[2025-10-07 19:47:22] INFO  SQLQueries - [SALISBURY OCEAN CITY WICOMICO REGIONAL AIRPORT,578,4050,14.27160493827160]
[2025-10-07 19:47:22] INFO  SQLQueries - [PORTSMOUTH INTERNATIONAL AT PEASE AIRPORT,136,967,14.06411582213030]
[2025-10-07 19:47:22] INFO  SQLQueries - [BRAINERD LAKES REGIONAL AIRPORT,215,1531,14.04310907903331]
[2025-10-07 19:47:22] INFO  SQLQueries - [STILLWATER REGIONAL AIRPORT,244,1757,13.88730791121229]
[2025-10-07 19:47:22] INFO  SQLQueries - [COASTAL CAROLINA REGIONAL AIRPORT,590,4343,13.58507943817638]
[2025-10-07 19:47:22] INFO  SQLQueries - [NEWPORT NEWS WILLIAMSBURG INTERNATIONAL AIRPORT,502,3699,13.57123546904569]
[2025-10-07 19:47:22] INFO  SQLQueries - [ABERDEEN REGIONAL AIRPORT,233,1754,13.28392246294185]
[2025-10-07 19:47:22] INFO  SQLQueries - [LYNCHBURG REGIONAL AIRPORT - PRESTON GLENN FIELD,560,4262,13.13937118723604]
[2025-10-07 19:47:22] INFO  SQLQueries - [GREAT FALLS INTERNATIONAL AIRPORT,857,6534,13.11600857055403]
[2025-10-07 19:47:22] INFO  SQLQueries - [WALLA WALLA REGIONAL AIRPORT,197,1507,13.07232913072329]
[2025-10-07 19:47:22] INFO  SQLQueries - [DELTA COUNTY AIRPORT,209,1606,13.01369863013699]
[2025-10-07 19:47:22] INFO  SQLQueries - [RANGE REGIONAL AIRPORT,206,1591,12.94783155248272]
[2025-10-07 19:47:22] INFO  SQLQueries - [PITT-GREENVILLE AIRPORT,294,2275,12.92307692307692]
[2025-10-07 19:47:22] INFO  SQLQueries - [PULLMAN-MOSCOW REGIONAL AIRPORT,332,2578,12.87820015515904]
[2025-10-07 19:47:22] INFO  SQLQueries - [JAMESTOWN REGIONAL AIRPORT,200,1570,12.73885350318471]
[2025-10-07 19:47:22] INFO  SQLQueries - [DEVILS LAKE REGIONAL AIRPORT,205,1633,12.55358236374770]
[2025-10-07 19:47:22] INFO  SQLQueries - [LEWISTON NEZ PERCE COUNTY AIRPORT,277,2246,12.33303650934996]
[2025-10-07 19:47:22] INFO  SQLQueries - [FLORENCE REGIONAL AIRPORT,237,1967,12.04880528723945]
[2025-10-07 19:47:22] INFO  SQLQueries - [HELENA REGIONAL AIRPORT,525,4369,12.01647974364843]
[2025-10-07 19:47:22] INFO  SQLQueries - [GUAM, TT: GUAM INTERNATIONAL,215,1793,11.99107640825432]
[2025-10-07 19:47:22] INFO  SQLQueries - [GOLDEN TRIANGLE REGIONAL AIRPORT,223,1863,11.96994095544820]
[2025-10-07 19:47:22] INFO  SQLQueries - [FRIEDMAN MEMORIAL AIRPORT,660,5517,11.96302338227297]
[2025-10-07 19:47:22] INFO  SQLQueries - [WATERTOWN INTERNATIONAL AIRPORT,199,1665,11.95195195195195]
[2025-10-07 19:47:22] INFO  SQLQueries - [DEADHORSE AIRPORT,144,1221,11.79361179361179]
[2025-10-07 19:47:22] INFO  SQLQueries - [YAKIMA AIR TERMINAL MCALLISTER FIELD,169,1443,11.71171171171171]
[2025-10-07 19:47:22] INFO  SQLQueries - [PANGBORN MEMORIAL AIRPORT,169,1506,11.22177954847278]
[2025-10-07 19:47:22] INFO  SQLQueries - [PUEBLO MEMORIAL AIRPORT,3,27,11.11111111111111]
[2025-10-07 19:47:22] INFO  SQLQueries - [YELLOWSTONE AIRPORT,71,651,10.90629800307220]
[2025-10-07 19:47:22] INFO  SQLQueries - [DEL RIO INTERNATIONAL AIRPORT,20,184,10.86956521739130]
[2025-10-07 19:47:22] INFO  SQLQueries - [CEDAR CITY REGIONAL AIRPORT,158,1509,10.47051027170311]
[2025-10-07 19:47:22] INFO  SQLQueries - [BERT MOONEY AIRPORT,170,1648,10.31553398058252]
[2025-10-07 19:47:22] INFO  SQLQueries - [MCCLELLAN-PALOMAR AIRPORT,21,216,9.72222222222222]
[2025-10-07 19:47:22] INFO  SQLQueries - [GUSTAVUS AIRPORT,16,165,9.69696969696970]
[2025-10-07 19:47:22] INFO  SQLQueries - [ADAK AIRPORT,24,252,9.52380952380952]
[2025-10-07 19:47:22] INFO  SQLQueries - [ELKO REGIONAL AIRPORT,73,899,8.12013348164627]
[2025-10-07 19:47:22] INFO  SQLQueries - [JOSLIN FIELD MAGIC VALLEY REGIONAL AIRPORT,115,1490,7.71812080536913]
[2025-10-07 19:47:22] INFO  SQLQueries - [POCATELLO REGIONAL AIRPORT,101,1484,6.80592991913747]
[2025-10-07 19:47:22] INFO  SQLQueries - [SAINT CLOUD REGIONAL AIRPORT,24,384,6.25000000000000]
[2025-10-07 19:47:22] INFO  SQLQueries - [SAIPAN, TT: FRANCISCO C. ADA SAIPAN INTERNATIONAL,33,911,3.62239297475302]
[2025-10-07 19:47:22] INFO  SQLQueries - Task 6.4 - Monthly performance for airline 'AA'
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 5.6261 ms
[2025-10-07 19:47:22] INFO  DAGScheduler - Registering RDD 51 (collectAsList at SQLQueries.java:160) as input to shuffle 9
[2025-10-07 19:47:22] INFO  DAGScheduler - Got map stage job 15 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:22] INFO  DAGScheduler - Final stage: ShuffleMapStage 37 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:22] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:22] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:22] INFO  DAGScheduler - Submitting ShuffleMapStage 37 (MapPartitionsRDD[51] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:22] INFO  MemoryStore - Block broadcast_16 stored as values in memory (estimated size 15.6 KiB, free 2.2 GiB)
[2025-10-07 19:47:22] INFO  MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 2.2 GiB)
[2025-10-07 19:47:22] INFO  BlockManagerInfo - Added broadcast_16_piece0 in memory on DESKTOP-618L1DH:62628 (size: 7.8 KiB, free: 2.2 GiB)
[2025-10-07 19:47:22] INFO  SparkContext - Created broadcast 16 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 11.977 ms
[2025-10-07 19:47:22] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[51] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:22] INFO  TaskSchedulerImpl - Adding task set 37.0 with 1 tasks resource profile 0
[2025-10-07 19:47:22] INFO  TaskSetManager - Starting task 0.0 in stage 37.0 (TID 15) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:22] INFO  Executor - Running task 0.0 in stage 37.0 (TID 15)
[2025-10-07 19:47:22] INFO  DAGScheduler - Registering RDD 53 (collectAsList at SQLQueries.java:160) as input to shuffle 10
[2025-10-07 19:47:22] INFO  DAGScheduler - Got map stage job 16 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:22] INFO  DAGScheduler - Final stage: ShuffleMapStage 38 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:22] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:22] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:22] INFO  DAGScheduler - Submitting ShuffleMapStage 38 (MapPartitionsRDD[53] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:22] INFO  MemoryStore - Block broadcast_17 stored as values in memory (estimated size 14.4 KiB, free 2.2 GiB)
[2025-10-07 19:47:22] INFO  MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 2.2 GiB)
[2025-10-07 19:47:22] INFO  BlockManagerInfo - Added broadcast_17_piece0 in memory on DESKTOP-618L1DH:62628 (size: 7.5 KiB, free: 2.2 GiB)
[2025-10-07 19:47:22] INFO  SparkContext - Created broadcast 17 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:22] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[53] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:22] INFO  TaskSchedulerImpl - Adding task set 38.0 with 1 tasks resource profile 0
[2025-10-07 19:47:22] INFO  TaskSetManager - Starting task 0.0 in stage 38.0 (TID 16) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:22] INFO  Executor - Running task 0.0 in stage 38.0 (TID 16)
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 6.0976 ms
[2025-10-07 19:47:22] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:22] INFO  Executor - Finished task 0.0 in stage 38.0 (TID 16). 1906 bytes result sent to driver
[2025-10-07 19:47:22] INFO  TaskSetManager - Finished task 0.0 in stage 38.0 (TID 16) in 66 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:22] INFO  TaskSchedulerImpl - Removed TaskSet 38.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:22] INFO  DAGScheduler - ShuffleMapStage 38 (collectAsList at SQLQueries.java:160) finished in 0.079 s
[2025-10-07 19:47:22] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:22] INFO  DAGScheduler - running: Set(ShuffleMapStage 37)
[2025-10-07 19:47:22] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:22] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 7.7686 ms
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 10.1783 ms
[2025-10-07 19:47:22] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:22] INFO  Executor - Finished task 0.0 in stage 37.0 (TID 15). 1906 bytes result sent to driver
[2025-10-07 19:47:22] INFO  TaskSetManager - Finished task 0.0 in stage 37.0 (TID 15) in 191 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:22] INFO  TaskSchedulerImpl - Removed TaskSet 37.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:22] INFO  DAGScheduler - ShuffleMapStage 37 (collectAsList at SQLQueries.java:160) finished in 0.207 s
[2025-10-07 19:47:22] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:22] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:22] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:22] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:22] INFO  ShufflePartitionsUtil - For shuffle(9, 10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 30.913 ms
[2025-10-07 19:47:22] INFO  DAGScheduler - Registering RDD 60 (collectAsList at SQLQueries.java:160) as input to shuffle 11
[2025-10-07 19:47:22] INFO  DAGScheduler - Got map stage job 17 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:22] INFO  DAGScheduler - Final stage: ShuffleMapStage 41 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:22] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 39, ShuffleMapStage 40)
[2025-10-07 19:47:22] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:22] INFO  DAGScheduler - Submitting ShuffleMapStage 41 (MapPartitionsRDD[60] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:22] INFO  MemoryStore - Block broadcast_18 stored as values in memory (estimated size 63.7 KiB, free 2.2 GiB)
[2025-10-07 19:47:22] INFO  MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 2.2 GiB)
[2025-10-07 19:47:22] INFO  BlockManagerInfo - Added broadcast_18_piece0 in memory on DESKTOP-618L1DH:62628 (size: 27.9 KiB, free: 2.2 GiB)
[2025-10-07 19:47:22] INFO  SparkContext - Created broadcast 18 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:22] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[60] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:22] INFO  TaskSchedulerImpl - Adding task set 41.0 with 1 tasks resource profile 0
[2025-10-07 19:47:22] INFO  TaskSetManager - Starting task 0.0 in stage 41.0 (TID 17) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9270 bytes) 
[2025-10-07 19:47:22] INFO  Executor - Running task 0.0 in stage 41.0 (TID 17)
[2025-10-07 19:47:22] INFO  ShuffleBlockFetcherIterator - Getting 1 (829.4 KiB) non-empty blocks including 1 (829.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:22] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 6.3864 ms
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 6.7611 ms
[2025-10-07 19:47:22] INFO  ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:22] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 28.9839 ms
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 8.523 ms
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 5.9712 ms
[2025-10-07 19:47:22] INFO  Executor - Finished task 0.0 in stage 41.0 (TID 17). 6771 bytes result sent to driver
[2025-10-07 19:47:22] INFO  TaskSetManager - Finished task 0.0 in stage 41.0 (TID 17) in 283 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:22] INFO  TaskSchedulerImpl - Removed TaskSet 41.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:22] INFO  DAGScheduler - ShuffleMapStage 41 (collectAsList at SQLQueries.java:160) finished in 0.293 s
[2025-10-07 19:47:22] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:22] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:22] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:22] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:22] INFO  ShufflePartitionsUtil - For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:22] INFO  HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 33.6785 ms
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 6.8933 ms
[2025-10-07 19:47:22] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:22] INFO  DAGScheduler - Got job 18 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:22] INFO  DAGScheduler - Final stage: ResultStage 45 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:22] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 44)
[2025-10-07 19:47:22] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:22] INFO  DAGScheduler - Submitting ResultStage 45 (MapPartitionsRDD[65] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:22] INFO  MemoryStore - Block broadcast_19 stored as values in memory (estimated size 61.4 KiB, free 2.2 GiB)
[2025-10-07 19:47:22] INFO  MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 26.8 KiB, free 2.2 GiB)
[2025-10-07 19:47:22] INFO  BlockManagerInfo - Added broadcast_19_piece0 in memory on DESKTOP-618L1DH:62628 (size: 26.8 KiB, free: 2.2 GiB)
[2025-10-07 19:47:22] INFO  SparkContext - Created broadcast 19 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:22] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[65] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:22] INFO  TaskSchedulerImpl - Adding task set 45.0 with 1 tasks resource profile 0
[2025-10-07 19:47:22] INFO  TaskSetManager - Starting task 0.0 in stage 45.0 (TID 18) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:22] INFO  Executor - Running task 0.0 in stage 45.0 (TID 18)
[2025-10-07 19:47:22] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.0 KiB) non-empty blocks including 1 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:22] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-07 19:47:22] INFO  CodeGenerator - Code generated in 16.1888 ms
[2025-10-07 19:47:22] INFO  Executor - Finished task 0.0 in stage 45.0 (TID 18). 9350 bytes result sent to driver
[2025-10-07 19:47:22] INFO  TaskSetManager - Finished task 0.0 in stage 45.0 (TID 18) in 38 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:22] INFO  TaskSchedulerImpl - Removed TaskSet 45.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:22] INFO  DAGScheduler - ResultStage 45 (collectAsList at SQLQueries.java:160) finished in 0.053 s
[2025-10-07 19:47:22] INFO  DAGScheduler - Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:22] INFO  TaskSchedulerImpl - Killing all running tasks in stage 45: Stage finished
[2025-10-07 19:47:22] INFO  DAGScheduler - Job 18 finished: collectAsList at SQLQueries.java:160, took 0.058772 s
[2025-10-07 19:47:22] INFO  DAGScheduler - Registering RDD 66 (collectAsList at SQLQueries.java:160) as input to shuffle 12
[2025-10-07 19:47:22] INFO  DAGScheduler - Got map stage job 19 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:22] INFO  DAGScheduler - Final stage: ShuffleMapStage 49 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:22] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 48)
[2025-10-07 19:47:22] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:22] INFO  DAGScheduler - Submitting ShuffleMapStage 49 (MapPartitionsRDD[66] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:22] INFO  MemoryStore - Block broadcast_20 stored as values in memory (estimated size 62.9 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Added broadcast_20_piece0 in memory on DESKTOP-618L1DH:62628 (size: 27.1 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  SparkContext - Created broadcast 20 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[66] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Adding task set 49.0 with 1 tasks resource profile 0
[2025-10-07 19:47:23] INFO  TaskSetManager - Starting task 0.0 in stage 49.0 (TID 19) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-07 19:47:23] INFO  Executor - Running task 0.0 in stage 49.0 (TID 19)
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 4.4396 ms
[2025-10-07 19:47:23] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.0 KiB) non-empty blocks including 1 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:23] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-07 19:47:23] INFO  Executor - Finished task 0.0 in stage 49.0 (TID 19). 8264 bytes result sent to driver
[2025-10-07 19:47:23] INFO  TaskSetManager - Finished task 0.0 in stage 49.0 (TID 19) in 95 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Removed TaskSet 49.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:23] INFO  DAGScheduler - ShuffleMapStage 49 (collectAsList at SQLQueries.java:160) finished in 0.108 s
[2025-10-07 19:47:23] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:23] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:23] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:23] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:23] INFO  ShufflePartitionsUtil - For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:23] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:23] INFO  DAGScheduler - Got job 20 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:23] INFO  DAGScheduler - Final stage: ResultStage 54 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:23] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 53)
[2025-10-07 19:47:23] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting ResultStage 54 (MapPartitionsRDD[69] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_21 stored as values in memory (estimated size 54.4 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 24.5 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Added broadcast_21_piece0 in memory on DESKTOP-618L1DH:62628 (size: 24.5 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  SparkContext - Created broadcast 21 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[69] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Adding task set 54.0 with 1 tasks resource profile 0
[2025-10-07 19:47:23] INFO  TaskSetManager - Starting task 0.0 in stage 54.0 (TID 20) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:23] INFO  Executor - Running task 0.0 in stage 54.0 (TID 20)
[2025-10-07 19:47:23] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.7 KiB) non-empty blocks including 1 (2.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:23] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-07 19:47:23] INFO  Executor - Finished task 0.0 in stage 54.0 (TID 20). 10395 bytes result sent to driver
[2025-10-07 19:47:23] INFO  TaskSetManager - Finished task 0.0 in stage 54.0 (TID 20) in 11 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Removed TaskSet 54.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:23] INFO  DAGScheduler - ResultStage 54 (collectAsList at SQLQueries.java:160) finished in 0.021 s
[2025-10-07 19:47:23] INFO  DAGScheduler - Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Killing all running tasks in stage 54: Stage finished
[2025-10-07 19:47:23] INFO  DAGScheduler - Job 20 finished: collectAsList at SQLQueries.java:160, took 0.025544 s
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 4.4821 ms
[2025-10-07 19:47:23] INFO  SQLQueries - [2023,1,16691,74999,22.25496339951199]
[2025-10-07 19:47:23] INFO  SQLQueries - [2023,2,15124,71289,21.21505421593794]
[2025-10-07 19:47:23] INFO  SQLQueries - [2023,3,20810,78705,26.44050568578870]
[2025-10-07 19:47:23] INFO  SQLQueries - [2023,4,19385,77039,25.16257999195213]
[2025-10-07 19:47:23] INFO  SQLQueries - [2023,5,16502,79782,20.68386352811411]
[2025-10-07 19:47:23] INFO  SQLQueries - [2023,6,24149,80416,30.03009351372861]
[2025-10-07 19:47:23] INFO  SQLQueries - [2023,7,25955,83013,31.26618722368786]
[2025-10-07 19:47:23] INFO  SQLQueries - [2023,8,21278,85157,24.98678910717851]
[2025-10-07 19:47:23] INFO  SQLQueries - [2023,9,15570,76972,20.22813490619966]
[2025-10-07 19:47:23] INFO  SQLQueries - [2023,10,13521,81344,16.62200039339103]
[2025-10-07 19:47:23] INFO  SQLQueries - [2023,11,11533,76407,15.09416676482521]
[2025-10-07 19:47:23] INFO  SQLQueries - [2023,12,13332,75408,17.67982176957352]
[2025-10-07 19:47:23] INFO  SQLQueries - [2024,1,22292,77346,28.82114136477646]
[2025-10-07 19:47:23] INFO  SQLQueries - [2024,2,13964,74870,18.65099505810071]
[2025-10-07 19:47:23] INFO  SQLQueries - [2024,3,21978,82259,26.71804908885350]
[2025-10-07 19:47:23] INFO  SQLQueries - [2024,4,19380,81216,23.86229314420804]
[2025-10-07 19:47:23] INFO  SQLQueries - [2024,5,30736,86765,35.42442229009393]
[2025-10-07 19:47:23] INFO  SQLQueries - [2024,6,26802,85581,31.31769902197918]
[2025-10-07 19:47:23] INFO  SQLQueries - [2024,7,32526,88291,36.83954196917013]
[2025-10-07 19:47:23] INFO  SQLQueries - [2024,8,25825,85963,30.04199481172132]
[2025-10-07 19:47:23] INFO  SQLQueries - [2024,9,15485,80709,19.18621219442689]
[2025-10-07 19:47:23] INFO  SQLQueries - [2024,10,13578,86812,15.64069483481546]
[2025-10-07 19:47:23] INFO  SQLQueries - [2024,11,12529,76757,16.32294123011582]
[2025-10-07 19:47:23] INFO  SQLQueries - [2024,12,17390,77737,22.37029985721085]
[2025-10-07 19:47:23] INFO  SQLQueries - [2025,1,13860,75088,18.45834221180482]
[2025-10-07 19:47:23] INFO  SQLQueries - [2025,2,14135,69876,20.22869082374492]
[2025-10-07 19:47:23] INFO  SQLQueries - [2025,3,18743,82536,22.70887854996608]
[2025-10-07 19:47:23] INFO  SQLQueries - [2025,4,19766,82261,24.02839741797450]
[2025-10-07 19:47:23] INFO  SQLQueries - [2025,5,22398,86123,26.00699000267060]
[2025-10-07 19:47:23] INFO  SQLQueries - Task 7.1 - Total delay by cause
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 11.5358 ms
[2025-10-07 19:47:23] INFO  DAGScheduler - Registering RDD 72 (collectAsList at SQLQueries.java:160) as input to shuffle 13
[2025-10-07 19:47:23] INFO  DAGScheduler - Got map stage job 21 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:23] INFO  DAGScheduler - Final stage: ShuffleMapStage 55 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:23] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:23] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting ShuffleMapStage 55 (MapPartitionsRDD[72] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_22 stored as values in memory (estimated size 23.6 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Added broadcast_22_piece0 in memory on DESKTOP-618L1DH:62628 (size: 9.9 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  SparkContext - Created broadcast 22 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[72] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Adding task set 55.0 with 1 tasks resource profile 0
[2025-10-07 19:47:23] INFO  TaskSetManager - Starting task 0.0 in stage 55.0 (TID 21) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:23] INFO  Executor - Running task 0.0 in stage 55.0 (TID 21)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Removed broadcast_20_piece0 on DESKTOP-618L1DH:62628 in memory (size: 27.1 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Removed broadcast_19_piece0 on DESKTOP-618L1DH:62628 in memory (size: 26.8 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Removed broadcast_21_piece0 on DESKTOP-618L1DH:62628 in memory (size: 24.5 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Removed broadcast_16_piece0 on DESKTOP-618L1DH:62628 in memory (size: 7.8 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Removed broadcast_17_piece0 on DESKTOP-618L1DH:62628 in memory (size: 7.5 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Removed broadcast_15_piece0 on DESKTOP-618L1DH:62628 in memory (size: 24.8 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 15.0725 ms
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Removed broadcast_18_piece0 on DESKTOP-618L1DH:62628 in memory (size: 27.9 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:23] INFO  Executor - Finished task 0.0 in stage 55.0 (TID 21). 1888 bytes result sent to driver
[2025-10-07 19:47:23] INFO  TaskSetManager - Finished task 0.0 in stage 55.0 (TID 21) in 148 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Removed TaskSet 55.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:23] INFO  DAGScheduler - ShuffleMapStage 55 (collectAsList at SQLQueries.java:160) finished in 0.159 s
[2025-10-07 19:47:23] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:23] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:23] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:23] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 11.5859 ms
[2025-10-07 19:47:23] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:23] INFO  DAGScheduler - Got job 22 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:23] INFO  DAGScheduler - Final stage: ResultStage 57 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:23] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 56)
[2025-10-07 19:47:23] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting ResultStage 57 (MapPartitionsRDD[75] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_23 stored as values in memory (estimated size 20.5 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Added broadcast_23_piece0 in memory on DESKTOP-618L1DH:62628 (size: 7.9 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  SparkContext - Created broadcast 23 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[75] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Adding task set 57.0 with 1 tasks resource profile 0
[2025-10-07 19:47:23] INFO  TaskSetManager - Starting task 0.0 in stage 57.0 (TID 22) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:23] INFO  Executor - Running task 0.0 in stage 57.0 (TID 22)
[2025-10-07 19:47:23] INFO  ShuffleBlockFetcherIterator - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:23] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 13.8564 ms
[2025-10-07 19:47:23] INFO  Executor - Finished task 0.0 in stage 57.0 (TID 22). 4019 bytes result sent to driver
[2025-10-07 19:47:23] INFO  TaskSetManager - Finished task 0.0 in stage 57.0 (TID 22) in 27 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Removed TaskSet 57.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:23] INFO  DAGScheduler - ResultStage 57 (collectAsList at SQLQueries.java:160) finished in 0.032 s
[2025-10-07 19:47:23] INFO  DAGScheduler - Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Killing all running tasks in stage 57: Stage finished
[2025-10-07 19:47:23] INFO  DAGScheduler - Job 22 finished: collectAsList at SQLQueries.java:160, took 0.040164 s
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 7.3626 ms
[2025-10-07 19:47:23] INFO  SQLQueries - [1169147,134101,989776,9602,1325689]
[2025-10-07 19:47:23] INFO  SQLQueries - Task 7.2 - Total delay by minutes
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 10.7327 ms
[2025-10-07 19:47:23] INFO  DAGScheduler - Registering RDD 78 (collectAsList at SQLQueries.java:160) as input to shuffle 14
[2025-10-07 19:47:23] INFO  DAGScheduler - Got map stage job 23 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:23] INFO  DAGScheduler - Final stage: ShuffleMapStage 58 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:23] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:23] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting ShuffleMapStage 58 (MapPartitionsRDD[78] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_24 stored as values in memory (estimated size 23.0 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_24_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Added broadcast_24_piece0 in memory on DESKTOP-618L1DH:62628 (size: 9.6 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  SparkContext - Created broadcast 24 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[78] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Adding task set 58.0 with 1 tasks resource profile 0
[2025-10-07 19:47:23] INFO  TaskSetManager - Starting task 0.0 in stage 58.0 (TID 23) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:23] INFO  Executor - Running task 0.0 in stage 58.0 (TID 23)
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 8.1838 ms
[2025-10-07 19:47:23] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:23] INFO  Executor - Finished task 0.0 in stage 58.0 (TID 23). 1845 bytes result sent to driver
[2025-10-07 19:47:23] INFO  TaskSetManager - Finished task 0.0 in stage 58.0 (TID 23) in 177 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Removed TaskSet 58.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:23] INFO  DAGScheduler - ShuffleMapStage 58 (collectAsList at SQLQueries.java:160) finished in 0.182 s
[2025-10-07 19:47:23] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:23] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:23] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:23] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 8.248 ms
[2025-10-07 19:47:23] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:23] INFO  DAGScheduler - Got job 24 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:23] INFO  DAGScheduler - Final stage: ResultStage 60 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:23] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 59)
[2025-10-07 19:47:23] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting ResultStage 60 (MapPartitionsRDD[81] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_25 stored as values in memory (estimated size 20.6 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_25_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Added broadcast_25_piece0 in memory on DESKTOP-618L1DH:62628 (size: 7.9 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  SparkContext - Created broadcast 25 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[81] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Adding task set 60.0 with 1 tasks resource profile 0
[2025-10-07 19:47:23] INFO  TaskSetManager - Starting task 0.0 in stage 60.0 (TID 24) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:23] INFO  Executor - Running task 0.0 in stage 60.0 (TID 24)
[2025-10-07 19:47:23] INFO  ShuffleBlockFetcherIterator - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:23] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 6.1681 ms
[2025-10-07 19:47:23] INFO  Executor - Finished task 0.0 in stage 60.0 (TID 24). 3934 bytes result sent to driver
[2025-10-07 19:47:23] INFO  TaskSetManager - Finished task 0.0 in stage 60.0 (TID 24) in 21 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Removed TaskSet 60.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:23] INFO  DAGScheduler - ResultStage 60 (collectAsList at SQLQueries.java:160) finished in 0.030 s
[2025-10-07 19:47:23] INFO  DAGScheduler - Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Killing all running tasks in stage 60: Stage finished
[2025-10-07 19:47:23] INFO  DAGScheduler - Job 24 finished: collectAsList at SQLQueries.java:160, took 0.030660 s
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 7.9857 ms
[2025-10-07 19:47:23] INFO  SQLQueries - [8.9264373E7,1.5427864E7,4.9141353E7,451262.0,1.0410157E8]
[2025-10-07 19:47:23] INFO  SQLQueries - Task 7.3 - Average delay by minutes
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 4.7213 ms
[2025-10-07 19:47:23] INFO  DAGScheduler - Registering RDD 84 (collectAsList at SQLQueries.java:160) as input to shuffle 15
[2025-10-07 19:47:23] INFO  DAGScheduler - Got map stage job 25 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:23] INFO  DAGScheduler - Final stage: ShuffleMapStage 61 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:23] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:23] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting ShuffleMapStage 61 (MapPartitionsRDD[84] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_26 stored as values in memory (estimated size 18.7 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  MemoryStore - Block broadcast_26_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 2.2 GiB)
[2025-10-07 19:47:23] INFO  BlockManagerInfo - Added broadcast_26_piece0 in memory on DESKTOP-618L1DH:62628 (size: 9.0 KiB, free: 2.2 GiB)
[2025-10-07 19:47:23] INFO  SparkContext - Created broadcast 26 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:23] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[84] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Adding task set 61.0 with 1 tasks resource profile 0
[2025-10-07 19:47:23] INFO  TaskSetManager - Starting task 0.0 in stage 61.0 (TID 25) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:23] INFO  Executor - Running task 0.0 in stage 61.0 (TID 25)
[2025-10-07 19:47:23] INFO  CodeGenerator - Code generated in 5.151 ms
[2025-10-07 19:47:23] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:23] INFO  Executor - Finished task 0.0 in stage 61.0 (TID 25). 1845 bytes result sent to driver
[2025-10-07 19:47:23] INFO  TaskSetManager - Finished task 0.0 in stage 61.0 (TID 25) in 105 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:23] INFO  TaskSchedulerImpl - Removed TaskSet 61.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:23] INFO  DAGScheduler - ShuffleMapStage 61 (collectAsList at SQLQueries.java:160) finished in 0.113 s
[2025-10-07 19:47:23] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:23] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:23] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:23] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 11.1381 ms
[2025-10-07 19:47:24] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:24] INFO  DAGScheduler - Got job 26 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:24] INFO  DAGScheduler - Final stage: ResultStage 63 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:24] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 62)
[2025-10-07 19:47:24] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:24] INFO  DAGScheduler - Submitting ResultStage 63 (MapPartitionsRDD[87] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:24] INFO  MemoryStore - Block broadcast_27 stored as values in memory (estimated size 15.9 KiB, free 2.2 GiB)
[2025-10-07 19:47:24] INFO  MemoryStore - Block broadcast_27_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 2.2 GiB)
[2025-10-07 19:47:24] INFO  BlockManagerInfo - Added broadcast_27_piece0 in memory on DESKTOP-618L1DH:62628 (size: 7.0 KiB, free: 2.2 GiB)
[2025-10-07 19:47:24] INFO  SparkContext - Created broadcast 27 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:24] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[87] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Adding task set 63.0 with 1 tasks resource profile 0
[2025-10-07 19:47:24] INFO  TaskSetManager - Starting task 0.0 in stage 63.0 (TID 26) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:24] INFO  Executor - Running task 0.0 in stage 63.0 (TID 26)
[2025-10-07 19:47:24] INFO  ShuffleBlockFetcherIterator - Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:24] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 21.1907 ms
[2025-10-07 19:47:24] INFO  Executor - Finished task 0.0 in stage 63.0 (TID 26). 3952 bytes result sent to driver
[2025-10-07 19:47:24] INFO  TaskSetManager - Finished task 0.0 in stage 63.0 (TID 26) in 51 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Removed TaskSet 63.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:24] INFO  DAGScheduler - ResultStage 63 (collectAsList at SQLQueries.java:160) finished in 0.063 s
[2025-10-07 19:47:24] INFO  DAGScheduler - Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Killing all running tasks in stage 63: Stage finished
[2025-10-07 19:47:24] INFO  DAGScheduler - Job 26 finished: collectAsList at SQLQueries.java:160, took 0.072891 s
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 11.1381 ms
[2025-10-07 19:47:24] INFO  SQLQueries - [71.22849830659295]
[2025-10-07 19:47:24] INFO  SQLQueries - Task 7.4 - Yearly delay trend
[2025-10-07 19:47:24] INFO  BlockManagerInfo - Removed broadcast_22_piece0 on DESKTOP-618L1DH:62628 in memory (size: 9.9 KiB, free: 2.2 GiB)
[2025-10-07 19:47:24] INFO  BlockManagerInfo - Removed broadcast_27_piece0 on DESKTOP-618L1DH:62628 in memory (size: 7.0 KiB, free: 2.2 GiB)
[2025-10-07 19:47:24] INFO  BlockManagerInfo - Removed broadcast_26_piece0 on DESKTOP-618L1DH:62628 in memory (size: 9.0 KiB, free: 2.2 GiB)
[2025-10-07 19:47:24] INFO  BlockManagerInfo - Removed broadcast_24_piece0 on DESKTOP-618L1DH:62628 in memory (size: 9.6 KiB, free: 2.2 GiB)
[2025-10-07 19:47:24] INFO  BlockManagerInfo - Removed broadcast_23_piece0 on DESKTOP-618L1DH:62628 in memory (size: 7.9 KiB, free: 2.2 GiB)
[2025-10-07 19:47:24] INFO  BlockManagerInfo - Removed broadcast_25_piece0 on DESKTOP-618L1DH:62628 in memory (size: 7.9 KiB, free: 2.2 GiB)
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 41.7646 ms
[2025-10-07 19:47:24] INFO  DAGScheduler - Registering RDD 90 (collectAsList at SQLQueries.java:160) as input to shuffle 16
[2025-10-07 19:47:24] INFO  DAGScheduler - Got map stage job 27 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:24] INFO  DAGScheduler - Final stage: ShuffleMapStage 64 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:24] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:24] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:24] INFO  DAGScheduler - Submitting ShuffleMapStage 64 (MapPartitionsRDD[90] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:24] INFO  MemoryStore - Block broadcast_28 stored as values in memory (estimated size 65.4 KiB, free 2.2 GiB)
[2025-10-07 19:47:24] INFO  MemoryStore - Block broadcast_28_piece0 stored as bytes in memory (estimated size 25.3 KiB, free 2.2 GiB)
[2025-10-07 19:47:24] INFO  BlockManagerInfo - Added broadcast_28_piece0 in memory on DESKTOP-618L1DH:62628 (size: 25.3 KiB, free: 2.2 GiB)
[2025-10-07 19:47:24] INFO  SparkContext - Created broadcast 28 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:24] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[90] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Adding task set 64.0 with 1 tasks resource profile 0
[2025-10-07 19:47:24] INFO  TaskSetManager - Starting task 0.0 in stage 64.0 (TID 27) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:24] INFO  Executor - Running task 0.0 in stage 64.0 (TID 27)
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 31.2824 ms
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 3.4095 ms
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 3.8094 ms
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 5.5426 ms
[2025-10-07 19:47:24] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:24] INFO  Executor - Finished task 0.0 in stage 64.0 (TID 27). 2451 bytes result sent to driver
[2025-10-07 19:47:24] INFO  TaskSetManager - Finished task 0.0 in stage 64.0 (TID 27) in 319 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Removed TaskSet 64.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:24] INFO  DAGScheduler - ShuffleMapStage 64 (collectAsList at SQLQueries.java:160) finished in 0.328 s
[2025-10-07 19:47:24] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:24] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:24] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:24] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:24] INFO  ShufflePartitionsUtil - For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:24] INFO  HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 25.3694 ms
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 7.3053 ms
[2025-10-07 19:47:24] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:24] INFO  DAGScheduler - Got job 28 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:24] INFO  DAGScheduler - Final stage: ResultStage 66 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:24] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 65)
[2025-10-07 19:47:24] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:24] INFO  DAGScheduler - Submitting ResultStage 66 (MapPartitionsRDD[95] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:24] INFO  MemoryStore - Block broadcast_29 stored as values in memory (estimated size 79.7 KiB, free 2.2 GiB)
[2025-10-07 19:47:24] INFO  MemoryStore - Block broadcast_29_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 2.2 GiB)
[2025-10-07 19:47:24] INFO  BlockManagerInfo - Added broadcast_29_piece0 in memory on DESKTOP-618L1DH:62628 (size: 30.2 KiB, free: 2.2 GiB)
[2025-10-07 19:47:24] INFO  SparkContext - Created broadcast 29 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:24] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[95] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Adding task set 66.0 with 1 tasks resource profile 0
[2025-10-07 19:47:24] INFO  TaskSetManager - Starting task 0.0 in stage 66.0 (TID 28) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:24] INFO  Executor - Running task 0.0 in stage 66.0 (TID 28)
[2025-10-07 19:47:24] INFO  ShuffleBlockFetcherIterator - Getting 1 (351.0 B) non-empty blocks including 1 (351.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:24] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 11.5654 ms
[2025-10-07 19:47:24] INFO  Executor - Finished task 0.0 in stage 66.0 (TID 28). 5050 bytes result sent to driver
[2025-10-07 19:47:24] INFO  TaskSetManager - Finished task 0.0 in stage 66.0 (TID 28) in 28 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Removed TaskSet 66.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:24] INFO  DAGScheduler - ResultStage 66 (collectAsList at SQLQueries.java:160) finished in 0.038 s
[2025-10-07 19:47:24] INFO  DAGScheduler - Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Killing all running tasks in stage 66: Stage finished
[2025-10-07 19:47:24] INFO  DAGScheduler - Job 28 finished: collectAsList at SQLQueries.java:160, took 0.041924 s
[2025-10-07 19:47:24] INFO  DAGScheduler - Registering RDD 96 (collectAsList at SQLQueries.java:160) as input to shuffle 17
[2025-10-07 19:47:24] INFO  DAGScheduler - Got map stage job 29 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:24] INFO  DAGScheduler - Final stage: ShuffleMapStage 68 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:24] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 67)
[2025-10-07 19:47:24] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:24] INFO  DAGScheduler - Submitting ShuffleMapStage 68 (MapPartitionsRDD[96] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:24] INFO  MemoryStore - Block broadcast_30 stored as values in memory (estimated size 80.0 KiB, free 2.2 GiB)
[2025-10-07 19:47:24] INFO  MemoryStore - Block broadcast_30_piece0 stored as bytes in memory (estimated size 30.4 KiB, free 2.2 GiB)
[2025-10-07 19:47:24] INFO  BlockManagerInfo - Added broadcast_30_piece0 in memory on DESKTOP-618L1DH:62628 (size: 30.4 KiB, free: 2.2 GiB)
[2025-10-07 19:47:24] INFO  SparkContext - Created broadcast 30 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:24] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[96] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Adding task set 68.0 with 1 tasks resource profile 0
[2025-10-07 19:47:24] INFO  TaskSetManager - Starting task 0.0 in stage 68.0 (TID 29) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-07 19:47:24] INFO  Executor - Running task 0.0 in stage 68.0 (TID 29)
[2025-10-07 19:47:24] INFO  ShuffleBlockFetcherIterator - Getting 1 (351.0 B) non-empty blocks including 1 (351.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:24] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-07 19:47:24] INFO  Executor - Finished task 0.0 in stage 68.0 (TID 29). 4990 bytes result sent to driver
[2025-10-07 19:47:24] INFO  TaskSetManager - Finished task 0.0 in stage 68.0 (TID 29) in 33 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Removed TaskSet 68.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:24] INFO  DAGScheduler - ShuffleMapStage 68 (collectAsList at SQLQueries.java:160) finished in 0.044 s
[2025-10-07 19:47:24] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:24] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:24] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:24] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:24] INFO  ShufflePartitionsUtil - For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:24] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:24] INFO  DAGScheduler - Got job 30 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:24] INFO  DAGScheduler - Final stage: ResultStage 71 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:24] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 70)
[2025-10-07 19:47:24] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:24] INFO  DAGScheduler - Submitting ResultStage 71 (MapPartitionsRDD[99] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:24] INFO  MemoryStore - Block broadcast_31 stored as values in memory (estimated size 61.6 KiB, free 2.2 GiB)
[2025-10-07 19:47:24] INFO  MemoryStore - Block broadcast_31_piece0 stored as bytes in memory (estimated size 25.2 KiB, free 2.2 GiB)
[2025-10-07 19:47:24] INFO  BlockManagerInfo - Added broadcast_31_piece0 in memory on DESKTOP-618L1DH:62628 (size: 25.2 KiB, free: 2.2 GiB)
[2025-10-07 19:47:24] INFO  SparkContext - Created broadcast 31 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:24] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[99] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Adding task set 71.0 with 1 tasks resource profile 0
[2025-10-07 19:47:24] INFO  TaskSetManager - Starting task 0.0 in stage 71.0 (TID 30) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:24] INFO  Executor - Running task 0.0 in stage 71.0 (TID 30)
[2025-10-07 19:47:24] INFO  ShuffleBlockFetcherIterator - Getting 1 (240.0 B) non-empty blocks including 1 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:24] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-07 19:47:24] INFO  Executor - Finished task 0.0 in stage 71.0 (TID 30). 6380 bytes result sent to driver
[2025-10-07 19:47:24] INFO  TaskSetManager - Finished task 0.0 in stage 71.0 (TID 30) in 16 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Removed TaskSet 71.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:24] INFO  DAGScheduler - ResultStage 71 (collectAsList at SQLQueries.java:160) finished in 0.027 s
[2025-10-07 19:47:24] INFO  DAGScheduler - Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:24] INFO  TaskSchedulerImpl - Killing all running tasks in stage 71: Stage finished
[2025-10-07 19:47:24] INFO  DAGScheduler - Job 30 finished: collectAsList at SQLQueries.java:160, took 0.027657 s
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 5.5685 ms
[2025-10-07 19:47:24] INFO  SQLQueries - [2023,1.02137544E8,1464741,69.74]
[2025-10-07 19:47:24] INFO  SQLQueries - [2024,1.10468988E8,1531462,72.15]
[2025-10-07 19:47:24] INFO  SQLQueries - [2025,4.577989E7,632112,72.44]
[2025-10-07 19:47:24] INFO  SQLQueries - Task 7.5 - Cancellations by carrier & year
[2025-10-07 19:47:24] INFO  CodeGenerator - Code generated in 3.221 ms
[2025-10-07 19:47:24] INFO  DAGScheduler - Registering RDD 103 (collectAsList at SQLQueries.java:160) as input to shuffle 18
[2025-10-07 19:47:24] INFO  DAGScheduler - Got map stage job 31 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:24] INFO  DAGScheduler - Final stage: ShuffleMapStage 72 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:24] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:24] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:24] INFO  DAGScheduler - Submitting ShuffleMapStage 72 (MapPartitionsRDD[103] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:24] INFO  MemoryStore - Block broadcast_32 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
[2025-10-07 19:47:24] INFO  MemoryStore - Block broadcast_32_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 2.2 GiB)
[2025-10-07 19:47:24] INFO  BlockManagerInfo - Added broadcast_32_piece0 in memory on DESKTOP-618L1DH:62628 (size: 7.8 KiB, free: 2.2 GiB)
[2025-10-07 19:47:25] INFO  SparkContext - Created broadcast 32 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:25] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[103] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Adding task set 72.0 with 1 tasks resource profile 0
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 6.0851 ms
[2025-10-07 19:47:25] INFO  TaskSetManager - Starting task 0.0 in stage 72.0 (TID 31) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:25] INFO  Executor - Running task 0.0 in stage 72.0 (TID 31)
[2025-10-07 19:47:25] INFO  DAGScheduler - Registering RDD 105 (collectAsList at SQLQueries.java:160) as input to shuffle 19
[2025-10-07 19:47:25] INFO  DAGScheduler - Got map stage job 32 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:25] INFO  DAGScheduler - Final stage: ShuffleMapStage 73 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:25] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-07 19:47:25] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:25] INFO  DAGScheduler - Submitting ShuffleMapStage 73 (MapPartitionsRDD[105] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:25] INFO  MemoryStore - Block broadcast_33 stored as values in memory (estimated size 14.9 KiB, free 2.2 GiB)
[2025-10-07 19:47:25] INFO  MemoryStore - Block broadcast_33_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 2.2 GiB)
[2025-10-07 19:47:25] INFO  BlockManagerInfo - Added broadcast_33_piece0 in memory on DESKTOP-618L1DH:62628 (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-07 19:47:25] INFO  SparkContext - Created broadcast 33 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:25] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[105] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Adding task set 73.0 with 1 tasks resource profile 0
[2025-10-07 19:47:25] INFO  TaskSetManager - Starting task 0.0 in stage 73.0 (TID 32) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-07 19:47:25] INFO  Executor - Running task 0.0 in stage 73.0 (TID 32)
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 3.9128 ms
[2025-10-07 19:47:25] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 3.153 ms
[2025-10-07 19:47:25] INFO  Executor - Finished task 0.0 in stage 73.0 (TID 32). 1906 bytes result sent to driver
[2025-10-07 19:47:25] INFO  TaskSetManager - Finished task 0.0 in stage 73.0 (TID 32) in 78 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Removed TaskSet 73.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:25] INFO  DAGScheduler - ShuffleMapStage 73 (collectAsList at SQLQueries.java:160) finished in 0.090 s
[2025-10-07 19:47:25] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:25] INFO  DAGScheduler - running: Set(ShuffleMapStage 72)
[2025-10-07 19:47:25] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:25] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 7.9065 ms
[2025-10-07 19:47:25] INFO  JDBCRDD - closed connection
[2025-10-07 19:47:25] INFO  Executor - Finished task 0.0 in stage 72.0 (TID 31). 1906 bytes result sent to driver
[2025-10-07 19:47:25] INFO  TaskSetManager - Finished task 0.0 in stage 72.0 (TID 31) in 148 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Removed TaskSet 72.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:25] INFO  DAGScheduler - ShuffleMapStage 72 (collectAsList at SQLQueries.java:160) finished in 0.159 s
[2025-10-07 19:47:25] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:25] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:25] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:25] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:25] INFO  ShufflePartitionsUtil - For shuffle(18, 19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 25.7242 ms
[2025-10-07 19:47:25] INFO  BlockManagerInfo - Removed broadcast_32_piece0 on DESKTOP-618L1DH:62628 in memory (size: 7.8 KiB, free: 2.2 GiB)
[2025-10-07 19:47:25] INFO  BlockManagerInfo - Removed broadcast_31_piece0 on DESKTOP-618L1DH:62628 in memory (size: 25.2 KiB, free: 2.2 GiB)
[2025-10-07 19:47:25] INFO  DAGScheduler - Registering RDD 112 (collectAsList at SQLQueries.java:160) as input to shuffle 20
[2025-10-07 19:47:25] INFO  DAGScheduler - Got map stage job 33 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:25] INFO  DAGScheduler - Final stage: ShuffleMapStage 76 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:25] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 74, ShuffleMapStage 75)
[2025-10-07 19:47:25] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:25] INFO  DAGScheduler - Submitting ShuffleMapStage 76 (MapPartitionsRDD[112] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:25] INFO  BlockManagerInfo - Removed broadcast_29_piece0 on DESKTOP-618L1DH:62628 in memory (size: 30.2 KiB, free: 2.2 GiB)
[2025-10-07 19:47:25] INFO  BlockManagerInfo - Removed broadcast_33_piece0 on DESKTOP-618L1DH:62628 in memory (size: 7.7 KiB, free: 2.2 GiB)
[2025-10-07 19:47:25] INFO  MemoryStore - Block broadcast_34 stored as values in memory (estimated size 65.2 KiB, free 2.2 GiB)
[2025-10-07 19:47:25] INFO  MemoryStore - Block broadcast_34_piece0 stored as bytes in memory (estimated size 28.5 KiB, free 2.2 GiB)
[2025-10-07 19:47:25] INFO  BlockManagerInfo - Added broadcast_34_piece0 in memory on DESKTOP-618L1DH:62628 (size: 28.5 KiB, free: 2.2 GiB)
[2025-10-07 19:47:25] INFO  SparkContext - Created broadcast 34 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:25] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[112] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Adding task set 76.0 with 1 tasks resource profile 0
[2025-10-07 19:47:25] INFO  BlockManagerInfo - Removed broadcast_28_piece0 on DESKTOP-618L1DH:62628 in memory (size: 25.3 KiB, free: 2.2 GiB)
[2025-10-07 19:47:25] INFO  TaskSetManager - Starting task 0.0 in stage 76.0 (TID 33) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9270 bytes) 
[2025-10-07 19:47:25] INFO  Executor - Running task 0.0 in stage 76.0 (TID 33)
[2025-10-07 19:47:25] INFO  BlockManagerInfo - Removed broadcast_30_piece0 on DESKTOP-618L1DH:62628 in memory (size: 30.4 KiB, free: 2.2 GiB)
[2025-10-07 19:47:25] INFO  ShuffleBlockFetcherIterator - Getting 1 (425.4 KiB) non-empty blocks including 1 (425.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:25] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 5.282 ms
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 5.9317 ms
[2025-10-07 19:47:25] INFO  ShuffleBlockFetcherIterator - Getting 1 (2.0 KiB) non-empty blocks including 1 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:25] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 28.2264 ms
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 6.9366 ms
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 7.1314 ms
[2025-10-07 19:47:25] INFO  Executor - Finished task 0.0 in stage 76.0 (TID 33). 6771 bytes result sent to driver
[2025-10-07 19:47:25] INFO  TaskSetManager - Finished task 0.0 in stage 76.0 (TID 33) in 322 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Removed TaskSet 76.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:25] INFO  DAGScheduler - ShuffleMapStage 76 (collectAsList at SQLQueries.java:160) finished in 0.338 s
[2025-10-07 19:47:25] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:25] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:25] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:25] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:25] INFO  ShufflePartitionsUtil - For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:25] INFO  HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 13.0532 ms
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 6.4509 ms
[2025-10-07 19:47:25] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:25] INFO  DAGScheduler - Got job 34 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:25] INFO  DAGScheduler - Final stage: ResultStage 80 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:25] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 79)
[2025-10-07 19:47:25] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:25] INFO  DAGScheduler - Submitting ResultStage 80 (MapPartitionsRDD[117] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:25] INFO  MemoryStore - Block broadcast_35 stored as values in memory (estimated size 58.8 KiB, free 2.2 GiB)
[2025-10-07 19:47:25] INFO  MemoryStore - Block broadcast_35_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 2.2 GiB)
[2025-10-07 19:47:25] INFO  BlockManagerInfo - Added broadcast_35_piece0 in memory on DESKTOP-618L1DH:62628 (size: 25.5 KiB, free: 2.2 GiB)
[2025-10-07 19:47:25] INFO  SparkContext - Created broadcast 35 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:25] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[117] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Adding task set 80.0 with 1 tasks resource profile 0
[2025-10-07 19:47:25] INFO  TaskSetManager - Starting task 0.0 in stage 80.0 (TID 34) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:25] INFO  Executor - Running task 0.0 in stage 80.0 (TID 34)
[2025-10-07 19:47:25] INFO  ShuffleBlockFetcherIterator - Getting 1 (6.4 KiB) non-empty blocks including 1 (6.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:25] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 7.4781 ms
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 3.5386 ms
[2025-10-07 19:47:25] INFO  Executor - Finished task 0.0 in stage 80.0 (TID 34). 11301 bytes result sent to driver
[2025-10-07 19:47:25] INFO  TaskSetManager - Finished task 0.0 in stage 80.0 (TID 34) in 22 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Removed TaskSet 80.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:25] INFO  DAGScheduler - ResultStage 80 (collectAsList at SQLQueries.java:160) finished in 0.030 s
[2025-10-07 19:47:25] INFO  DAGScheduler - Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Killing all running tasks in stage 80: Stage finished
[2025-10-07 19:47:25] INFO  DAGScheduler - Job 34 finished: collectAsList at SQLQueries.java:160, took 0.041984 s
[2025-10-07 19:47:25] INFO  DAGScheduler - Registering RDD 118 (collectAsList at SQLQueries.java:160) as input to shuffle 21
[2025-10-07 19:47:25] INFO  DAGScheduler - Got map stage job 35 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:25] INFO  DAGScheduler - Final stage: ShuffleMapStage 84 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:25] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 83)
[2025-10-07 19:47:25] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:25] INFO  DAGScheduler - Submitting ShuffleMapStage 84 (MapPartitionsRDD[118] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:25] INFO  MemoryStore - Block broadcast_36 stored as values in memory (estimated size 62.4 KiB, free 2.2 GiB)
[2025-10-07 19:47:25] INFO  MemoryStore - Block broadcast_36_piece0 stored as bytes in memory (estimated size 26.2 KiB, free 2.2 GiB)
[2025-10-07 19:47:25] INFO  BlockManagerInfo - Added broadcast_36_piece0 in memory on DESKTOP-618L1DH:62628 (size: 26.2 KiB, free: 2.2 GiB)
[2025-10-07 19:47:25] INFO  SparkContext - Created broadcast 36 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:25] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[118] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Adding task set 84.0 with 1 tasks resource profile 0
[2025-10-07 19:47:25] INFO  TaskSetManager - Starting task 0.0 in stage 84.0 (TID 35) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-07 19:47:25] INFO  Executor - Running task 0.0 in stage 84.0 (TID 35)
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 4.5324 ms
[2025-10-07 19:47:25] INFO  ShuffleBlockFetcherIterator - Getting 1 (6.4 KiB) non-empty blocks including 1 (6.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:25] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-07 19:47:25] INFO  Executor - Finished task 0.0 in stage 84.0 (TID 35). 8255 bytes result sent to driver
[2025-10-07 19:47:25] INFO  TaskSetManager - Finished task 0.0 in stage 84.0 (TID 35) in 132 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Removed TaskSet 84.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:25] INFO  DAGScheduler - ShuffleMapStage 84 (collectAsList at SQLQueries.java:160) finished in 0.148 s
[2025-10-07 19:47:25] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-07 19:47:25] INFO  DAGScheduler - running: Set()
[2025-10-07 19:47:25] INFO  DAGScheduler - waiting: Set()
[2025-10-07 19:47:25] INFO  DAGScheduler - failed: Set()
[2025-10-07 19:47:25] INFO  ShufflePartitionsUtil - For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-07 19:47:25] INFO  SparkContext - Starting job: collectAsList at SQLQueries.java:160
[2025-10-07 19:47:25] INFO  DAGScheduler - Got job 36 (collectAsList at SQLQueries.java:160) with 1 output partitions
[2025-10-07 19:47:25] INFO  DAGScheduler - Final stage: ResultStage 89 (collectAsList at SQLQueries.java:160)
[2025-10-07 19:47:25] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 88)
[2025-10-07 19:47:25] INFO  DAGScheduler - Missing parents: List()
[2025-10-07 19:47:25] INFO  DAGScheduler - Submitting ResultStage 89 (MapPartitionsRDD[121] at collectAsList at SQLQueries.java:160), which has no missing parents
[2025-10-07 19:47:25] INFO  MemoryStore - Block broadcast_37 stored as values in memory (estimated size 52.4 KiB, free 2.2 GiB)
[2025-10-07 19:47:25] INFO  MemoryStore - Block broadcast_37_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 2.2 GiB)
[2025-10-07 19:47:25] INFO  BlockManagerInfo - Added broadcast_37_piece0 in memory on DESKTOP-618L1DH:62628 (size: 23.4 KiB, free: 2.2 GiB)
[2025-10-07 19:47:25] INFO  SparkContext - Created broadcast 37 from broadcast at DAGScheduler.scala:1611
[2025-10-07 19:47:25] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[121] at collectAsList at SQLQueries.java:160) (first 15 tasks are for partitions Vector(0))
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Adding task set 89.0 with 1 tasks resource profile 0
[2025-10-07 19:47:25] INFO  TaskSetManager - Starting task 0.0 in stage 89.0 (TID 36) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-07 19:47:25] INFO  Executor - Running task 0.0 in stage 89.0 (TID 36)
[2025-10-07 19:47:25] INFO  ShuffleBlockFetcherIterator - Getting 1 (7.1 KiB) non-empty blocks including 1 (7.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-07 19:47:25] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 3.9206 ms
[2025-10-07 19:47:25] INFO  Executor - Finished task 0.0 in stage 89.0 (TID 36). 11012 bytes result sent to driver
[2025-10-07 19:47:25] INFO  TaskSetManager - Finished task 0.0 in stage 89.0 (TID 36) in 21 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Removed TaskSet 89.0, whose tasks have all completed, from pool 
[2025-10-07 19:47:25] INFO  DAGScheduler - ResultStage 89 (collectAsList at SQLQueries.java:160) finished in 0.028 s
[2025-10-07 19:47:25] INFO  DAGScheduler - Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-07 19:47:25] INFO  TaskSchedulerImpl - Killing all running tasks in stage 89: Stage finished
[2025-10-07 19:47:25] INFO  DAGScheduler - Job 36 finished: collectAsList at SQLQueries.java:160, took 0.027563 s
[2025-10-07 19:47:25] INFO  CodeGenerator - Code generated in 6.269 ms
[2025-10-07 19:47:25] INFO  SQLQueries - [9E,ENDEAVOR AIR INC.,2023,4233,373]
[2025-10-07 19:47:25] INFO  SQLQueries - [AA,AMERICAN AIRLINES INC.,2023,9978,2495]
[2025-10-07 19:47:25] INFO  SQLQueries - [AS,ALASKA AIRLINES INC.,2023,1977,724]
[2025-10-07 19:47:25] INFO  SQLQueries - [B6,JETBLUE AIRWAYS,2023,5763,1174]
[2025-10-07 19:47:25] INFO  SQLQueries - [C5,COMMUTEAIR LLC DBA COMMUTEAIR,2023,1027,209]
[2025-10-07 19:47:25] INFO  SQLQueries - [DL,DELTA AIRLINES INC.,2023,10016,2039]
[2025-10-07 19:47:25] INFO  SQLQueries - [F9,FRONTIER AIRLINES INC.,2023,3774,309]
[2025-10-07 19:47:25] INFO  SQLQueries - [G4,ALLEGIANT AIR,2023,782,332]
[2025-10-07 19:47:25] INFO  SQLQueries - [G7,GOJET AIRLINES LLC D/B/A UNITED EXPRESS,2023,1474,79]
[2025-10-07 19:47:25] INFO  SQLQueries - [HA,HAWAIIAN AIRLINES INC.,2023,1053,72]
[2025-10-07 19:47:25] INFO  SQLQueries - [MQ,ENVOY AIR,2023,2193,503]
[2025-10-07 19:47:25] INFO  SQLQueries - [NK,SPIRIT AIRLINES,2023,4486,547]
[2025-10-07 19:47:25] INFO  SQLQueries - [OH,PSA AIRLINES INC.,2023,2461,502]
[2025-10-07 19:47:25] INFO  SQLQueries - [OO,SKYWEST AIRLINES INC.,2023,8186,2051]
[2025-10-07 19:47:25] INFO  SQLQueries - [PT,PIEDMONT AIRLINES,2023,685,387]
[2025-10-07 19:47:25] INFO  SQLQueries - [QX,HORIZON AIR,2023,490,128]
[2025-10-07 19:47:25] INFO  SQLQueries - [UA,UNITED AIRLINES INC.,2023,10270,1910]
[2025-10-07 19:47:25] INFO  SQLQueries - [WN,SOUTHWEST AIRLINES CO.,2023,14325,2902]
[2025-10-07 19:47:25] INFO  SQLQueries - [YV,MESA AIRLINES INC.,2023,1767,295]
[2025-10-07 19:47:25] INFO  SQLQueries - [YX,REPUBLIC AIRLINE,2023,8160,622]
[2025-10-07 19:47:25] INFO  SQLQueries - [ZW,AIR WISCONSIN AIRLINES CORP,2023,797,144]
[2025-10-07 19:47:25] INFO  SQLQueries - [9E,ENDEAVOR AIR INC.,2024,4598,414]
[2025-10-07 19:47:25] INFO  SQLQueries - [AA,AMERICAN AIRLINES INC.,2024,15252,2938]
[2025-10-07 19:47:25] INFO  SQLQueries - [AS,ALASKA AIRLINES INC.,2024,4811,685]
[2025-10-07 19:47:25] INFO  SQLQueries - [B6,JETBLUE AIRWAYS,2024,3735,864]
[2025-10-07 19:47:25] INFO  SQLQueries - [C5,COMMUTEAIR LLC DBA COMMUTEAIR,2024,1465,235]
[2025-10-07 19:47:25] INFO  SQLQueries - [DL,DELTA AIRLINES INC.,2024,9147,2201]
[2025-10-07 19:47:25] INFO  SQLQueries - [F9,FRONTIER AIRLINES INC.,2024,4835,307]
[2025-10-07 19:47:25] INFO  SQLQueries - [G4,ALLEGIANT AIR,2024,2018,310]
[2025-10-07 19:47:25] INFO  SQLQueries - [G7,GOJET AIRLINES LLC D/B/A UNITED EXPRESS,2024,1100,151]
[2025-10-07 19:47:25] INFO  SQLQueries - [HA,HAWAIIAN AIRLINES INC.,2024,822,75]
[2025-10-07 19:47:25] INFO  SQLQueries - [MQ,ENVOY AIR,2024,3857,653]
[2025-10-07 19:47:25] INFO  SQLQueries - [NK,SPIRIT AIRLINES,2024,4998,472]
[2025-10-07 19:47:25] INFO  SQLQueries - [OH,PSA AIRLINES INC.,2024,3744,547]
[2025-10-07 19:47:25] INFO  SQLQueries - [OO,SKYWEST AIRLINES INC.,2024,8453,2245]
[2025-10-07 19:47:25] INFO  SQLQueries - [PT,PIEDMONT AIRLINES,2024,765,395]
[2025-10-07 19:47:25] INFO  SQLQueries - [QX,HORIZON AIR,2024,829,146]
[2025-10-07 19:47:25] INFO  SQLQueries - [UA,UNITED AIRLINES INC.,2024,12478,2155]
[2025-10-07 19:47:25] INFO  SQLQueries - [WN,SOUTHWEST AIRLINES CO.,2024,11772,3050]
[2025-10-07 19:47:25] INFO  SQLQueries - [YV,MESA AIRLINES INC.,2024,1901,291]
[2025-10-07 19:47:25] INFO  SQLQueries - [YX,REPUBLIC AIRLINE,2024,5564,583]
[2025-10-07 19:47:25] INFO  SQLQueries - [ZW,AIR WISCONSIN AIRLINES CORP,2024,764,114]
[2025-10-07 19:47:25] INFO  SQLQueries - [9E,ENDEAVOR AIR INC.,2025,1849,186]
[2025-10-07 19:47:25] INFO  SQLQueries - [AA,AMERICAN AIRLINES INC.,2025,7469,1129]
[2025-10-07 19:47:25] INFO  SQLQueries - [AS,ALASKA AIRLINES INC.,2025,919,229]
[2025-10-07 19:47:25] INFO  SQLQueries - [B6,JETBLUE AIRWAYS,2025,1084,347]
[2025-10-07 19:47:25] INFO  SQLQueries - [C5,COMMUTEAIR LLC DBA COMMUTEAIR,2025,917,97]
[2025-10-07 19:47:25] INFO  SQLQueries - [DL,DELTA AIRLINES INC.,2025,3342,928]
[2025-10-07 19:47:25] INFO  SQLQueries - [F9,FRONTIER AIRLINES INC.,2025,1341,157]
[2025-10-07 19:47:25] INFO  SQLQueries - [G4,ALLEGIANT AIR,2025,313,127]
[2025-10-07 19:47:25] INFO  SQLQueries - [G7,GOJET AIRLINES LLC D/B/A UNITED EXPRESS,2025,730,62]
[2025-10-07 19:47:25] INFO  SQLQueries - [HA,HAWAIIAN AIRLINES INC.,2025,352,41]
[2025-10-07 19:47:25] INFO  SQLQueries - [MQ,ENVOY AIR,2025,3219,270]
[2025-10-07 19:47:25] INFO  SQLQueries - [NK,SPIRIT AIRLINES,2025,1267,144]
[2025-10-07 19:47:25] INFO  SQLQueries - [OH,PSA AIRLINES INC.,2025,6176,279]
[2025-10-07 19:47:25] INFO  SQLQueries - [OO,SKYWEST AIRLINES INC.,2025,4708,1063]
[2025-10-07 19:47:25] INFO  SQLQueries - [PT,PIEDMONT AIRLINES,2025,921,212]
[2025-10-07 19:47:25] INFO  SQLQueries - [QX,HORIZON AIR,2025,496,64]
[2025-10-07 19:47:25] INFO  SQLQueries - [UA,UNITED AIRLINES INC.,2025,2464,782]
[2025-10-07 19:47:25] INFO  SQLQueries - [WN,SOUTHWEST AIRLINES CO.,2025,5806,1105]
[2025-10-07 19:47:25] INFO  SQLQueries - [YV,MESA AIRLINES INC.,2025,796,108]
[2025-10-07 19:47:25] INFO  SQLQueries - [YX,REPUBLIC AIRLINE,2025,3326,252]
[2025-10-07 19:47:25] INFO  SQLQueries - [ZW,AIR WISCONSIN AIRLINES CORP,2025,207,22]
[2025-10-07 19:47:25] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-07 19:47:25] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-07 19:47:25] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-07 19:47:25] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-07 19:47:26] INFO  MemoryStore - MemoryStore cleared
[2025-10-07 19:47:26] INFO  BlockManager - BlockManager stopped
[2025-10-07 19:47:26] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-07 19:47:26] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-07 19:47:26] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-07 19:47:26] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-07 19:47:26] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-48436258-7a04-4e1c-a965-bcadde34e075
[2025-10-07 20:09:54] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-07 20:09:54] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-07 20:09:54] INFO  SparkContext - Java version 11.0.27
[2025-10-07 20:09:55] INFO  ResourceUtils - ==============================================================
[2025-10-07 20:09:55] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-07 20:09:55] INFO  ResourceUtils - ==============================================================
[2025-10-07 20:09:55] INFO  SparkContext - Submitted application: DataTransformationTest
[2025-10-07 20:09:55] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-07 20:09:55] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-07 20:09:55] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-07 20:09:55] INFO  SecurityManager - Changing view acls to: USER
[2025-10-07 20:09:55] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-07 20:09:55] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-07 20:09:55] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-07 20:09:55] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-07 20:09:55] INFO  Utils - Successfully started service 'sparkDriver' on port 53292.
[2025-10-07 20:09:55] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-07 20:09:55] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-07 20:09:55] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-07 20:09:55] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-07 20:09:55] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-07 20:09:55] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-52efcec8-10f0-4297-8fd8-5ef6c788a077
[2025-10-07 20:09:55] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-07 20:09:55] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-07 20:09:55] INFO  log - Logging initialized @2777ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-07 20:09:56] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-07 20:09:56] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-07 20:09:56] INFO  Server - Started @2926ms
[2025-10-07 20:09:56] INFO  AbstractConnector - Started ServerConnector@1de0641b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-07 20:09:56] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2cca611f{/,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-07 20:09:56] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-07 20:09:56] INFO  Executor - Java version 11.0.27
[2025-10-07 20:09:56] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-07 20:09:56] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1983b48a for default.
[2025-10-07 20:09:56] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53339.
[2025-10-07 20:09:56] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:53339
[2025-10-07 20:09:56] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-07 20:09:56] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 53339, None)
[2025-10-07 20:09:56] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:53339 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 53339, None)
[2025-10-07 20:09:56] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 53339, None)
[2025-10-07 20:09:56] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 53339, None)
[2025-10-07 20:09:56] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@2cca611f{/,null,STOPPED,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4b195203{/jobs,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@23444a36{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e0fdbe9{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@696b52bc{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f081b5d{/stages,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@740a0d5e{/stages/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@19f02280{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@19827608{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@14b528b6{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f930e0{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@78c262ba{/storage,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@329dc214{/storage/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@64021427{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@217dc48e{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@296edc75{/environment,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7aea704c{/environment/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@32507479{/executors,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4ae2e781{/executors/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2dd63e3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@209f3887{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b35798{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4702e7a5{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@73bb1337{/static,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1653b84e{/,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f85ee02{/api,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@33d7765a{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@56a4abd0{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5d1d9d73{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-07 20:09:56] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7a36c83a{/SQL,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7b297740{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1fe8f5e8{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6e3dd5ce{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-07 20:09:56] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@35563e4c{/static/sql,null,AVAILABLE,@Spark}
[2025-10-07 20:09:58] INFO  CodeGenerator - Code generated in 176.4368 ms
[2025-10-07 20:09:58] INFO  CodeGenerator - Code generated in 25.1536 ms
[2025-10-07 20:09:58] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-07 20:09:58] INFO  AbstractConnector - Stopped Spark@1de0641b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-07 20:09:58] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-07 20:09:58] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-07 20:09:58] INFO  MemoryStore - MemoryStore cleared
[2025-10-07 20:09:58] INFO  BlockManager - BlockManager stopped
[2025-10-07 20:09:58] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-07 20:09:58] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-07 20:09:59] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-07 20:09:59] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-07 20:09:59] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-8881e698-ba4a-4c0a-b6fe-8711df9e34c7
[2025-10-08 08:13:52] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-08 08:13:52] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-08 08:13:52] INFO  SparkContext - Java version 11.0.27
[2025-10-08 08:13:53] INFO  ResourceUtils - ==============================================================
[2025-10-08 08:13:53] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-08 08:13:53] INFO  ResourceUtils - ==============================================================
[2025-10-08 08:13:53] INFO  SparkContext - Submitted application: DataTransformationTest
[2025-10-08 08:13:53] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-08 08:13:53] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-08 08:13:53] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-08 08:13:53] INFO  SecurityManager - Changing view acls to: USER
[2025-10-08 08:13:53] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-08 08:13:53] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-08 08:13:53] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-08 08:13:53] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-08 08:13:54] INFO  Utils - Successfully started service 'sparkDriver' on port 51914.
[2025-10-08 08:13:54] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-08 08:13:54] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-08 08:13:54] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-08 08:13:54] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-08 08:13:54] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-08 08:13:54] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-b24a6510-6e26-4010-8c1a-d358390cdd10
[2025-10-08 08:13:54] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-08 08:13:54] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-08 08:13:54] INFO  log - Logging initialized @3697ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-08 08:13:54] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-08 08:13:54] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-08 08:13:54] INFO  Server - Started @3844ms
[2025-10-08 08:13:54] INFO  AbstractConnector - Started ServerConnector@1de0641b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 08:13:54] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-08 08:13:54] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2cca611f{/,null,AVAILABLE,@Spark}
[2025-10-08 08:13:54] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-08 08:13:54] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-08 08:13:54] INFO  Executor - Java version 11.0.27
[2025-10-08 08:13:54] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-08 08:13:54] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1983b48a for default.
[2025-10-08 08:13:54] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51961.
[2025-10-08 08:13:54] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:51961
[2025-10-08 08:13:54] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-08 08:13:55] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 51961, None)
[2025-10-08 08:13:55] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:51961 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 51961, None)
[2025-10-08 08:13:55] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 51961, None)
[2025-10-08 08:13:55] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 51961, None)
[2025-10-08 08:13:55] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@2cca611f{/,null,STOPPED,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4b195203{/jobs,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@23444a36{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e0fdbe9{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@696b52bc{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f081b5d{/stages,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@740a0d5e{/stages/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@19f02280{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@19827608{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@14b528b6{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f930e0{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@78c262ba{/storage,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@329dc214{/storage/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@64021427{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@217dc48e{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@296edc75{/environment,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7aea704c{/environment/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@32507479{/executors,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4ae2e781{/executors/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2dd63e3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@209f3887{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b35798{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4702e7a5{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@73bb1337{/static,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1653b84e{/,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f85ee02{/api,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@33d7765a{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@56a4abd0{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5d1d9d73{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-08 08:13:55] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7a36c83a{/SQL,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7b297740{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1fe8f5e8{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6e3dd5ce{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-08 08:13:55] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@35563e4c{/static/sql,null,AVAILABLE,@Spark}
[2025-10-08 08:13:59] INFO  CodeGenerator - Code generated in 355.5917 ms
[2025-10-08 08:13:59] INFO  CodeGenerator - Code generated in 56.0061 ms
[2025-10-08 08:13:59] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 08:13:59] INFO  AbstractConnector - Stopped Spark@1de0641b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 08:13:59] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-08 08:13:59] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-08 08:13:59] INFO  MemoryStore - MemoryStore cleared
[2025-10-08 08:13:59] INFO  BlockManager - BlockManager stopped
[2025-10-08 08:13:59] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-08 08:13:59] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-08 08:13:59] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-08 08:13:59] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-08 08:13:59] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-7b56f52c-122c-4e24-b1bd-53a353e83e34
[2025-10-08 16:00:27] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-08 16:00:27] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-08 16:00:27] INFO  SparkContext - Java version 11.0.27
[2025-10-08 16:00:27] INFO  ResourceUtils - ==============================================================
[2025-10-08 16:00:27] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-08 16:00:27] INFO  ResourceUtils - ==============================================================
[2025-10-08 16:00:27] INFO  SparkContext - Submitted application: DataTransformationTest
[2025-10-08 16:00:27] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-08 16:00:27] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-08 16:00:27] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-08 16:00:27] INFO  SecurityManager - Changing view acls to: USER
[2025-10-08 16:00:27] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-08 16:00:27] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-08 16:00:27] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-08 16:00:27] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-08 16:00:28] INFO  Utils - Successfully started service 'sparkDriver' on port 50965.
[2025-10-08 16:00:28] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-08 16:00:28] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-08 16:00:28] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-08 16:00:28] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-08 16:00:28] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-08 16:00:28] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-8e546b64-d2e2-4bc2-8751-565f9258dac4
[2025-10-08 16:00:28] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-08 16:00:28] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-08 16:00:29] INFO  log - Logging initialized @3422ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-08 16:00:29] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-08 16:00:29] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-08 16:00:29] INFO  Server - Started @3588ms
[2025-10-08 16:00:29] INFO  AbstractConnector - Started ServerConnector@1de0641b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 16:00:29] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2cca611f{/,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-08 16:00:29] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-08 16:00:29] INFO  Executor - Java version 11.0.27
[2025-10-08 16:00:29] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-08 16:00:29] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1983b48a for default.
[2025-10-08 16:00:29] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51012.
[2025-10-08 16:00:29] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:51012
[2025-10-08 16:00:29] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-08 16:00:29] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 51012, None)
[2025-10-08 16:00:29] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:51012 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 51012, None)
[2025-10-08 16:00:29] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 51012, None)
[2025-10-08 16:00:29] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 51012, None)
[2025-10-08 16:00:29] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@2cca611f{/,null,STOPPED,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4b195203{/jobs,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@23444a36{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e0fdbe9{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@696b52bc{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f081b5d{/stages,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@740a0d5e{/stages/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@19f02280{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@19827608{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@14b528b6{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f930e0{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@78c262ba{/storage,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@329dc214{/storage/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@64021427{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@217dc48e{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@296edc75{/environment,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7aea704c{/environment/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@32507479{/executors,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4ae2e781{/executors/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2dd63e3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@209f3887{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b35798{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4702e7a5{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@73bb1337{/static,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1653b84e{/,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f85ee02{/api,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@33d7765a{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@56a4abd0{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5d1d9d73{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-08 16:00:29] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7a36c83a{/SQL,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7b297740{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1fe8f5e8{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6e3dd5ce{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-08 16:00:29] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@35563e4c{/static/sql,null,AVAILABLE,@Spark}
[2025-10-08 16:00:33] INFO  CodeGenerator - Code generated in 210.9452 ms
[2025-10-08 16:00:33] INFO  CodeGenerator - Code generated in 21.1799 ms
[2025-10-08 16:00:33] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 16:00:33] INFO  AbstractConnector - Stopped Spark@1de0641b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 16:00:33] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-08 16:00:33] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-08 16:00:33] INFO  MemoryStore - MemoryStore cleared
[2025-10-08 16:00:33] INFO  BlockManager - BlockManager stopped
[2025-10-08 16:00:33] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-08 16:00:33] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-08 16:00:33] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-08 16:00:33] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-08 16:00:33] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-fbf08f52-eee8-4b6c-9975-492c10f505ba
[2025-10-08 17:57:34] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-08 17:57:34] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-08 17:57:34] INFO  SparkContext - Java version 11.0.27
[2025-10-08 17:57:37] INFO  ResourceUtils - ==============================================================
[2025-10-08 17:57:37] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-08 17:57:37] INFO  ResourceUtils - ==============================================================
[2025-10-08 17:57:37] INFO  SparkContext - Submitted application: Airline Delay Data Cleaning
[2025-10-08 17:57:37] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-08 17:57:37] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-08 17:57:37] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-08 17:57:37] INFO  SecurityManager - Changing view acls to: USER
[2025-10-08 17:57:37] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-08 17:57:37] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-08 17:57:37] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-08 17:57:37] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-08 17:57:38] INFO  Utils - Successfully started service 'sparkDriver' on port 60368.
[2025-10-08 17:57:38] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-08 17:57:38] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-08 17:57:38] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-08 17:57:38] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-08 17:57:38] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-08 17:57:38] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-6141139d-7fa5-4767-b3a8-d4a95236303d
[2025-10-08 17:57:38] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-08 17:57:38] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-08 17:57:38] INFO  log - Logging initialized @5183ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-08 17:57:38] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-08 17:57:38] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-08 17:57:38] INFO  Server - Started @5330ms
[2025-10-08 17:57:38] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 17:57:38] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@244418a{/,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-08 17:57:38] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-08 17:57:38] INFO  Executor - Java version 11.0.27
[2025-10-08 17:57:38] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-08 17:57:38] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3d90eeb3 for default.
[2025-10-08 17:57:38] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60415.
[2025-10-08 17:57:38] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:60415
[2025-10-08 17:57:38] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-08 17:57:38] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 60415, None)
[2025-10-08 17:57:38] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:60415 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 60415, None)
[2025-10-08 17:57:38] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 60415, None)
[2025-10-08 17:57:38] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 60415, None)
[2025-10-08 17:57:38] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@244418a{/,null,STOPPED,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6cfbbff7{/jobs,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@45b32dfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@14c141c0{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@d611f1c{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@51fc862e{/stages,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@fe09383{/stages/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@f25f48a{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b2e5c0d{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5438c17a{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@429aeac1{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6b4fc2d1{/storage,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de4285e{/storage/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@634ff56{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5a484ce1{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2ffe243f{/environment,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4099209b{/environment/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1dad01fe{/executors,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3e3cd6fe{/executors/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@68b734a8{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4215e133{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@d88f893{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@48eaf42f{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2091833{/static,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1084ac45{/,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6ea246af{/api,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@17e0933c{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1dcedc93{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-08 17:57:38] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@38291795{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:39] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-08 17:57:39] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-08 17:57:39] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4bb1b96b{/SQL,null,AVAILABLE,@Spark}
[2025-10-08 17:57:39] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1f66d8e1{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:39] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7069f076{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-08 17:57:39] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@764b14b8{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-08 17:57:39] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6ad1701a{/static/sql,null,AVAILABLE,@Spark}
[2025-10-08 17:57:40] INFO  DataCleaning - Loading from DB Table: bronze.raw_dataset
[2025-10-08 17:58:01] ERROR GlobalExceptionHandler - Exception in Data cleaning failed: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:165) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:55) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:839) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:415) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:237) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:180) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:161) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:157) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:63) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:241) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at scala.Option.getOrElse(Option.scala:189) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.spark.DataCleaning.loadFromTable(DataCleaning.java:79) ~[classes/:?]
	at org.spark.DataCleaning.main(DataCleaning.java:28) [classes/:?]
Caused by: com.mysql.cj.exceptions.CJCommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:?]
	at jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:?]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:490) ~[?:?]
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:52) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:95) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:140) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:156) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:79) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.NativeSession.connect(NativeSession.java:142) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:963) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:827) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	... 19 more
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.PlainSocketImpl.connect0(Native Method) ~[?:?]
	at java.net.PlainSocketImpl.socketConnect(PlainSocketImpl.java:101) ~[?:?]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412) ~[?:?]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255) ~[?:?]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237) ~[?:?]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:?]
	at java.net.Socket.connect(Socket.java:608) ~[?:?]
	at com.mysql.cj.protocol.StandardSocketFactory.connect(StandardSocketFactory.java:144) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:53) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.NativeSession.connect(NativeSession.java:142) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:963) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:827) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	... 19 more
[2025-10-08 17:58:01] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 17:58:01] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 17:58:01] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-08 17:58:01] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-08 17:58:01] INFO  MemoryStore - MemoryStore cleared
[2025-10-08 17:58:01] INFO  BlockManager - BlockManager stopped
[2025-10-08 17:58:01] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-08 17:58:01] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-08 17:58:01] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-08 17:58:01] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-08 17:58:01] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-317bc04e-f887-427e-a494-af20b0bd78fd
[2025-10-08 18:00:29] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-08 18:00:29] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-08 18:00:29] INFO  SparkContext - Java version 11.0.27
[2025-10-08 18:00:30] INFO  ResourceUtils - ==============================================================
[2025-10-08 18:00:30] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-08 18:00:30] INFO  ResourceUtils - ==============================================================
[2025-10-08 18:00:30] INFO  SparkContext - Submitted application: Airline Delay Data Cleaning
[2025-10-08 18:00:30] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-08 18:00:30] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-08 18:00:30] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-08 18:00:30] INFO  SecurityManager - Changing view acls to: USER
[2025-10-08 18:00:30] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-08 18:00:30] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-08 18:00:30] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-08 18:00:30] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-08 18:00:30] INFO  Utils - Successfully started service 'sparkDriver' on port 52878.
[2025-10-08 18:00:30] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-08 18:00:30] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-08 18:00:30] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-08 18:00:30] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-08 18:00:30] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-08 18:00:30] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-9cbe9a36-4778-4d0f-975f-dff55b30a1a4
[2025-10-08 18:00:30] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-08 18:00:30] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-08 18:00:31] INFO  log - Logging initialized @2811ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-08 18:00:31] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-08 18:00:31] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-08 18:00:31] INFO  Server - Started @2956ms
[2025-10-08 18:00:31] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 18:00:31] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@244418a{/,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-08 18:00:31] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-08 18:00:31] INFO  Executor - Java version 11.0.27
[2025-10-08 18:00:31] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-08 18:00:31] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3d90eeb3 for default.
[2025-10-08 18:00:31] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52926.
[2025-10-08 18:00:31] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:52926
[2025-10-08 18:00:31] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-08 18:00:31] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 52926, None)
[2025-10-08 18:00:31] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:52926 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 52926, None)
[2025-10-08 18:00:31] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 52926, None)
[2025-10-08 18:00:31] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 52926, None)
[2025-10-08 18:00:31] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@244418a{/,null,STOPPED,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@30db5536{/jobs,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@136ccbfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@61874b9d{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f2d014a{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@a7cf42f{/stages,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@28e0e464{/stages/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b7c80c6{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7499eac7{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@b9d018b{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79eeff87{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@8bd076a{/storage,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1378eea2{/storage/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66522ead{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@e91b4f4{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58ae402b{/environment,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43ac0a68{/environment/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3728a578{/executors,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de0641b{/executors/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a464fa3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ccb85d6{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@259b85d6{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@488f3dd1{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7bc58891{/static,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@566f1852{/,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e4389ed{/api,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7edb6fca{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@716185fe{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@234c5e41{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-08 18:00:31] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1bbddada{/SQL,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@721d5b74{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a070cf0{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@202d9236{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-08 18:00:31] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7ecda95b{/static/sql,null,AVAILABLE,@Spark}
[2025-10-08 18:00:32] INFO  DataCleaning - Loading from DB Table: bronze.raw_dataset
[2025-10-08 18:00:53] ERROR GlobalExceptionHandler - Exception in Data cleaning failed: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:165) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:55) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:839) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:415) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:237) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:180) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:161) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:157) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:63) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:241) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at scala.Option.getOrElse(Option.scala:189) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.spark.DataCleaning.loadFromTable(DataCleaning.java:79) ~[classes/:?]
	at org.spark.DataCleaning.main(DataCleaning.java:28) [classes/:?]
Caused by: com.mysql.cj.exceptions.CJCommunicationsException: Communications link failure

The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
	at jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:?]
	at jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:?]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:490) ~[?:?]
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:52) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:95) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:140) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:156) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:79) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.NativeSession.connect(NativeSession.java:142) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:963) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:827) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	... 19 more
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.PlainSocketImpl.connect0(Native Method) ~[?:?]
	at java.net.PlainSocketImpl.socketConnect(PlainSocketImpl.java:101) ~[?:?]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412) ~[?:?]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255) ~[?:?]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237) ~[?:?]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:?]
	at java.net.Socket.connect(Socket.java:608) ~[?:?]
	at com.mysql.cj.protocol.StandardSocketFactory.connect(StandardSocketFactory.java:144) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:53) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.NativeSession.connect(NativeSession.java:142) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:963) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:827) ~[mysql-connector-j-9.4.0.jar:9.4.0]
	... 19 more
[2025-10-08 18:00:53] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 18:00:53] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 18:00:53] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-08 18:00:53] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-08 18:00:53] INFO  MemoryStore - MemoryStore cleared
[2025-10-08 18:00:53] INFO  BlockManager - BlockManager stopped
[2025-10-08 18:00:53] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-08 18:00:53] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-08 18:00:53] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-08 18:00:53] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-08 18:00:53] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-6390c6dc-0049-483d-8c12-3bb5fe1d38a8
[2025-10-08 18:01:16] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-08 18:01:16] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-08 18:01:16] INFO  SparkContext - Java version 11.0.27
[2025-10-08 18:01:16] INFO  ResourceUtils - ==============================================================
[2025-10-08 18:01:16] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-08 18:01:16] INFO  ResourceUtils - ==============================================================
[2025-10-08 18:01:16] INFO  SparkContext - Submitted application: Airline Delay Data Cleaning
[2025-10-08 18:01:16] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-08 18:01:16] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-08 18:01:16] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-08 18:01:16] INFO  SecurityManager - Changing view acls to: USER
[2025-10-08 18:01:16] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-08 18:01:16] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-08 18:01:16] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-08 18:01:16] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-08 18:01:17] INFO  Utils - Successfully started service 'sparkDriver' on port 63695.
[2025-10-08 18:01:17] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-08 18:01:17] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-08 18:01:17] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-08 18:01:17] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-08 18:01:17] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-08 18:01:17] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-b37498fc-cc22-4ffd-afed-fd5d40b522e5
[2025-10-08 18:01:17] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-08 18:01:17] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-08 18:01:17] INFO  log - Logging initialized @2662ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-08 18:01:17] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-08 18:01:17] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-08 18:01:17] INFO  Server - Started @2783ms
[2025-10-08 18:01:17] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 18:01:17] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-08 18:01:17] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@244418a{/,null,AVAILABLE,@Spark}
[2025-10-08 18:01:17] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-08 18:01:17] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-08 18:01:17] INFO  Executor - Java version 11.0.27
[2025-10-08 18:01:17] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-08 18:01:17] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3d90eeb3 for default.
[2025-10-08 18:01:17] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63742.
[2025-10-08 18:01:17] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:63742
[2025-10-08 18:01:17] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-08 18:01:17] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 63742, None)
[2025-10-08 18:01:17] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:63742 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 63742, None)
[2025-10-08 18:01:17] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 63742, None)
[2025-10-08 18:01:17] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 63742, None)
[2025-10-08 18:01:18] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@244418a{/,null,STOPPED,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@30db5536{/jobs,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@136ccbfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@61874b9d{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f2d014a{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@a7cf42f{/stages,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@28e0e464{/stages/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b7c80c6{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7499eac7{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@b9d018b{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79eeff87{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@8bd076a{/storage,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1378eea2{/storage/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66522ead{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@e91b4f4{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58ae402b{/environment,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43ac0a68{/environment/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3728a578{/executors,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de0641b{/executors/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a464fa3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ccb85d6{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@259b85d6{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@488f3dd1{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7bc58891{/static,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@566f1852{/,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e4389ed{/api,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7edb6fca{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@716185fe{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@234c5e41{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-08 18:01:18] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1bbddada{/SQL,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@721d5b74{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a070cf0{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@202d9236{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:18] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7ecda95b{/static/sql,null,AVAILABLE,@Spark}
[2025-10-08 18:01:19] INFO  DataCleaning - Loading from DB Table: bronze.raw_dataset
[2025-10-08 18:01:20] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 18:01:20] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 18:01:20] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-08 18:01:20] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-08 18:01:20] INFO  MemoryStore - MemoryStore cleared
[2025-10-08 18:01:20] INFO  BlockManager - BlockManager stopped
[2025-10-08 18:01:20] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-08 18:01:20] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-08 18:01:20] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-08 18:01:20] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_dataset
[2025-10-08 18:01:21] ERROR GlobalExceptionHandler - Exception in Failed to save dataset cleaned_dataset: None.get
java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:529) ~[scala-library-2.12.18.jar:?]
	at scala.None$.get(Option.scala:527) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.datasources.BasicWriteJobStatsTracker$.metrics(BasicWriteStatsTracker.scala:239) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics$(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics$lzycompute(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics$lzycompute(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:63) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.$anonfun$fromSparkPlan$3(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at scala.collection.immutable.List.map(List.scala:293) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:120) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.spark.DataCleaning.save(DataCleaning.java:133) [classes/:?]
	at org.spark.DataCleaning.main(DataCleaning.java:41) [classes/:?]
[2025-10-08 18:01:21] ERROR GlobalExceptionHandler - Exception in Data cleaning failed: java.util.NoSuchElementException: None.get
java.lang.RuntimeException: java.util.NoSuchElementException: None.get
	at org.exception.GlobalExceptionHandler.handle(GlobalExceptionHandler.java:11) [classes/:?]
	at org.spark.DataCleaning.save(DataCleaning.java:146) ~[classes/:?]
	at org.spark.DataCleaning.main(DataCleaning.java:41) [classes/:?]
Caused by: java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:529) ~[scala-library-2.12.18.jar:?]
	at scala.None$.get(Option.scala:527) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.datasources.BasicWriteJobStatsTracker$.metrics(BasicWriteStatsTracker.scala:239) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics$(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics$lzycompute(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics$lzycompute(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:63) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.$anonfun$fromSparkPlan$3(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at scala.collection.immutable.List.map(List.scala:293) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:120) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.spark.DataCleaning.save(DataCleaning.java:133) ~[classes/:?]
	... 1 more
[2025-10-08 18:01:21] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 18:01:21] INFO  SparkContext - SparkContext already stopped.
[2025-10-08 18:01:21] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-08 18:01:21] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-41ead43f-bd13-411c-8c71-d1617e0980ec
[2025-10-08 18:01:38] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-08 18:01:38] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-08 18:01:38] INFO  SparkContext - Java version 11.0.27
[2025-10-08 18:01:38] INFO  ResourceUtils - ==============================================================
[2025-10-08 18:01:38] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-08 18:01:38] INFO  ResourceUtils - ==============================================================
[2025-10-08 18:01:38] INFO  SparkContext - Submitted application: Airline Delay Data Cleaning
[2025-10-08 18:01:39] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-08 18:01:39] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-08 18:01:39] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-08 18:01:39] INFO  SecurityManager - Changing view acls to: USER
[2025-10-08 18:01:39] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-08 18:01:39] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-08 18:01:39] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-08 18:01:39] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-08 18:01:39] INFO  Utils - Successfully started service 'sparkDriver' on port 59130.
[2025-10-08 18:01:39] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-08 18:01:39] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-08 18:01:39] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-08 18:01:39] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-08 18:01:39] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-08 18:01:39] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-7a607b58-a890-47fd-8749-fc38f37761ad
[2025-10-08 18:01:39] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-08 18:01:39] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-08 18:01:39] INFO  log - Logging initialized @2683ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-08 18:01:40] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-08 18:01:40] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-08 18:01:40] INFO  Server - Started @2846ms
[2025-10-08 18:01:40] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 18:01:40] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@244418a{/,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-08 18:01:40] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-08 18:01:40] INFO  Executor - Java version 11.0.27
[2025-10-08 18:01:40] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-08 18:01:40] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3d90eeb3 for default.
[2025-10-08 18:01:40] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59177.
[2025-10-08 18:01:40] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:59177
[2025-10-08 18:01:40] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-08 18:01:40] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 59177, None)
[2025-10-08 18:01:40] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:59177 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 59177, None)
[2025-10-08 18:01:40] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 59177, None)
[2025-10-08 18:01:40] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 59177, None)
[2025-10-08 18:01:40] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@244418a{/,null,STOPPED,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@30db5536{/jobs,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@136ccbfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@61874b9d{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f2d014a{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@a7cf42f{/stages,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@28e0e464{/stages/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b7c80c6{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7499eac7{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@b9d018b{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79eeff87{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@8bd076a{/storage,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1378eea2{/storage/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66522ead{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@e91b4f4{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58ae402b{/environment,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43ac0a68{/environment/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3728a578{/executors,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de0641b{/executors/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a464fa3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ccb85d6{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@259b85d6{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@488f3dd1{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7bc58891{/static,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@566f1852{/,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e4389ed{/api,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7edb6fca{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@716185fe{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@234c5e41{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-08 18:01:40] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1bbddada{/SQL,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@721d5b74{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a070cf0{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@202d9236{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-08 18:01:40] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7ecda95b{/static/sql,null,AVAILABLE,@Spark}
[2025-10-08 18:01:41] INFO  DataCleaning - Loading from DB Table: bronze.raw_dataset
[2025-10-08 18:01:42] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_dataset
[2025-10-08 18:01:44] INFO  CodeGenerator - Code generated in 416.2985 ms
[2025-10-08 18:01:44] INFO  DAGScheduler - Registering RDD 2 (save at DataCleaning.java:133) as input to shuffle 0
[2025-10-08 18:01:44] INFO  DAGScheduler - Got map stage job 0 (save at DataCleaning.java:133) with 1 output partitions
[2025-10-08 18:01:44] INFO  DAGScheduler - Final stage: ShuffleMapStage 0 (save at DataCleaning.java:133)
[2025-10-08 18:01:44] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 18:01:44] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 18:01:44] INFO  DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at DataCleaning.java:133), which has no missing parents
[2025-10-08 18:01:44] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 75.7 KiB, free 2.2 GiB)
[2025-10-08 18:01:44] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-08 18:01:44] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on DESKTOP-618L1DH:59177 (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-08 18:01:44] INFO  SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1611
[2025-10-08 18:01:44] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at DataCleaning.java:133) (first 15 tasks are for partitions Vector(0))
[2025-10-08 18:01:44] INFO  TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
[2025-10-08 18:01:44] INFO  TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-08 18:01:44] INFO  Executor - Running task 0.0 in stage 0.0 (TID 0)
[2025-10-08 18:01:45] INFO  CodeGenerator - Code generated in 89.757 ms
[2025-10-08 18:01:45] INFO  CodeGenerator - Code generated in 30.2893 ms
[2025-10-08 18:01:45] INFO  CodeGenerator - Code generated in 8.4119 ms
[2025-10-08 18:01:45] INFO  CodeGenerator - Code generated in 11.0279 ms
[2025-10-08 18:01:45] INFO  JDBCRDD - closed connection
[2025-10-08 18:01:46] INFO  Executor - Finished task 0.0 in stage 0.0 (TID 0). 2593 bytes result sent to driver
[2025-10-08 18:01:46] INFO  TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1490 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 18:01:46] INFO  TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[2025-10-08 18:01:46] INFO  DAGScheduler - ShuffleMapStage 0 (save at DataCleaning.java:133) finished in 1.667 s
[2025-10-08 18:01:46] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-08 18:01:46] INFO  DAGScheduler - running: Set()
[2025-10-08 18:01:46] INFO  DAGScheduler - waiting: Set()
[2025-10-08 18:01:46] INFO  DAGScheduler - failed: Set()
[2025-10-08 18:01:46] INFO  ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-08 18:01:46] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:01:46] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 18:01:46] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 18:01:46] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:01:46] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 18:01:46] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 18:01:46] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:01:46] INFO  CodeGenerator - Code generated in 68.2508 ms
[2025-10-08 18:01:46] INFO  SparkContext - Starting job: save at DataCleaning.java:133
[2025-10-08 18:01:46] INFO  DAGScheduler - Got job 1 (save at DataCleaning.java:133) with 1 output partitions
[2025-10-08 18:01:46] INFO  DAGScheduler - Final stage: ResultStage 2 (save at DataCleaning.java:133)
[2025-10-08 18:01:46] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
[2025-10-08 18:01:46] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 18:01:46] INFO  DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[6] at save at DataCleaning.java:133), which has no missing parents
[2025-10-08 18:01:46] INFO  MemoryStore - Block broadcast_1 stored as values in memory (estimated size 288.9 KiB, free 2.2 GiB)
[2025-10-08 18:01:46] INFO  MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 102.8 KiB, free 2.2 GiB)
[2025-10-08 18:01:46] INFO  BlockManagerInfo - Added broadcast_1_piece0 in memory on DESKTOP-618L1DH:59177 (size: 102.8 KiB, free: 2.2 GiB)
[2025-10-08 18:01:46] INFO  SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1611
[2025-10-08 18:01:46] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at save at DataCleaning.java:133) (first 15 tasks are for partitions Vector(0))
[2025-10-08 18:01:46] INFO  TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
[2025-10-08 18:01:46] INFO  TaskSetManager - Starting task 0.0 in stage 2.0 (TID 1) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9387 bytes) 
[2025-10-08 18:01:46] INFO  Executor - Running task 0.0 in stage 2.0 (TID 1)
[2025-10-08 18:01:46] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 18:01:46] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 18:01:46] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:01:46] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 18:01:46] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 18:01:46] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:01:47] INFO  CodecConfig - Compression: SNAPPY
[2025-10-08 18:01:47] INFO  CodecConfig - Compression: SNAPPY
[2025-10-08 18:01:47] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-08 18:01:47] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "year",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "month",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "airport",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "isSigned" : false,
      "scale" : 0
    }
  }, {
    "name" : "airport_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_flights",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_del15",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "weather_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "nas_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "security_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "late_aircraft_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_cancelled",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_diverted",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "weather_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "nas_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "security_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "late_aircraft_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 year;
  optional int32 month;
  optional binary carrier (STRING);
  optional binary carrier_name (STRING);
  optional binary airport (STRING);
  optional binary airport_name (STRING);
  optional int32 arr_flights;
  optional double arr_del15;
  optional double carrier_ct;
  optional double weather_ct;
  optional double nas_ct;
  optional double security_ct;
  optional double late_aircraft_ct;
  optional double arr_cancelled;
  optional double arr_diverted;
  optional double arr_delay;
  optional double carrier_delay;
  optional double weather_delay;
  optional double nas_delay;
  optional double security_delay;
  optional double late_aircraft_delay;
  optional int32 date (DATE);
}

       
[2025-10-08 18:01:47] INFO  CodecPool - Got brand-new compressor [.snappy]
[2025-10-08 18:01:47] INFO  ShuffleBlockFetcherIterator - Getting 1 (1055.0 KiB) non-empty blocks including 1 (1055.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:47] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 8 ms
[2025-10-08 18:01:47] INFO  CodeGenerator - Code generated in 64.9458 ms
[2025-10-08 18:01:48] INFO  ShuffleBlockFetcherIterator - Getting 1 (1053.2 KiB) non-empty blocks including 1 (1053.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:48] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-08 18:01:48] INFO  ShuffleBlockFetcherIterator - Getting 1 (1035.9 KiB) non-empty blocks including 1 (1035.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:48] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-08 18:01:48] INFO  ShuffleBlockFetcherIterator - Getting 1 (1031.9 KiB) non-empty blocks including 1 (1031.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:48] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-08 18:01:48] INFO  ShuffleBlockFetcherIterator - Getting 1 (1639.8 KiB) non-empty blocks including 1 (1639.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:48] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-08 18:01:48] INFO  FileOutputCommitter - Saved output of task 'attempt_202510081801465267883964906270796_0002_m_000000_1' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/silver/cleaned_dataset/_temporary/0/task_202510081801465267883964906270796_0002_m_000000
[2025-10-08 18:01:48] INFO  SparkHadoopMapRedUtil - attempt_202510081801465267883964906270796_0002_m_000000_1: Committed. Elapsed time: 2 ms.
[2025-10-08 18:01:48] INFO  Executor - Finished task 0.0 in stage 2.0 (TID 1). 6005 bytes result sent to driver
[2025-10-08 18:01:48] INFO  TaskSetManager - Finished task 0.0 in stage 2.0 (TID 1) in 2073 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 18:01:48] INFO  TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[2025-10-08 18:01:48] INFO  DAGScheduler - ResultStage 2 (save at DataCleaning.java:133) finished in 2.169 s
[2025-10-08 18:01:49] INFO  DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 18:01:49] INFO  TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
[2025-10-08 18:01:49] INFO  DAGScheduler - Job 1 finished: save at DataCleaning.java:133, took 2.203777 s
[2025-10-08 18:01:49] INFO  FileFormatWriter - Start to commit write Job f401fe0a-637b-4cb1-8269-77788db0d0a6.
[2025-10-08 18:01:49] INFO  FileFormatWriter - Write Job f401fe0a-637b-4cb1-8269-77788db0d0a6 committed. Elapsed time: 13 ms.
[2025-10-08 18:01:49] INFO  FileFormatWriter - Finished processing stats for write job f401fe0a-637b-4cb1-8269-77788db0d0a6.
[2025-10-08 18:01:49] INFO  DataCleaning - Overwriting DB Table: silver.cleaned_dataset
[2025-10-08 18:01:49] WARN  SparkStringUtils - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2025-10-08 18:01:49] INFO  DAGScheduler - Registering RDD 9 (save at DataCleaning.java:144) as input to shuffle 1
[2025-10-08 18:01:49] INFO  DAGScheduler - Got map stage job 2 (save at DataCleaning.java:144) with 1 output partitions
[2025-10-08 18:01:49] INFO  DAGScheduler - Final stage: ShuffleMapStage 3 (save at DataCleaning.java:144)
[2025-10-08 18:01:49] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 18:01:49] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 18:01:49] INFO  DAGScheduler - Submitting ShuffleMapStage 3 (MapPartitionsRDD[9] at save at DataCleaning.java:144), which has no missing parents
[2025-10-08 18:01:49] INFO  MemoryStore - Block broadcast_2 stored as values in memory (estimated size 75.7 KiB, free 2.2 GiB)
[2025-10-08 18:01:49] INFO  MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-08 18:01:49] INFO  BlockManagerInfo - Added broadcast_2_piece0 in memory on DESKTOP-618L1DH:59177 (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-08 18:01:49] INFO  SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1611
[2025-10-08 18:01:49] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[9] at save at DataCleaning.java:144) (first 15 tasks are for partitions Vector(0))
[2025-10-08 18:01:49] INFO  TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
[2025-10-08 18:01:49] INFO  TaskSetManager - Starting task 0.0 in stage 3.0 (TID 2) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-08 18:01:49] INFO  Executor - Running task 0.0 in stage 3.0 (TID 2)
[2025-10-08 18:01:49] INFO  BlockManagerInfo - Removed broadcast_1_piece0 on DESKTOP-618L1DH:59177 in memory (size: 102.8 KiB, free: 2.2 GiB)
[2025-10-08 18:01:49] INFO  JDBCRDD - closed connection
[2025-10-08 18:01:50] INFO  Executor - Finished task 0.0 in stage 3.0 (TID 2). 2507 bytes result sent to driver
[2025-10-08 18:01:50] INFO  TaskSetManager - Finished task 0.0 in stage 3.0 (TID 2) in 952 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 18:01:50] INFO  TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[2025-10-08 18:01:50] INFO  DAGScheduler - ShuffleMapStage 3 (save at DataCleaning.java:144) finished in 0.968 s
[2025-10-08 18:01:50] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-08 18:01:50] INFO  DAGScheduler - running: Set()
[2025-10-08 18:01:50] INFO  DAGScheduler - waiting: Set()
[2025-10-08 18:01:50] INFO  DAGScheduler - failed: Set()
[2025-10-08 18:01:50] INFO  ShufflePartitionsUtil - For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-08 18:01:50] INFO  SparkContext - Starting job: save at DataCleaning.java:144
[2025-10-08 18:01:50] INFO  DAGScheduler - Got job 3 (save at DataCleaning.java:144) with 5 output partitions
[2025-10-08 18:01:50] INFO  DAGScheduler - Final stage: ResultStage 5 (save at DataCleaning.java:144)
[2025-10-08 18:01:50] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 4)
[2025-10-08 18:01:50] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 18:01:50] INFO  DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[14] at save at DataCleaning.java:144), which has no missing parents
[2025-10-08 18:01:50] INFO  MemoryStore - Block broadcast_3 stored as values in memory (estimated size 95.5 KiB, free 2.2 GiB)
[2025-10-08 18:01:50] INFO  MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 2.2 GiB)
[2025-10-08 18:01:50] INFO  BlockManagerInfo - Added broadcast_3_piece0 in memory on DESKTOP-618L1DH:59177 (size: 34.8 KiB, free: 2.2 GiB)
[2025-10-08 18:01:50] INFO  SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1611
[2025-10-08 18:01:50] INFO  DAGScheduler - Submitting 5 missing tasks from ResultStage 5 (MapPartitionsRDD[14] at save at DataCleaning.java:144) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
[2025-10-08 18:01:50] INFO  TaskSchedulerImpl - Adding task set 5.0 with 5 tasks resource profile 0
[2025-10-08 18:01:50] INFO  TaskSetManager - Starting task 0.0 in stage 5.0 (TID 3) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-08 18:01:50] INFO  TaskSetManager - Starting task 1.0 in stage 5.0 (TID 4) (DESKTOP-618L1DH, executor driver, partition 1, NODE_LOCAL, 8999 bytes) 
[2025-10-08 18:01:50] INFO  TaskSetManager - Starting task 2.0 in stage 5.0 (TID 5) (DESKTOP-618L1DH, executor driver, partition 2, NODE_LOCAL, 8999 bytes) 
[2025-10-08 18:01:50] INFO  TaskSetManager - Starting task 3.0 in stage 5.0 (TID 6) (DESKTOP-618L1DH, executor driver, partition 3, NODE_LOCAL, 8999 bytes) 
[2025-10-08 18:01:50] INFO  TaskSetManager - Starting task 4.0 in stage 5.0 (TID 7) (DESKTOP-618L1DH, executor driver, partition 4, NODE_LOCAL, 8999 bytes) 
[2025-10-08 18:01:50] INFO  Executor - Running task 0.0 in stage 5.0 (TID 3)
[2025-10-08 18:01:50] INFO  Executor - Running task 1.0 in stage 5.0 (TID 4)
[2025-10-08 18:01:50] INFO  Executor - Running task 2.0 in stage 5.0 (TID 5)
[2025-10-08 18:01:50] INFO  Executor - Running task 3.0 in stage 5.0 (TID 6)
[2025-10-08 18:01:50] INFO  Executor - Running task 4.0 in stage 5.0 (TID 7)
[2025-10-08 18:01:50] INFO  ShuffleBlockFetcherIterator - Getting 1 (1031.9 KiB) non-empty blocks including 1 (1031.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:50] INFO  ShuffleBlockFetcherIterator - Getting 1 (1055.0 KiB) non-empty blocks including 1 (1055.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:50] INFO  ShuffleBlockFetcherIterator - Getting 1 (1035.9 KiB) non-empty blocks including 1 (1035.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:50] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 3 ms
[2025-10-08 18:01:50] INFO  ShuffleBlockFetcherIterator - Getting 1 (1639.8 KiB) non-empty blocks including 1 (1639.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:50] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 3 ms
[2025-10-08 18:01:50] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 3 ms
[2025-10-08 18:01:50] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 4 ms
[2025-10-08 18:01:50] INFO  ShuffleBlockFetcherIterator - Getting 1 (1053.2 KiB) non-empty blocks including 1 (1053.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:50] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 3 ms
[2025-10-08 18:01:51] INFO  CodeGenerator - Code generated in 20.7527 ms
[2025-10-08 18:01:55] INFO  Executor - Finished task 3.0 in stage 5.0 (TID 6). 4794 bytes result sent to driver
[2025-10-08 18:01:55] INFO  TaskSetManager - Finished task 3.0 in stage 5.0 (TID 6) in 4946 ms on DESKTOP-618L1DH (executor driver) (1/5)
[2025-10-08 18:01:55] INFO  Executor - Finished task 2.0 in stage 5.0 (TID 5). 4751 bytes result sent to driver
[2025-10-08 18:01:55] INFO  TaskSetManager - Finished task 2.0 in stage 5.0 (TID 5) in 4972 ms on DESKTOP-618L1DH (executor driver) (2/5)
[2025-10-08 18:01:55] INFO  Executor - Finished task 1.0 in stage 5.0 (TID 4). 4751 bytes result sent to driver
[2025-10-08 18:01:55] INFO  TaskSetManager - Finished task 1.0 in stage 5.0 (TID 4) in 5050 ms on DESKTOP-618L1DH (executor driver) (3/5)
[2025-10-08 18:01:55] INFO  Executor - Finished task 0.0 in stage 5.0 (TID 3). 4751 bytes result sent to driver
[2025-10-08 18:01:55] INFO  TaskSetManager - Finished task 0.0 in stage 5.0 (TID 3) in 5057 ms on DESKTOP-618L1DH (executor driver) (4/5)
[2025-10-08 18:01:57] INFO  Executor - Finished task 4.0 in stage 5.0 (TID 7). 4751 bytes result sent to driver
[2025-10-08 18:01:57] INFO  TaskSetManager - Finished task 4.0 in stage 5.0 (TID 7) in 7386 ms on DESKTOP-618L1DH (executor driver) (5/5)
[2025-10-08 18:01:57] INFO  TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[2025-10-08 18:01:57] INFO  DAGScheduler - ResultStage 5 (save at DataCleaning.java:144) finished in 7.409 s
[2025-10-08 18:01:57] INFO  DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 18:01:57] INFO  TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
[2025-10-08 18:01:57] INFO  DAGScheduler - Job 3 finished: save at DataCleaning.java:144, took 7.426879 s
[2025-10-08 18:01:57] INFO  DAGScheduler - Registering RDD 17 (count at DataCleaning.java:42) as input to shuffle 2
[2025-10-08 18:01:57] INFO  DAGScheduler - Got map stage job 4 (count at DataCleaning.java:42) with 1 output partitions
[2025-10-08 18:01:57] INFO  DAGScheduler - Final stage: ShuffleMapStage 6 (count at DataCleaning.java:42)
[2025-10-08 18:01:57] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 18:01:57] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 18:01:57] INFO  DAGScheduler - Submitting ShuffleMapStage 6 (MapPartitionsRDD[17] at count at DataCleaning.java:42), which has no missing parents
[2025-10-08 18:01:57] INFO  MemoryStore - Block broadcast_4 stored as values in memory (estimated size 75.7 KiB, free 2.2 GiB)
[2025-10-08 18:01:57] INFO  MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-08 18:01:57] INFO  BlockManagerInfo - Added broadcast_4_piece0 in memory on DESKTOP-618L1DH:59177 (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-08 18:01:57] INFO  SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1611
[2025-10-08 18:01:57] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[17] at count at DataCleaning.java:42) (first 15 tasks are for partitions Vector(0))
[2025-10-08 18:01:57] INFO  TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
[2025-10-08 18:01:57] INFO  TaskSetManager - Starting task 0.0 in stage 6.0 (TID 8) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-08 18:01:57] INFO  Executor - Running task 0.0 in stage 6.0 (TID 8)
[2025-10-08 18:01:58] INFO  JDBCRDD - closed connection
[2025-10-08 18:01:58] INFO  Executor - Finished task 0.0 in stage 6.0 (TID 8). 2507 bytes result sent to driver
[2025-10-08 18:01:58] INFO  TaskSetManager - Finished task 0.0 in stage 6.0 (TID 8) in 851 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 18:01:58] INFO  TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[2025-10-08 18:01:58] INFO  DAGScheduler - ShuffleMapStage 6 (count at DataCleaning.java:42) finished in 0.867 s
[2025-10-08 18:01:58] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-08 18:01:58] INFO  DAGScheduler - running: Set()
[2025-10-08 18:01:58] INFO  DAGScheduler - waiting: Set()
[2025-10-08 18:01:58] INFO  DAGScheduler - failed: Set()
[2025-10-08 18:01:58] INFO  ShufflePartitionsUtil - For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-08 18:01:58] INFO  CodeGenerator - Code generated in 41.9373 ms
[2025-10-08 18:01:58] INFO  DAGScheduler - Registering RDD 20 (count at DataCleaning.java:42) as input to shuffle 3
[2025-10-08 18:01:58] INFO  DAGScheduler - Got map stage job 5 (count at DataCleaning.java:42) with 5 output partitions
[2025-10-08 18:01:58] INFO  DAGScheduler - Final stage: ShuffleMapStage 8 (count at DataCleaning.java:42)
[2025-10-08 18:01:58] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 7)
[2025-10-08 18:01:58] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 18:01:58] INFO  DAGScheduler - Submitting ShuffleMapStage 8 (MapPartitionsRDD[20] at count at DataCleaning.java:42), which has no missing parents
[2025-10-08 18:01:58] INFO  MemoryStore - Block broadcast_5 stored as values in memory (estimated size 76.1 KiB, free 2.2 GiB)
[2025-10-08 18:01:58] INFO  MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.1 KiB, free 2.2 GiB)
[2025-10-08 18:01:58] INFO  BlockManagerInfo - Added broadcast_5_piece0 in memory on DESKTOP-618L1DH:59177 (size: 29.1 KiB, free: 2.2 GiB)
[2025-10-08 18:01:58] INFO  SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1611
[2025-10-08 18:01:58] INFO  DAGScheduler - Submitting 5 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[20] at count at DataCleaning.java:42) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
[2025-10-08 18:01:58] INFO  TaskSchedulerImpl - Adding task set 8.0 with 5 tasks resource profile 0
[2025-10-08 18:01:58] INFO  TaskSetManager - Starting task 0.0 in stage 8.0 (TID 9) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-08 18:01:58] INFO  TaskSetManager - Starting task 1.0 in stage 8.0 (TID 10) (DESKTOP-618L1DH, executor driver, partition 1, NODE_LOCAL, 8988 bytes) 
[2025-10-08 18:01:58] INFO  TaskSetManager - Starting task 2.0 in stage 8.0 (TID 11) (DESKTOP-618L1DH, executor driver, partition 2, NODE_LOCAL, 8988 bytes) 
[2025-10-08 18:01:58] INFO  TaskSetManager - Starting task 3.0 in stage 8.0 (TID 12) (DESKTOP-618L1DH, executor driver, partition 3, NODE_LOCAL, 8988 bytes) 
[2025-10-08 18:01:58] INFO  TaskSetManager - Starting task 4.0 in stage 8.0 (TID 13) (DESKTOP-618L1DH, executor driver, partition 4, NODE_LOCAL, 8988 bytes) 
[2025-10-08 18:01:58] INFO  Executor - Running task 1.0 in stage 8.0 (TID 10)
[2025-10-08 18:01:58] INFO  Executor - Running task 0.0 in stage 8.0 (TID 9)
[2025-10-08 18:01:58] INFO  Executor - Running task 3.0 in stage 8.0 (TID 12)
[2025-10-08 18:01:58] INFO  Executor - Running task 2.0 in stage 8.0 (TID 11)
[2025-10-08 18:01:58] INFO  Executor - Running task 4.0 in stage 8.0 (TID 13)
[2025-10-08 18:01:58] INFO  ShuffleBlockFetcherIterator - Getting 1 (1031.9 KiB) non-empty blocks including 1 (1031.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:58] INFO  ShuffleBlockFetcherIterator - Getting 1 (1639.8 KiB) non-empty blocks including 1 (1639.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:58] INFO  ShuffleBlockFetcherIterator - Getting 1 (1055.0 KiB) non-empty blocks including 1 (1055.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:58] INFO  ShuffleBlockFetcherIterator - Getting 1 (1035.9 KiB) non-empty blocks including 1 (1035.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:58] INFO  ShuffleBlockFetcherIterator - Getting 1 (1053.2 KiB) non-empty blocks including 1 (1053.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:58] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-08 18:01:58] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-08 18:01:58] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-08 18:01:58] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-08 18:01:58] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-08 18:01:59] INFO  CodeGenerator - Code generated in 43.5816 ms
[2025-10-08 18:01:59] INFO  Executor - Finished task 0.0 in stage 8.0 (TID 9). 5423 bytes result sent to driver
[2025-10-08 18:01:59] INFO  TaskSetManager - Finished task 0.0 in stage 8.0 (TID 9) in 199 ms on DESKTOP-618L1DH (executor driver) (1/5)
[2025-10-08 18:01:59] INFO  Executor - Finished task 2.0 in stage 8.0 (TID 11). 5509 bytes result sent to driver
[2025-10-08 18:01:59] INFO  TaskSetManager - Finished task 2.0 in stage 8.0 (TID 11) in 215 ms on DESKTOP-618L1DH (executor driver) (2/5)
[2025-10-08 18:01:59] INFO  Executor - Finished task 1.0 in stage 8.0 (TID 10). 5466 bytes result sent to driver
[2025-10-08 18:01:59] INFO  TaskSetManager - Finished task 1.0 in stage 8.0 (TID 10) in 219 ms on DESKTOP-618L1DH (executor driver) (3/5)
[2025-10-08 18:01:59] INFO  Executor - Finished task 3.0 in stage 8.0 (TID 12). 5466 bytes result sent to driver
[2025-10-08 18:01:59] INFO  TaskSetManager - Finished task 3.0 in stage 8.0 (TID 12) in 227 ms on DESKTOP-618L1DH (executor driver) (4/5)
[2025-10-08 18:01:59] INFO  Executor - Finished task 4.0 in stage 8.0 (TID 13). 5466 bytes result sent to driver
[2025-10-08 18:01:59] INFO  TaskSetManager - Finished task 4.0 in stage 8.0 (TID 13) in 236 ms on DESKTOP-618L1DH (executor driver) (5/5)
[2025-10-08 18:01:59] INFO  TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[2025-10-08 18:01:59] INFO  DAGScheduler - ShuffleMapStage 8 (count at DataCleaning.java:42) finished in 0.251 s
[2025-10-08 18:01:59] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-08 18:01:59] INFO  DAGScheduler - running: Set()
[2025-10-08 18:01:59] INFO  DAGScheduler - waiting: Set()
[2025-10-08 18:01:59] INFO  DAGScheduler - failed: Set()
[2025-10-08 18:01:59] INFO  BlockManagerInfo - Removed broadcast_3_piece0 on DESKTOP-618L1DH:59177 in memory (size: 34.8 KiB, free: 2.2 GiB)
[2025-10-08 18:01:59] INFO  BlockManagerInfo - Removed broadcast_4_piece0 on DESKTOP-618L1DH:59177 in memory (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-08 18:01:59] INFO  BlockManagerInfo - Removed broadcast_0_piece0 on DESKTOP-618L1DH:59177 in memory (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-08 18:01:59] INFO  CodeGenerator - Code generated in 22.4615 ms
[2025-10-08 18:01:59] INFO  BlockManagerInfo - Removed broadcast_2_piece0 on DESKTOP-618L1DH:59177 in memory (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-08 18:01:59] INFO  SparkContext - Starting job: count at DataCleaning.java:42
[2025-10-08 18:01:59] INFO  DAGScheduler - Got job 6 (count at DataCleaning.java:42) with 1 output partitions
[2025-10-08 18:01:59] INFO  DAGScheduler - Final stage: ResultStage 11 (count at DataCleaning.java:42)
[2025-10-08 18:01:59] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 10)
[2025-10-08 18:01:59] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 18:01:59] INFO  DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[23] at count at DataCleaning.java:42), which has no missing parents
[2025-10-08 18:01:59] INFO  MemoryStore - Block broadcast_6 stored as values in memory (estimated size 12.5 KiB, free 2.2 GiB)
[2025-10-08 18:01:59] INFO  MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
[2025-10-08 18:01:59] INFO  BlockManagerInfo - Added broadcast_6_piece0 in memory on DESKTOP-618L1DH:59177 (size: 5.9 KiB, free: 2.2 GiB)
[2025-10-08 18:01:59] INFO  SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-10-08 18:01:59] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[23] at count at DataCleaning.java:42) (first 15 tasks are for partitions Vector(0))
[2025-10-08 18:01:59] INFO  TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
[2025-10-08 18:01:59] INFO  TaskSetManager - Starting task 0.0 in stage 11.0 (TID 14) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-08 18:01:59] INFO  Executor - Running task 0.0 in stage 11.0 (TID 14)
[2025-10-08 18:01:59] INFO  ShuffleBlockFetcherIterator - Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 18:01:59] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-08 18:01:59] INFO  CodeGenerator - Code generated in 9.9462 ms
[2025-10-08 18:01:59] INFO  Executor - Finished task 0.0 in stage 11.0 (TID 14). 4038 bytes result sent to driver
[2025-10-08 18:01:59] INFO  TaskSetManager - Finished task 0.0 in stage 11.0 (TID 14) in 41 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 18:01:59] INFO  TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
[2025-10-08 18:01:59] INFO  DAGScheduler - ResultStage 11 (count at DataCleaning.java:42) finished in 0.052 s
[2025-10-08 18:01:59] INFO  DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 18:01:59] INFO  TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
[2025-10-08 18:01:59] INFO  DAGScheduler - Job 6 finished: count at DataCleaning.java:42, took 0.060953 s
[2025-10-08 18:01:59] INFO  DataCleaning - Cleaned dataset stored in silver layer. Row count = 54619
[2025-10-08 18:01:59] INFO  DataCleaning - Loading from DB Table: bronze.carrier_lookup
[2025-10-08 18:01:59] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_carrier_lookup
[2025-10-08 18:01:59] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:01:59] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 18:01:59] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 18:01:59] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:01:59] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 18:01:59] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 18:01:59] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:01:59] INFO  CodeGenerator - Code generated in 9.8199 ms
[2025-10-08 18:01:59] INFO  SparkContext - Starting job: save at DataCleaning.java:133
[2025-10-08 18:01:59] INFO  DAGScheduler - Got job 7 (save at DataCleaning.java:133) with 1 output partitions
[2025-10-08 18:01:59] INFO  DAGScheduler - Final stage: ResultStage 12 (save at DataCleaning.java:133)
[2025-10-08 18:01:59] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 18:01:59] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 18:01:59] INFO  DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[27] at save at DataCleaning.java:133), which has no missing parents
[2025-10-08 18:01:59] INFO  MemoryStore - Block broadcast_7 stored as values in memory (estimated size 213.2 KiB, free 2.2 GiB)
[2025-10-08 18:01:59] INFO  MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 77.1 KiB, free 2.2 GiB)
[2025-10-08 18:01:59] INFO  BlockManagerInfo - Added broadcast_7_piece0 in memory on DESKTOP-618L1DH:59177 (size: 77.1 KiB, free: 2.2 GiB)
[2025-10-08 18:01:59] INFO  SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-10-08 18:01:59] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[27] at save at DataCleaning.java:133) (first 15 tasks are for partitions Vector(0))
[2025-10-08 18:01:59] INFO  TaskSchedulerImpl - Adding task set 12.0 with 1 tasks resource profile 0
[2025-10-08 18:01:59] INFO  TaskSetManager - Starting task 0.0 in stage 12.0 (TID 15) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9121 bytes) 
[2025-10-08 18:01:59] INFO  Executor - Running task 0.0 in stage 12.0 (TID 15)
[2025-10-08 18:01:59] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 18:01:59] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 18:01:59] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:01:59] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 18:01:59] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 18:01:59] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:01:59] INFO  CodecConfig - Compression: SNAPPY
[2025-10-08 18:01:59] INFO  CodecConfig - Compression: SNAPPY
[2025-10-08 18:01:59] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-08 18:01:59] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "carrier",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary carrier (STRING);
  optional binary carrier_name (STRING);
}

       
[2025-10-08 18:01:59] INFO  CodeGenerator - Code generated in 7.8166 ms
[2025-10-08 18:01:59] INFO  JDBCRDD - closed connection
[2025-10-08 18:01:59] INFO  FileOutputCommitter - Saved output of task 'attempt_202510081801592246431090919604956_0012_m_000000_15' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/silver/cleaned_carrier_lookup/_temporary/0/task_202510081801592246431090919604956_0012_m_000000
[2025-10-08 18:01:59] INFO  SparkHadoopMapRedUtil - attempt_202510081801592246431090919604956_0012_m_000000_15: Committed. Elapsed time: 5 ms.
[2025-10-08 18:01:59] INFO  Executor - Finished task 0.0 in stage 12.0 (TID 15). 2484 bytes result sent to driver
[2025-10-08 18:01:59] INFO  TaskSetManager - Finished task 0.0 in stage 12.0 (TID 15) in 91 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 18:01:59] INFO  TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool 
[2025-10-08 18:01:59] INFO  DAGScheduler - ResultStage 12 (save at DataCleaning.java:133) finished in 0.122 s
[2025-10-08 18:01:59] INFO  DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 18:01:59] INFO  TaskSchedulerImpl - Killing all running tasks in stage 12: Stage finished
[2025-10-08 18:01:59] INFO  DAGScheduler - Job 7 finished: save at DataCleaning.java:133, took 0.126555 s
[2025-10-08 18:01:59] INFO  FileFormatWriter - Start to commit write Job f113cea8-5645-4547-a243-6a6a6be725e2.
[2025-10-08 18:01:59] INFO  FileFormatWriter - Write Job f113cea8-5645-4547-a243-6a6a6be725e2 committed. Elapsed time: 15 ms.
[2025-10-08 18:01:59] INFO  FileFormatWriter - Finished processing stats for write job f113cea8-5645-4547-a243-6a6a6be725e2.
[2025-10-08 18:01:59] INFO  DataCleaning - Overwriting DB Table: silver.cleaned_carrier_lookup
[2025-10-08 18:01:59] INFO  SparkContext - Starting job: save at DataCleaning.java:144
[2025-10-08 18:01:59] INFO  DAGScheduler - Got job 8 (save at DataCleaning.java:144) with 1 output partitions
[2025-10-08 18:01:59] INFO  DAGScheduler - Final stage: ResultStage 13 (save at DataCleaning.java:144)
[2025-10-08 18:01:59] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 18:01:59] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 18:01:59] INFO  DAGScheduler - Submitting ResultStage 13 (MapPartitionsRDD[32] at save at DataCleaning.java:144), which has no missing parents
[2025-10-08 18:01:59] INFO  MemoryStore - Block broadcast_8 stored as values in memory (estimated size 28.1 KiB, free 2.2 GiB)
[2025-10-08 18:01:59] INFO  MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.2 KiB, free 2.2 GiB)
[2025-10-08 18:01:59] INFO  BlockManagerInfo - Added broadcast_8_piece0 in memory on DESKTOP-618L1DH:59177 (size: 13.2 KiB, free: 2.2 GiB)
[2025-10-08 18:01:59] INFO  SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-10-08 18:01:59] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[32] at save at DataCleaning.java:144) (first 15 tasks are for partitions Vector(0))
[2025-10-08 18:01:59] INFO  TaskSchedulerImpl - Adding task set 13.0 with 1 tasks resource profile 0
[2025-10-08 18:01:59] INFO  TaskSetManager - Starting task 0.0 in stage 13.0 (TID 16) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) 
[2025-10-08 18:01:59] INFO  Executor - Running task 0.0 in stage 13.0 (TID 16)
[2025-10-08 18:01:59] INFO  CodeGenerator - Code generated in 9.8708 ms
[2025-10-08 18:01:59] INFO  JDBCRDD - closed connection
[2025-10-08 18:02:00] INFO  Executor - Finished task 0.0 in stage 13.0 (TID 16). 1273 bytes result sent to driver
[2025-10-08 18:02:00] INFO  TaskSetManager - Finished task 0.0 in stage 13.0 (TID 16) in 132 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 18:02:00] INFO  TaskSchedulerImpl - Removed TaskSet 13.0, whose tasks have all completed, from pool 
[2025-10-08 18:02:00] INFO  DAGScheduler - ResultStage 13 (save at DataCleaning.java:144) finished in 0.158 s
[2025-10-08 18:02:00] INFO  DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 18:02:00] INFO  TaskSchedulerImpl - Killing all running tasks in stage 13: Stage finished
[2025-10-08 18:02:00] INFO  DAGScheduler - Job 8 finished: save at DataCleaning.java:144, took 0.167419 s
[2025-10-08 18:02:00] INFO  DataCleaning - Loading from DB Table: bronze.airport_lookup
[2025-10-08 18:02:00] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_airport_lookup
[2025-10-08 18:02:00] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:02:00] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 18:02:00] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 18:02:00] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:02:00] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 18:02:00] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 18:02:00] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:02:00] INFO  CodeGenerator - Code generated in 15.9891 ms
[2025-10-08 18:02:00] INFO  SparkContext - Starting job: save at DataCleaning.java:133
[2025-10-08 18:02:00] INFO  DAGScheduler - Got job 9 (save at DataCleaning.java:133) with 1 output partitions
[2025-10-08 18:02:00] INFO  DAGScheduler - Final stage: ResultStage 14 (save at DataCleaning.java:133)
[2025-10-08 18:02:00] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 18:02:00] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 18:02:00] INFO  DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[36] at save at DataCleaning.java:133), which has no missing parents
[2025-10-08 18:02:00] INFO  MemoryStore - Block broadcast_9 stored as values in memory (estimated size 213.9 KiB, free 2.2 GiB)
[2025-10-08 18:02:00] INFO  MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 2.2 GiB)
[2025-10-08 18:02:00] INFO  BlockManagerInfo - Added broadcast_9_piece0 in memory on DESKTOP-618L1DH:59177 (size: 77.2 KiB, free: 2.2 GiB)
[2025-10-08 18:02:00] INFO  BlockManagerInfo - Removed broadcast_8_piece0 on DESKTOP-618L1DH:59177 in memory (size: 13.2 KiB, free: 2.2 GiB)
[2025-10-08 18:02:00] INFO  SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-10-08 18:02:00] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[36] at save at DataCleaning.java:133) (first 15 tasks are for partitions Vector(0))
[2025-10-08 18:02:00] INFO  TaskSchedulerImpl - Adding task set 14.0 with 1 tasks resource profile 0
[2025-10-08 18:02:00] INFO  TaskSetManager - Starting task 0.0 in stage 14.0 (TID 17) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9121 bytes) 
[2025-10-08 18:02:00] INFO  Executor - Running task 0.0 in stage 14.0 (TID 17)
[2025-10-08 18:02:00] INFO  BlockManagerInfo - Removed broadcast_5_piece0 on DESKTOP-618L1DH:59177 in memory (size: 29.1 KiB, free: 2.2 GiB)
[2025-10-08 18:02:00] INFO  BlockManagerInfo - Removed broadcast_6_piece0 on DESKTOP-618L1DH:59177 in memory (size: 5.9 KiB, free: 2.2 GiB)
[2025-10-08 18:02:00] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 18:02:00] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 18:02:00] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:02:00] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 18:02:00] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 18:02:00] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 18:02:00] INFO  CodecConfig - Compression: SNAPPY
[2025-10-08 18:02:00] INFO  CodecConfig - Compression: SNAPPY
[2025-10-08 18:02:00] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-08 18:02:00] INFO  BlockManagerInfo - Removed broadcast_7_piece0 on DESKTOP-618L1DH:59177 in memory (size: 77.1 KiB, free: 2.2 GiB)
[2025-10-08 18:02:00] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "iso_country",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "iata_code",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary iso_country (STRING);
  optional binary name (STRING);
  optional binary iata_code (STRING);
}

       
[2025-10-08 18:02:00] INFO  CodeGenerator - Code generated in 15.5137 ms
[2025-10-08 18:02:00] INFO  JDBCRDD - closed connection
[2025-10-08 18:02:00] INFO  FileOutputCommitter - Saved output of task 'attempt_202510081802001902913856316365808_0014_m_000000_17' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/silver/cleaned_airport_lookup/_temporary/0/task_202510081802001902913856316365808_0014_m_000000
[2025-10-08 18:02:00] INFO  SparkHadoopMapRedUtil - attempt_202510081802001902913856316365808_0014_m_000000_17: Committed. Elapsed time: 3 ms.
[2025-10-08 18:02:00] INFO  Executor - Finished task 0.0 in stage 14.0 (TID 17). 2484 bytes result sent to driver
[2025-10-08 18:02:00] INFO  TaskSetManager - Finished task 0.0 in stage 14.0 (TID 17) in 211 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 18:02:00] INFO  TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool 
[2025-10-08 18:02:00] INFO  DAGScheduler - ResultStage 14 (save at DataCleaning.java:133) finished in 0.260 s
[2025-10-08 18:02:00] INFO  DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 18:02:00] INFO  TaskSchedulerImpl - Killing all running tasks in stage 14: Stage finished
[2025-10-08 18:02:00] INFO  DAGScheduler - Job 9 finished: save at DataCleaning.java:133, took 0.271315 s
[2025-10-08 18:02:00] INFO  FileFormatWriter - Start to commit write Job 4961db13-4dbc-47d5-bc99-ab5d3702ce94.
[2025-10-08 18:02:00] INFO  FileFormatWriter - Write Job 4961db13-4dbc-47d5-bc99-ab5d3702ce94 committed. Elapsed time: 45 ms.
[2025-10-08 18:02:00] INFO  FileFormatWriter - Finished processing stats for write job 4961db13-4dbc-47d5-bc99-ab5d3702ce94.
[2025-10-08 18:02:00] INFO  DataCleaning - Overwriting DB Table: silver.cleaned_airport_lookup
[2025-10-08 18:02:00] INFO  SparkContext - Starting job: save at DataCleaning.java:144
[2025-10-08 18:02:00] INFO  DAGScheduler - Got job 10 (save at DataCleaning.java:144) with 1 output partitions
[2025-10-08 18:02:00] INFO  DAGScheduler - Final stage: ResultStage 15 (save at DataCleaning.java:144)
[2025-10-08 18:02:00] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 18:02:00] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 18:02:00] INFO  DAGScheduler - Submitting ResultStage 15 (MapPartitionsRDD[41] at save at DataCleaning.java:144), which has no missing parents
[2025-10-08 18:02:00] INFO  MemoryStore - Block broadcast_10 stored as values in memory (estimated size 29.2 KiB, free 2.2 GiB)
[2025-10-08 18:02:00] INFO  MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 2.2 GiB)
[2025-10-08 18:02:00] INFO  BlockManagerInfo - Added broadcast_10_piece0 in memory on DESKTOP-618L1DH:59177 (size: 13.4 KiB, free: 2.2 GiB)
[2025-10-08 18:02:00] INFO  SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1611
[2025-10-08 18:02:00] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[41] at save at DataCleaning.java:144) (first 15 tasks are for partitions Vector(0))
[2025-10-08 18:02:00] INFO  TaskSchedulerImpl - Adding task set 15.0 with 1 tasks resource profile 0
[2025-10-08 18:02:00] INFO  TaskSetManager - Starting task 0.0 in stage 15.0 (TID 18) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) 
[2025-10-08 18:02:00] INFO  Executor - Running task 0.0 in stage 15.0 (TID 18)
[2025-10-08 18:02:00] INFO  CodeGenerator - Code generated in 7.924 ms
[2025-10-08 18:02:01] INFO  JDBCRDD - closed connection
[2025-10-08 18:02:01] INFO  Executor - Finished task 0.0 in stage 15.0 (TID 18). 1230 bytes result sent to driver
[2025-10-08 18:02:01] INFO  TaskSetManager - Finished task 0.0 in stage 15.0 (TID 18) in 713 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 18:02:01] INFO  TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
[2025-10-08 18:02:01] INFO  DAGScheduler - ResultStage 15 (save at DataCleaning.java:144) finished in 0.733 s
[2025-10-08 18:02:01] INFO  DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 18:02:01] INFO  TaskSchedulerImpl - Killing all running tasks in stage 15: Stage finished
[2025-10-08 18:02:01] INFO  DAGScheduler - Job 10 finished: save at DataCleaning.java:144, took 0.742425 s
[2025-10-08 18:02:01] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 18:02:01] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 18:02:01] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-08 18:02:01] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-08 18:02:01] INFO  MemoryStore - MemoryStore cleared
[2025-10-08 18:02:01] INFO  BlockManager - BlockManager stopped
[2025-10-08 18:02:01] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-08 18:02:01] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-08 18:02:01] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-08 18:02:01] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-08 18:02:01] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-961c6b3b-e2c3-4177-aa63-9d106a44f748
[2025-10-08 18:02:13] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-08 18:02:13] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-08 18:02:13] INFO  SparkContext - Java version 11.0.27
[2025-10-08 18:02:13] INFO  ResourceUtils - ==============================================================
[2025-10-08 18:02:13] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-08 18:02:13] INFO  ResourceUtils - ==============================================================
[2025-10-08 18:02:13] INFO  SparkContext - Submitted application: Airline Delay Data Cleaning
[2025-10-08 18:02:13] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-08 18:02:13] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-08 18:02:13] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-08 18:02:13] INFO  SecurityManager - Changing view acls to: USER
[2025-10-08 18:02:13] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-08 18:02:13] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-08 18:02:13] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-08 18:02:13] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-08 18:02:14] INFO  Utils - Successfully started service 'sparkDriver' on port 60084.
[2025-10-08 18:02:14] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-08 18:02:14] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-08 18:02:14] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-08 18:02:14] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-08 18:02:14] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-08 18:02:14] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-3f33dfe4-32d2-467c-a79d-d1526f85bdd7
[2025-10-08 18:02:14] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-08 18:02:14] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-08 18:02:14] INFO  log - Logging initialized @2341ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-08 18:02:14] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-08 18:02:14] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-08 18:02:14] INFO  Server - Started @2466ms
[2025-10-08 18:02:14] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 18:02:14] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-08 18:02:14] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@46383a78{/,null,AVAILABLE,@Spark}
[2025-10-08 18:02:14] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-08 18:02:14] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-08 18:02:14] INFO  Executor - Java version 11.0.27
[2025-10-08 18:02:14] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-08 18:02:14] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@697173d9 for default.
[2025-10-08 18:02:14] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60132.
[2025-10-08 18:02:14] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:60132
[2025-10-08 18:02:14] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-08 18:02:14] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 60132, None)
[2025-10-08 18:02:15] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:60132 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 60132, None)
[2025-10-08 18:02:15] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 60132, None)
[2025-10-08 18:02:15] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 60132, None)
[2025-10-08 18:02:15] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@46383a78{/,null,STOPPED,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@49f3ff41{/jobs,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@30db5536{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@484149eb{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@61874b9d{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f2d014a{/stages,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@a7cf42f{/stages/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@54336976{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b7c80c6{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7499eac7{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@b9d018b{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79eeff87{/storage,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@8bd076a{/storage/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1378eea2{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66522ead{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@e91b4f4{/environment,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58ae402b{/environment/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43ac0a68{/executors,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3728a578{/executors/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de0641b{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a464fa3{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ccb85d6{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@259b85d6{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@488f3dd1{/static,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@327e5be5{/,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@566f1852{/api,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2349f14d{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7edb6fca{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2d2b6960{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-08 18:02:15] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66e17eff{/SQL,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1bbddada{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@68b7d0ef{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a070cf0{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-08 18:02:15] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@519c6fcc{/static/sql,null,AVAILABLE,@Spark}
[2025-10-08 18:02:16] INFO  DataCleaning - Loading from DB Table: bronze.raw_dataset
[2025-10-08 18:02:17] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 18:02:17] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 18:02:17] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-08 18:02:17] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-08 18:02:17] INFO  MemoryStore - MemoryStore cleared
[2025-10-08 18:02:17] INFO  BlockManager - BlockManager stopped
[2025-10-08 18:02:17] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-08 18:02:17] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-08 18:02:17] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-08 18:02:17] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_dataset
[2025-10-08 18:02:18] ERROR GlobalExceptionHandler - Exception in Failed to save dataset cleaned_dataset: None.get
java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:529) ~[scala-library-2.12.18.jar:?]
	at scala.None$.get(Option.scala:527) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.datasources.BasicWriteJobStatsTracker$.metrics(BasicWriteStatsTracker.scala:239) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics$(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics$lzycompute(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics$lzycompute(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:63) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.$anonfun$fromSparkPlan$3(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at scala.collection.immutable.List.map(List.scala:293) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:120) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.spark.DataCleaning.save(DataCleaning.java:133) [classes/:?]
	at org.spark.DataCleaning.main(DataCleaning.java:41) [classes/:?]
[2025-10-08 18:02:18] ERROR GlobalExceptionHandler - Exception in Data cleaning failed: java.util.NoSuchElementException: None.get
java.lang.RuntimeException: java.util.NoSuchElementException: None.get
	at org.exception.GlobalExceptionHandler.handle(GlobalExceptionHandler.java:11) [classes/:?]
	at org.spark.DataCleaning.save(DataCleaning.java:146) ~[classes/:?]
	at org.spark.DataCleaning.main(DataCleaning.java:41) [classes/:?]
Caused by: java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:529) ~[scala-library-2.12.18.jar:?]
	at scala.None$.get(Option.scala:527) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.datasources.BasicWriteJobStatsTracker$.metrics(BasicWriteStatsTracker.scala:239) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics$(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics$lzycompute(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics$lzycompute(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:63) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.$anonfun$fromSparkPlan$3(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at scala.collection.immutable.List.map(List.scala:293) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:120) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.spark.DataCleaning.save(DataCleaning.java:133) ~[classes/:?]
	... 1 more
[2025-10-08 18:02:18] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 18:02:18] INFO  SparkContext - SparkContext already stopped.
[2025-10-08 18:02:18] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-08 18:02:18] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-6a2feb73-b597-463e-ba21-2199edd26ac6
[2025-10-08 18:09:33] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-08 18:09:33] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-08 18:09:33] INFO  SparkContext - Java version 11.0.27
[2025-10-08 18:09:34] INFO  ResourceUtils - ==============================================================
[2025-10-08 18:09:34] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-08 18:09:34] INFO  ResourceUtils - ==============================================================
[2025-10-08 18:09:34] INFO  SparkContext - Submitted application: Airline Delay Data Cleaning
[2025-10-08 18:09:34] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-08 18:09:34] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-08 18:09:34] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-08 18:09:34] INFO  SecurityManager - Changing view acls to: USER
[2025-10-08 18:09:34] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-08 18:09:34] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-08 18:09:34] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-08 18:09:34] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-08 18:09:34] INFO  Utils - Successfully started service 'sparkDriver' on port 50834.
[2025-10-08 18:09:34] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-08 18:09:34] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-08 18:09:34] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-08 18:09:34] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-08 18:09:34] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-08 18:09:34] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-b7c14e3e-3495-4764-ad55-1665497f0fdc
[2025-10-08 18:09:34] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-08 18:09:34] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-08 18:09:34] INFO  log - Logging initialized @2349ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-08 18:09:35] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-08 18:09:35] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-08 18:09:35] INFO  Server - Started @2478ms
[2025-10-08 18:09:35] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 18:09:35] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@244418a{/,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-08 18:09:35] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-08 18:09:35] INFO  Executor - Java version 11.0.27
[2025-10-08 18:09:35] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-08 18:09:35] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3d90eeb3 for default.
[2025-10-08 18:09:35] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50881.
[2025-10-08 18:09:35] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:50881
[2025-10-08 18:09:35] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-08 18:09:35] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 50881, None)
[2025-10-08 18:09:35] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:50881 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 50881, None)
[2025-10-08 18:09:35] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 50881, None)
[2025-10-08 18:09:35] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 50881, None)
[2025-10-08 18:09:35] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@244418a{/,null,STOPPED,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@30db5536{/jobs,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@136ccbfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@61874b9d{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f2d014a{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@a7cf42f{/stages,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@28e0e464{/stages/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b7c80c6{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7499eac7{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@b9d018b{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79eeff87{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@8bd076a{/storage,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1378eea2{/storage/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66522ead{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@e91b4f4{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58ae402b{/environment,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43ac0a68{/environment/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3728a578{/executors,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de0641b{/executors/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a464fa3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ccb85d6{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@259b85d6{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@488f3dd1{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7bc58891{/static,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@566f1852{/,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e4389ed{/api,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7edb6fca{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@716185fe{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@234c5e41{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-08 18:09:35] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1bbddada{/SQL,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@721d5b74{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a070cf0{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@202d9236{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-08 18:09:35] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7ecda95b{/static/sql,null,AVAILABLE,@Spark}
[2025-10-08 18:09:36] INFO  DataCleaning - Loading from DB Table: bronze.raw_dataset
[2025-10-08 18:09:37] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 18:09:37] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 18:09:37] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-08 18:09:37] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-08 18:09:37] INFO  MemoryStore - MemoryStore cleared
[2025-10-08 18:09:37] INFO  BlockManager - BlockManager stopped
[2025-10-08 18:09:37] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-08 18:09:37] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-08 18:09:37] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-08 18:09:37] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_dataset
[2025-10-08 18:09:38] ERROR GlobalExceptionHandler - Exception in Failed to save dataset cleaned_dataset: None.get
java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:529) ~[scala-library-2.12.18.jar:?]
	at scala.None$.get(Option.scala:527) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.datasources.BasicWriteJobStatsTracker$.metrics(BasicWriteStatsTracker.scala:239) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics$(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics$lzycompute(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics$lzycompute(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:63) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.$anonfun$fromSparkPlan$3(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at scala.collection.immutable.List.map(List.scala:293) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:120) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.spark.DataCleaning.save(DataCleaning.java:133) [classes/:?]
	at org.spark.DataCleaning.main(DataCleaning.java:41) [classes/:?]
[2025-10-08 18:09:38] ERROR GlobalExceptionHandler - Exception in Data cleaning failed: java.util.NoSuchElementException: None.get
java.lang.RuntimeException: java.util.NoSuchElementException: None.get
	at org.exception.GlobalExceptionHandler.handle(GlobalExceptionHandler.java:11) [classes/:?]
	at org.spark.DataCleaning.save(DataCleaning.java:146) ~[classes/:?]
	at org.spark.DataCleaning.main(DataCleaning.java:41) [classes/:?]
Caused by: java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:529) ~[scala-library-2.12.18.jar:?]
	at scala.None$.get(Option.scala:527) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.datasources.BasicWriteJobStatsTracker$.metrics(BasicWriteStatsTracker.scala:239) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics$(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics$lzycompute(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics$lzycompute(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:63) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.$anonfun$fromSparkPlan$3(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at scala.collection.immutable.List.map(List.scala:293) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:120) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.spark.DataCleaning.save(DataCleaning.java:133) ~[classes/:?]
	... 1 more
[2025-10-08 18:09:38] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 18:09:38] INFO  SparkContext - SparkContext already stopped.
[2025-10-08 18:09:38] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-08 18:09:38] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-1674ae09-4771-4c66-a6e7-3dc00f47c7f5
[2025-10-08 18:10:07] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-08 18:10:07] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-08 18:10:07] INFO  SparkContext - Java version 11.0.27
[2025-10-08 18:10:07] INFO  ResourceUtils - ==============================================================
[2025-10-08 18:10:07] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-08 18:10:07] INFO  ResourceUtils - ==============================================================
[2025-10-08 18:10:07] INFO  SparkContext - Submitted application: Airline Delay Data Cleaning
[2025-10-08 18:10:07] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-08 18:10:07] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-08 18:10:07] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-08 18:10:07] INFO  SecurityManager - Changing view acls to: USER
[2025-10-08 18:10:07] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-08 18:10:07] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-08 18:10:07] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-08 18:10:07] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-08 18:10:08] INFO  Utils - Successfully started service 'sparkDriver' on port 54546.
[2025-10-08 18:10:08] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-08 18:10:08] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-08 18:10:08] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-08 18:10:08] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-08 18:10:08] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-08 18:10:08] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-210af3fa-7146-4cc3-a7d6-dd6018b47a35
[2025-10-08 18:10:08] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-08 18:10:08] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-08 18:10:08] INFO  log - Logging initialized @2720ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-08 18:10:08] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-08 18:10:08] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-08 18:10:08] INFO  Server - Started @2898ms
[2025-10-08 18:10:08] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 18:10:08] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@244418a{/,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-08 18:10:08] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-08 18:10:08] INFO  Executor - Java version 11.0.27
[2025-10-08 18:10:08] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-08 18:10:08] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3d90eeb3 for default.
[2025-10-08 18:10:08] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54593.
[2025-10-08 18:10:08] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:54593
[2025-10-08 18:10:08] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-08 18:10:08] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 54593, None)
[2025-10-08 18:10:08] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:54593 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 54593, None)
[2025-10-08 18:10:08] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 54593, None)
[2025-10-08 18:10:08] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 54593, None)
[2025-10-08 18:10:08] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@244418a{/,null,STOPPED,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@30db5536{/jobs,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@136ccbfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@61874b9d{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f2d014a{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@a7cf42f{/stages,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@28e0e464{/stages/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b7c80c6{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7499eac7{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@b9d018b{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79eeff87{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@8bd076a{/storage,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1378eea2{/storage/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66522ead{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@e91b4f4{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58ae402b{/environment,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43ac0a68{/environment/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3728a578{/executors,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de0641b{/executors/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a464fa3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ccb85d6{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@259b85d6{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@488f3dd1{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7bc58891{/static,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@566f1852{/,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e4389ed{/api,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7edb6fca{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@716185fe{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-08 18:10:08] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@234c5e41{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:09] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-08 18:10:09] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-08 18:10:09] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1bbddada{/SQL,null,AVAILABLE,@Spark}
[2025-10-08 18:10:09] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@721d5b74{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:09] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a070cf0{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-08 18:10:09] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@202d9236{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-08 18:10:09] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7ecda95b{/static/sql,null,AVAILABLE,@Spark}
[2025-10-08 18:10:09] INFO  DataCleaning - Loading from DB Table: bronze.raw_dataset
[2025-10-08 18:10:11] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 18:10:11] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 18:10:11] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-08 18:10:11] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-08 18:10:11] INFO  MemoryStore - MemoryStore cleared
[2025-10-08 18:10:11] INFO  BlockManager - BlockManager stopped
[2025-10-08 18:10:11] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-08 18:10:11] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-08 18:10:11] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-08 18:10:11] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_dataset
[2025-10-08 18:10:11] ERROR GlobalExceptionHandler - Exception in Failed to save dataset cleaned_dataset: None.get
java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:529) ~[scala-library-2.12.18.jar:?]
	at scala.None$.get(Option.scala:527) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.datasources.BasicWriteJobStatsTracker$.metrics(BasicWriteStatsTracker.scala:239) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics$(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics$lzycompute(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics$lzycompute(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:63) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.$anonfun$fromSparkPlan$3(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at scala.collection.immutable.List.map(List.scala:293) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:120) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.spark.DataCleaning.save(DataCleaning.java:133) [classes/:?]
	at org.spark.DataCleaning.main(DataCleaning.java:41) [classes/:?]
[2025-10-08 18:10:11] ERROR GlobalExceptionHandler - Exception in Data cleaning failed: java.util.NoSuchElementException: None.get
java.lang.RuntimeException: java.util.NoSuchElementException: None.get
	at org.exception.GlobalExceptionHandler.handle(GlobalExceptionHandler.java:11) [classes/:?]
	at org.spark.DataCleaning.save(DataCleaning.java:146) ~[classes/:?]
	at org.spark.DataCleaning.main(DataCleaning.java:41) [classes/:?]
Caused by: java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:529) ~[scala-library-2.12.18.jar:?]
	at scala.None$.get(Option.scala:527) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.datasources.BasicWriteJobStatsTracker$.metrics(BasicWriteStatsTracker.scala:239) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics$(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics$lzycompute(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics$lzycompute(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:63) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.$anonfun$fromSparkPlan$3(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at scala.collection.immutable.List.map(List.scala:293) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:120) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.spark.DataCleaning.save(DataCleaning.java:133) ~[classes/:?]
	... 1 more
[2025-10-08 18:10:11] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 18:10:11] INFO  SparkContext - SparkContext already stopped.
[2025-10-08 18:10:11] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-08 18:10:11] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-0d27dbfe-8aa4-488e-bf7f-6f9ff4acc090
[2025-10-08 19:51:41] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-08 19:51:41] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-08 19:51:41] INFO  SparkContext - Java version 11.0.27
[2025-10-08 19:51:41] INFO  ResourceUtils - ==============================================================
[2025-10-08 19:51:41] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-08 19:51:41] INFO  ResourceUtils - ==============================================================
[2025-10-08 19:51:41] INFO  SparkContext - Submitted application: Airline Delay Data Cleaning
[2025-10-08 19:51:41] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-08 19:51:41] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-08 19:51:41] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-08 19:51:41] INFO  SecurityManager - Changing view acls to: USER
[2025-10-08 19:51:41] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-08 19:51:41] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-08 19:51:41] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-08 19:51:41] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-08 19:51:42] INFO  Utils - Successfully started service 'sparkDriver' on port 56703.
[2025-10-08 19:51:42] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-08 19:51:42] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-08 19:51:42] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-08 19:51:42] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-08 19:51:42] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-08 19:51:42] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-a811e9dd-076c-4880-b57e-de17c1aebe5c
[2025-10-08 19:51:42] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-08 19:51:42] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-08 19:51:42] INFO  log - Logging initialized @2645ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-08 19:51:42] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-08 19:51:42] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-08 19:51:42] INFO  Server - Started @2774ms
[2025-10-08 19:51:42] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 19:51:42] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-08 19:51:42] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@244418a{/,null,AVAILABLE,@Spark}
[2025-10-08 19:51:42] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-08 19:51:42] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-08 19:51:42] INFO  Executor - Java version 11.0.27
[2025-10-08 19:51:42] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-08 19:51:42] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3d90eeb3 for default.
[2025-10-08 19:51:42] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56750.
[2025-10-08 19:51:42] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:56750
[2025-10-08 19:51:42] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-08 19:51:42] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 56750, None)
[2025-10-08 19:51:42] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:56750 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 56750, None)
[2025-10-08 19:51:42] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 56750, None)
[2025-10-08 19:51:42] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 56750, None)
[2025-10-08 19:51:43] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@244418a{/,null,STOPPED,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@30db5536{/jobs,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@136ccbfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@61874b9d{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f2d014a{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@a7cf42f{/stages,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@28e0e464{/stages/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b7c80c6{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7499eac7{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@b9d018b{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79eeff87{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@8bd076a{/storage,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1378eea2{/storage/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66522ead{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@e91b4f4{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58ae402b{/environment,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43ac0a68{/environment/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3728a578{/executors,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de0641b{/executors/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a464fa3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ccb85d6{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@259b85d6{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@488f3dd1{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7bc58891{/static,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@566f1852{/,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e4389ed{/api,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7edb6fca{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@716185fe{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@234c5e41{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-08 19:51:43] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1bbddada{/SQL,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@721d5b74{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a070cf0{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@202d9236{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7ecda95b{/static/sql,null,AVAILABLE,@Spark}
[2025-10-08 19:51:43] INFO  DataCleaning - Loading from DB Table: bronze.raw_dataset
[2025-10-08 19:51:45] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 19:51:45] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 19:51:45] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-08 19:51:45] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-08 19:51:45] INFO  MemoryStore - MemoryStore cleared
[2025-10-08 19:51:45] INFO  BlockManager - BlockManager stopped
[2025-10-08 19:51:45] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-08 19:51:45] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-08 19:51:45] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-08 19:51:45] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_dataset
[2025-10-08 19:51:46] ERROR GlobalExceptionHandler - Exception in Failed to save dataset cleaned_dataset: None.get
java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:529) ~[scala-library-2.12.18.jar:?]
	at scala.None$.get(Option.scala:527) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.datasources.BasicWriteJobStatsTracker$.metrics(BasicWriteStatsTracker.scala:239) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics$(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics$lzycompute(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics$lzycompute(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:63) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.$anonfun$fromSparkPlan$3(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at scala.collection.immutable.List.map(List.scala:293) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:120) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.spark.DataCleaning.save(DataCleaning.java:133) [classes/:?]
	at org.spark.DataCleaning.main(DataCleaning.java:41) [classes/:?]
[2025-10-08 19:51:46] ERROR GlobalExceptionHandler - Exception in Data cleaning failed: java.util.NoSuchElementException: None.get
java.lang.RuntimeException: java.util.NoSuchElementException: None.get
	at org.exception.GlobalExceptionHandler.handle(GlobalExceptionHandler.java:11) [classes/:?]
	at org.spark.DataCleaning.save(DataCleaning.java:146) ~[classes/:?]
	at org.spark.DataCleaning.main(DataCleaning.java:41) [classes/:?]
Caused by: java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:529) ~[scala-library-2.12.18.jar:?]
	at scala.None$.get(Option.scala:527) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.datasources.BasicWriteJobStatsTracker$.metrics(BasicWriteStatsTracker.scala:239) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommand.metrics$(DataWritingCommand.scala:55) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics$lzycompute(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.metrics(InsertIntoHadoopFsRelationCommand.scala:47) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics$lzycompute(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics(commands.scala:109) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:63) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SparkPlanInfo$.$anonfun$fromSparkPlan$3(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at scala.collection.immutable.List.map(List.scala:293) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:75) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:120) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) ~[spark-sql-api_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) ~[spark-catalyst_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243) ~[spark-sql_2.12-3.5.6.jar:3.5.6]
	at org.spark.DataCleaning.save(DataCleaning.java:133) ~[classes/:?]
	... 1 more
[2025-10-08 19:51:46] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 19:51:46] INFO  SparkContext - SparkContext already stopped.
[2025-10-08 19:51:46] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-08 19:51:46] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-c3407001-80e6-4bf7-a99d-2caea9939ae4
[2025-10-08 19:52:10] INFO  SparkContext - Running Spark version 3.5.6
[2025-10-08 19:52:10] INFO  SparkContext - OS info Windows 11, 10.0, amd64
[2025-10-08 19:52:10] INFO  SparkContext - Java version 11.0.27
[2025-10-08 19:52:10] INFO  ResourceUtils - ==============================================================
[2025-10-08 19:52:10] INFO  ResourceUtils - No custom resources configured for spark.driver.
[2025-10-08 19:52:10] INFO  ResourceUtils - ==============================================================
[2025-10-08 19:52:10] INFO  SparkContext - Submitted application: Airline Delay Data Cleaning
[2025-10-08 19:52:10] INFO  ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-10-08 19:52:10] INFO  ResourceProfile - Limiting resource is cpu
[2025-10-08 19:52:10] INFO  ResourceProfileManager - Added ResourceProfile id: 0
[2025-10-08 19:52:10] INFO  SecurityManager - Changing view acls to: USER
[2025-10-08 19:52:10] INFO  SecurityManager - Changing modify acls to: USER
[2025-10-08 19:52:10] INFO  SecurityManager - Changing view acls groups to: 
[2025-10-08 19:52:10] INFO  SecurityManager - Changing modify acls groups to: 
[2025-10-08 19:52:10] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: USER; groups with view permissions: EMPTY; users with modify permissions: USER; groups with modify permissions: EMPTY
[2025-10-08 19:52:10] INFO  Utils - Successfully started service 'sparkDriver' on port 56791.
[2025-10-08 19:52:10] INFO  SparkEnv - Registering MapOutputTracker
[2025-10-08 19:52:10] INFO  SparkEnv - Registering BlockManagerMaster
[2025-10-08 19:52:10] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-10-08 19:52:10] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
[2025-10-08 19:52:10] INFO  SparkEnv - Registering BlockManagerMasterHeartbeat
[2025-10-08 19:52:10] INFO  DiskBlockManager - Created local directory at C:\Users\USER\AppData\Local\Temp\blockmgr-f3e5e3dd-fdeb-4fd5-92dc-5fabd0991082
[2025-10-08 19:52:10] INFO  MemoryStore - MemoryStore started with capacity 2.2 GiB
[2025-10-08 19:52:10] INFO  SparkEnv - Registering OutputCommitCoordinator
[2025-10-08 19:52:11] INFO  log - Logging initialized @2599ms to org.sparkproject.jetty.util.log.Slf4jLog
[2025-10-08 19:52:11] INFO  JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
[2025-10-08 19:52:11] INFO  Server - jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 11.0.27+8-LTS-232
[2025-10-08 19:52:11] INFO  Server - Started @2717ms
[2025-10-08 19:52:11] INFO  AbstractConnector - Started ServerConnector@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 19:52:11] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@244418a{/,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  Executor - Starting executor ID driver on host DESKTOP-618L1DH
[2025-10-08 19:52:11] INFO  Executor - OS info Windows 11, 10.0, amd64
[2025-10-08 19:52:11] INFO  Executor - Java version 11.0.27
[2025-10-08 19:52:11] INFO  Executor - Starting executor with user classpath (userClassPathFirst = false): ''
[2025-10-08 19:52:11] INFO  Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3d90eeb3 for default.
[2025-10-08 19:52:11] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56838.
[2025-10-08 19:52:11] INFO  NettyBlockTransferService - Server created on DESKTOP-618L1DH:56838
[2025-10-08 19:52:11] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-10-08 19:52:11] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 56838, None)
[2025-10-08 19:52:11] INFO  BlockManagerMasterEndpoint - Registering block manager DESKTOP-618L1DH:56838 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-618L1DH, 56838, None)
[2025-10-08 19:52:11] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-618L1DH, 56838, None)
[2025-10-08 19:52:11] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-618L1DH, 56838, None)
[2025-10-08 19:52:11] INFO  ContextHandler - Stopped o.s.j.s.ServletContextHandler@244418a{/,null,STOPPED,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@30db5536{/jobs,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@136ccbfe{/jobs/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@61874b9d{/jobs/job,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f2d014a{/jobs/job/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@a7cf42f{/stages,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@28e0e464{/stages/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b7c80c6{/stages/stage,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7499eac7{/stages/stage/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@b9d018b{/stages/pool,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79eeff87{/stages/pool/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@8bd076a{/storage,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1378eea2{/storage/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66522ead{/storage/rdd,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@e91b4f4{/storage/rdd/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58ae402b{/environment,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43ac0a68{/environment/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3728a578{/executors,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1de0641b{/executors/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a464fa3{/executors/threadDump,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ccb85d6{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@259b85d6{/executors/heapHistogram,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@488f3dd1{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7bc58891{/static,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@566f1852{/,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e4389ed{/api,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7edb6fca{/jobs/job/kill,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@716185fe{/stages/stage/kill,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@234c5e41{/metrics/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  DataCleaning - Loading from DB Table: bronze.raw_dataset
[2025-10-08 19:52:11] INFO  SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-10-08 19:52:11] INFO  SharedState - Warehouse path is 'file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/spark-warehouse'.
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@432af457{/SQL,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@519c6fcc{/SQL/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@713a35c5{/SQL/execution,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@11787b64{/SQL/execution/json,null,AVAILABLE,@Spark}
[2025-10-08 19:52:11] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6b321262{/static/sql,null,AVAILABLE,@Spark}
[2025-10-08 19:52:13] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_dataset
[2025-10-08 19:52:15] INFO  CodeGenerator - Code generated in 355.8686 ms
[2025-10-08 19:52:15] INFO  DAGScheduler - Registering RDD 2 (save at DataCleaning.java:132) as input to shuffle 0
[2025-10-08 19:52:15] INFO  DAGScheduler - Got map stage job 0 (save at DataCleaning.java:132) with 1 output partitions
[2025-10-08 19:52:15] INFO  DAGScheduler - Final stage: ShuffleMapStage 0 (save at DataCleaning.java:132)
[2025-10-08 19:52:15] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 19:52:15] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 19:52:15] INFO  DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at save at DataCleaning.java:132), which has no missing parents
[2025-10-08 19:52:15] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 75.7 KiB, free 2.2 GiB)
[2025-10-08 19:52:15] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-08 19:52:15] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on DESKTOP-618L1DH:56838 (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-08 19:52:15] INFO  SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1611
[2025-10-08 19:52:15] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at save at DataCleaning.java:132) (first 15 tasks are for partitions Vector(0))
[2025-10-08 19:52:15] INFO  TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
[2025-10-08 19:52:15] INFO  TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-08 19:52:15] INFO  Executor - Running task 0.0 in stage 0.0 (TID 0)
[2025-10-08 19:52:16] INFO  CodeGenerator - Code generated in 78.7401 ms
[2025-10-08 19:52:16] INFO  CodeGenerator - Code generated in 26.5175 ms
[2025-10-08 19:52:16] INFO  CodeGenerator - Code generated in 5.3087 ms
[2025-10-08 19:52:16] INFO  CodeGenerator - Code generated in 15.4091 ms
[2025-10-08 19:52:16] INFO  JDBCRDD - closed connection
[2025-10-08 19:52:17] INFO  Executor - Finished task 0.0 in stage 0.0 (TID 0). 2593 bytes result sent to driver
[2025-10-08 19:52:17] INFO  TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1416 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 19:52:17] INFO  TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[2025-10-08 19:52:17] INFO  DAGScheduler - ShuffleMapStage 0 (save at DataCleaning.java:132) finished in 1.691 s
[2025-10-08 19:52:17] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-08 19:52:17] INFO  DAGScheduler - running: Set()
[2025-10-08 19:52:17] INFO  DAGScheduler - waiting: Set()
[2025-10-08 19:52:17] INFO  DAGScheduler - failed: Set()
[2025-10-08 19:52:17] INFO  ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-08 19:52:17] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:17] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 19:52:17] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 19:52:17] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:17] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 19:52:17] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 19:52:17] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:17] INFO  CodeGenerator - Code generated in 75.2318 ms
[2025-10-08 19:52:17] INFO  SparkContext - Starting job: save at DataCleaning.java:132
[2025-10-08 19:52:17] INFO  DAGScheduler - Got job 1 (save at DataCleaning.java:132) with 1 output partitions
[2025-10-08 19:52:17] INFO  DAGScheduler - Final stage: ResultStage 2 (save at DataCleaning.java:132)
[2025-10-08 19:52:17] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
[2025-10-08 19:52:17] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 19:52:17] INFO  DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[6] at save at DataCleaning.java:132), which has no missing parents
[2025-10-08 19:52:17] INFO  MemoryStore - Block broadcast_1 stored as values in memory (estimated size 288.9 KiB, free 2.2 GiB)
[2025-10-08 19:52:17] INFO  MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 102.8 KiB, free 2.2 GiB)
[2025-10-08 19:52:17] INFO  BlockManagerInfo - Added broadcast_1_piece0 in memory on DESKTOP-618L1DH:56838 (size: 102.8 KiB, free: 2.2 GiB)
[2025-10-08 19:52:17] INFO  SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1611
[2025-10-08 19:52:17] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at save at DataCleaning.java:132) (first 15 tasks are for partitions Vector(0))
[2025-10-08 19:52:17] INFO  TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
[2025-10-08 19:52:17] INFO  TaskSetManager - Starting task 0.0 in stage 2.0 (TID 1) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 9387 bytes) 
[2025-10-08 19:52:17] INFO  Executor - Running task 0.0 in stage 2.0 (TID 1)
[2025-10-08 19:52:17] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 19:52:17] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 19:52:17] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:17] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 19:52:17] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 19:52:17] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:17] INFO  CodecConfig - Compression: SNAPPY
[2025-10-08 19:52:17] INFO  CodecConfig - Compression: SNAPPY
[2025-10-08 19:52:17] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-08 19:52:17] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "year",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "month",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "airport",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "isSigned" : false,
      "scale" : 0
    }
  }, {
    "name" : "airport_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_flights",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "arr_del15",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "weather_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "nas_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "security_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "late_aircraft_ct",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_cancelled",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_diverted",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "arr_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "carrier_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "weather_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "nas_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "security_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "late_aircraft_delay",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "isSigned" : true,
      "scale" : 0
    }
  }, {
    "name" : "date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 year;
  optional int32 month;
  optional binary carrier (STRING);
  optional binary carrier_name (STRING);
  optional binary airport (STRING);
  optional binary airport_name (STRING);
  optional int32 arr_flights;
  optional double arr_del15;
  optional double carrier_ct;
  optional double weather_ct;
  optional double nas_ct;
  optional double security_ct;
  optional double late_aircraft_ct;
  optional double arr_cancelled;
  optional double arr_diverted;
  optional double arr_delay;
  optional double carrier_delay;
  optional double weather_delay;
  optional double nas_delay;
  optional double security_delay;
  optional double late_aircraft_delay;
  optional int32 date (DATE);
}

       
[2025-10-08 19:52:18] INFO  CodecPool - Got brand-new compressor [.snappy]
[2025-10-08 19:52:18] INFO  ShuffleBlockFetcherIterator - Getting 1 (1055.0 KiB) non-empty blocks including 1 (1055.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:18] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 11 ms
[2025-10-08 19:52:18] INFO  CodeGenerator - Code generated in 41.8477 ms
[2025-10-08 19:52:18] INFO  ShuffleBlockFetcherIterator - Getting 1 (1053.2 KiB) non-empty blocks including 1 (1053.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:18] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-08 19:52:18] INFO  ShuffleBlockFetcherIterator - Getting 1 (1035.9 KiB) non-empty blocks including 1 (1035.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:18] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-08 19:52:19] INFO  ShuffleBlockFetcherIterator - Getting 1 (1031.9 KiB) non-empty blocks including 1 (1031.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:19] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-08 19:52:19] INFO  ShuffleBlockFetcherIterator - Getting 1 (1639.8 KiB) non-empty blocks including 1 (1639.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:19] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
[2025-10-08 19:52:19] INFO  FileOutputCommitter - Saved output of task 'attempt_202510081952174369743696587039413_0002_m_000000_1' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/silver/cleaned_dataset/_temporary/0/task_202510081952174369743696587039413_0002_m_000000
[2025-10-08 19:52:19] INFO  SparkHadoopMapRedUtil - attempt_202510081952174369743696587039413_0002_m_000000_1: Committed. Elapsed time: 1 ms.
[2025-10-08 19:52:19] INFO  Executor - Finished task 0.0 in stage 2.0 (TID 1). 6005 bytes result sent to driver
[2025-10-08 19:52:19] INFO  TaskSetManager - Finished task 0.0 in stage 2.0 (TID 1) in 1790 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 19:52:19] INFO  TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[2025-10-08 19:52:19] INFO  DAGScheduler - ResultStage 2 (save at DataCleaning.java:132) finished in 1.843 s
[2025-10-08 19:52:19] INFO  DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 19:52:19] INFO  TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
[2025-10-08 19:52:19] INFO  DAGScheduler - Job 1 finished: save at DataCleaning.java:132, took 1.855162 s
[2025-10-08 19:52:19] INFO  FileFormatWriter - Start to commit write Job 8f82056f-8e67-48f4-8014-653a9f0d37a3.
[2025-10-08 19:52:19] INFO  FileFormatWriter - Write Job 8f82056f-8e67-48f4-8014-653a9f0d37a3 committed. Elapsed time: 17 ms.
[2025-10-08 19:52:19] INFO  FileFormatWriter - Finished processing stats for write job 8f82056f-8e67-48f4-8014-653a9f0d37a3.
[2025-10-08 19:52:19] INFO  DataCleaning - Overwriting DB Table: silver.cleaned_dataset
[2025-10-08 19:52:19] WARN  SparkStringUtils - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2025-10-08 19:52:19] INFO  DAGScheduler - Registering RDD 9 (save at DataCleaning.java:143) as input to shuffle 1
[2025-10-08 19:52:19] INFO  DAGScheduler - Got map stage job 2 (save at DataCleaning.java:143) with 1 output partitions
[2025-10-08 19:52:19] INFO  DAGScheduler - Final stage: ShuffleMapStage 3 (save at DataCleaning.java:143)
[2025-10-08 19:52:19] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 19:52:19] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 19:52:19] INFO  DAGScheduler - Submitting ShuffleMapStage 3 (MapPartitionsRDD[9] at save at DataCleaning.java:143), which has no missing parents
[2025-10-08 19:52:19] INFO  MemoryStore - Block broadcast_2 stored as values in memory (estimated size 75.7 KiB, free 2.2 GiB)
[2025-10-08 19:52:19] INFO  MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-08 19:52:19] INFO  BlockManagerInfo - Added broadcast_2_piece0 in memory on DESKTOP-618L1DH:56838 (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-08 19:52:19] INFO  SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1611
[2025-10-08 19:52:19] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[9] at save at DataCleaning.java:143) (first 15 tasks are for partitions Vector(0))
[2025-10-08 19:52:19] INFO  TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
[2025-10-08 19:52:19] INFO  TaskSetManager - Starting task 0.0 in stage 3.0 (TID 2) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-08 19:52:19] INFO  Executor - Running task 0.0 in stage 3.0 (TID 2)
[2025-10-08 19:52:20] INFO  BlockManagerInfo - Removed broadcast_1_piece0 on DESKTOP-618L1DH:56838 in memory (size: 102.8 KiB, free: 2.2 GiB)
[2025-10-08 19:52:20] INFO  JDBCRDD - closed connection
[2025-10-08 19:52:20] INFO  Executor - Finished task 0.0 in stage 3.0 (TID 2). 2550 bytes result sent to driver
[2025-10-08 19:52:20] INFO  TaskSetManager - Finished task 0.0 in stage 3.0 (TID 2) in 761 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 19:52:20] INFO  TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[2025-10-08 19:52:20] INFO  DAGScheduler - ShuffleMapStage 3 (save at DataCleaning.java:143) finished in 0.775 s
[2025-10-08 19:52:20] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-08 19:52:20] INFO  DAGScheduler - running: Set()
[2025-10-08 19:52:20] INFO  DAGScheduler - waiting: Set()
[2025-10-08 19:52:20] INFO  DAGScheduler - failed: Set()
[2025-10-08 19:52:20] INFO  ShufflePartitionsUtil - For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-08 19:52:20] INFO  SparkContext - Starting job: save at DataCleaning.java:143
[2025-10-08 19:52:20] INFO  DAGScheduler - Got job 3 (save at DataCleaning.java:143) with 5 output partitions
[2025-10-08 19:52:20] INFO  DAGScheduler - Final stage: ResultStage 5 (save at DataCleaning.java:143)
[2025-10-08 19:52:20] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 4)
[2025-10-08 19:52:20] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 19:52:20] INFO  DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[14] at save at DataCleaning.java:143), which has no missing parents
[2025-10-08 19:52:20] INFO  MemoryStore - Block broadcast_3 stored as values in memory (estimated size 95.5 KiB, free 2.2 GiB)
[2025-10-08 19:52:20] INFO  MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 2.2 GiB)
[2025-10-08 19:52:20] INFO  BlockManagerInfo - Added broadcast_3_piece0 in memory on DESKTOP-618L1DH:56838 (size: 34.8 KiB, free: 2.2 GiB)
[2025-10-08 19:52:20] INFO  SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1611
[2025-10-08 19:52:20] INFO  DAGScheduler - Submitting 5 missing tasks from ResultStage 5 (MapPartitionsRDD[14] at save at DataCleaning.java:143) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
[2025-10-08 19:52:20] INFO  TaskSchedulerImpl - Adding task set 5.0 with 5 tasks resource profile 0
[2025-10-08 19:52:20] INFO  TaskSetManager - Starting task 0.0 in stage 5.0 (TID 3) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-08 19:52:20] INFO  TaskSetManager - Starting task 1.0 in stage 5.0 (TID 4) (DESKTOP-618L1DH, executor driver, partition 1, NODE_LOCAL, 8999 bytes) 
[2025-10-08 19:52:20] INFO  TaskSetManager - Starting task 2.0 in stage 5.0 (TID 5) (DESKTOP-618L1DH, executor driver, partition 2, NODE_LOCAL, 8999 bytes) 
[2025-10-08 19:52:20] INFO  TaskSetManager - Starting task 3.0 in stage 5.0 (TID 6) (DESKTOP-618L1DH, executor driver, partition 3, NODE_LOCAL, 8999 bytes) 
[2025-10-08 19:52:20] INFO  TaskSetManager - Starting task 4.0 in stage 5.0 (TID 7) (DESKTOP-618L1DH, executor driver, partition 4, NODE_LOCAL, 8999 bytes) 
[2025-10-08 19:52:20] INFO  Executor - Running task 0.0 in stage 5.0 (TID 3)
[2025-10-08 19:52:20] INFO  Executor - Running task 1.0 in stage 5.0 (TID 4)
[2025-10-08 19:52:20] INFO  Executor - Running task 2.0 in stage 5.0 (TID 5)
[2025-10-08 19:52:20] INFO  Executor - Running task 3.0 in stage 5.0 (TID 6)
[2025-10-08 19:52:20] INFO  Executor - Running task 4.0 in stage 5.0 (TID 7)
[2025-10-08 19:52:20] INFO  ShuffleBlockFetcherIterator - Getting 1 (1035.9 KiB) non-empty blocks including 1 (1035.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:20] INFO  ShuffleBlockFetcherIterator - Getting 1 (1031.9 KiB) non-empty blocks including 1 (1031.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:20] INFO  ShuffleBlockFetcherIterator - Getting 1 (1639.8 KiB) non-empty blocks including 1 (1639.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:20] INFO  ShuffleBlockFetcherIterator - Getting 1 (1053.2 KiB) non-empty blocks including 1 (1053.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:20] INFO  ShuffleBlockFetcherIterator - Getting 1 (1055.0 KiB) non-empty blocks including 1 (1055.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:20] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 3 ms
[2025-10-08 19:52:20] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 3 ms
[2025-10-08 19:52:20] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 3 ms
[2025-10-08 19:52:20] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 4 ms
[2025-10-08 19:52:20] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 4 ms
[2025-10-08 19:52:22] INFO  CodeGenerator - Code generated in 20.2539 ms
[2025-10-08 19:52:26] INFO  Executor - Finished task 3.0 in stage 5.0 (TID 6). 4794 bytes result sent to driver
[2025-10-08 19:52:26] INFO  Executor - Finished task 2.0 in stage 5.0 (TID 5). 4708 bytes result sent to driver
[2025-10-08 19:52:26] INFO  TaskSetManager - Finished task 2.0 in stage 5.0 (TID 5) in 5676 ms on DESKTOP-618L1DH (executor driver) (1/5)
[2025-10-08 19:52:26] INFO  TaskSetManager - Finished task 3.0 in stage 5.0 (TID 6) in 5685 ms on DESKTOP-618L1DH (executor driver) (2/5)
[2025-10-08 19:52:26] INFO  Executor - Finished task 1.0 in stage 5.0 (TID 4). 4751 bytes result sent to driver
[2025-10-08 19:52:26] INFO  TaskSetManager - Finished task 1.0 in stage 5.0 (TID 4) in 5774 ms on DESKTOP-618L1DH (executor driver) (3/5)
[2025-10-08 19:52:26] INFO  Executor - Finished task 0.0 in stage 5.0 (TID 3). 4708 bytes result sent to driver
[2025-10-08 19:52:26] INFO  TaskSetManager - Finished task 0.0 in stage 5.0 (TID 3) in 5800 ms on DESKTOP-618L1DH (executor driver) (4/5)
[2025-10-08 19:52:29] INFO  Executor - Finished task 4.0 in stage 5.0 (TID 7). 4751 bytes result sent to driver
[2025-10-08 19:52:29] INFO  TaskSetManager - Finished task 4.0 in stage 5.0 (TID 7) in 8718 ms on DESKTOP-618L1DH (executor driver) (5/5)
[2025-10-08 19:52:29] INFO  TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[2025-10-08 19:52:29] INFO  DAGScheduler - ResultStage 5 (save at DataCleaning.java:143) finished in 8.765 s
[2025-10-08 19:52:29] INFO  DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 19:52:29] INFO  TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
[2025-10-08 19:52:29] INFO  DAGScheduler - Job 3 finished: save at DataCleaning.java:143, took 8.773983 s
[2025-10-08 19:52:29] INFO  DAGScheduler - Registering RDD 17 (count at DataCleaning.java:41) as input to shuffle 2
[2025-10-08 19:52:29] INFO  DAGScheduler - Got map stage job 4 (count at DataCleaning.java:41) with 1 output partitions
[2025-10-08 19:52:29] INFO  DAGScheduler - Final stage: ShuffleMapStage 6 (count at DataCleaning.java:41)
[2025-10-08 19:52:29] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 19:52:29] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 19:52:29] INFO  DAGScheduler - Submitting ShuffleMapStage 6 (MapPartitionsRDD[17] at count at DataCleaning.java:41), which has no missing parents
[2025-10-08 19:52:29] INFO  MemoryStore - Block broadcast_4 stored as values in memory (estimated size 75.7 KiB, free 2.2 GiB)
[2025-10-08 19:52:29] INFO  MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 2.2 GiB)
[2025-10-08 19:52:29] INFO  BlockManagerInfo - Added broadcast_4_piece0 in memory on DESKTOP-618L1DH:56838 (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-08 19:52:29] INFO  SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1611
[2025-10-08 19:52:29] INFO  DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[17] at count at DataCleaning.java:41) (first 15 tasks are for partitions Vector(0))
[2025-10-08 19:52:29] INFO  TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
[2025-10-08 19:52:29] INFO  TaskSetManager - Starting task 0.0 in stage 6.0 (TID 8) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) 
[2025-10-08 19:52:29] INFO  Executor - Running task 0.0 in stage 6.0 (TID 8)
[2025-10-08 19:52:30] INFO  JDBCRDD - closed connection
[2025-10-08 19:52:32] INFO  Executor - Finished task 0.0 in stage 6.0 (TID 8). 2507 bytes result sent to driver
[2025-10-08 19:52:32] INFO  TaskSetManager - Finished task 0.0 in stage 6.0 (TID 8) in 2146 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 19:52:32] INFO  DAGScheduler - ShuffleMapStage 6 (count at DataCleaning.java:41) finished in 2.166 s
[2025-10-08 19:52:32] INFO  TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[2025-10-08 19:52:32] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-08 19:52:32] INFO  DAGScheduler - running: Set()
[2025-10-08 19:52:32] INFO  DAGScheduler - waiting: Set()
[2025-10-08 19:52:32] INFO  DAGScheduler - failed: Set()
[2025-10-08 19:52:32] INFO  ShufflePartitionsUtil - For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-10-08 19:52:32] INFO  CodeGenerator - Code generated in 144.4827 ms
[2025-10-08 19:52:32] INFO  DAGScheduler - Registering RDD 20 (count at DataCleaning.java:41) as input to shuffle 3
[2025-10-08 19:52:32] INFO  DAGScheduler - Got map stage job 5 (count at DataCleaning.java:41) with 5 output partitions
[2025-10-08 19:52:32] INFO  DAGScheduler - Final stage: ShuffleMapStage 8 (count at DataCleaning.java:41)
[2025-10-08 19:52:32] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 7)
[2025-10-08 19:52:32] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 19:52:32] INFO  DAGScheduler - Submitting ShuffleMapStage 8 (MapPartitionsRDD[20] at count at DataCleaning.java:41), which has no missing parents
[2025-10-08 19:52:32] INFO  MemoryStore - Block broadcast_5 stored as values in memory (estimated size 76.1 KiB, free 2.2 GiB)
[2025-10-08 19:52:32] INFO  MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.1 KiB, free 2.2 GiB)
[2025-10-08 19:52:32] INFO  BlockManagerInfo - Added broadcast_5_piece0 in memory on DESKTOP-618L1DH:56838 (size: 29.1 KiB, free: 2.2 GiB)
[2025-10-08 19:52:32] INFO  SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1611
[2025-10-08 19:52:32] INFO  DAGScheduler - Submitting 5 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[20] at count at DataCleaning.java:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
[2025-10-08 19:52:32] INFO  TaskSchedulerImpl - Adding task set 8.0 with 5 tasks resource profile 0
[2025-10-08 19:52:32] INFO  TaskSetManager - Starting task 0.0 in stage 8.0 (TID 9) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8988 bytes) 
[2025-10-08 19:52:32] INFO  TaskSetManager - Starting task 1.0 in stage 8.0 (TID 10) (DESKTOP-618L1DH, executor driver, partition 1, NODE_LOCAL, 8988 bytes) 
[2025-10-08 19:52:32] INFO  TaskSetManager - Starting task 2.0 in stage 8.0 (TID 11) (DESKTOP-618L1DH, executor driver, partition 2, NODE_LOCAL, 8988 bytes) 
[2025-10-08 19:52:32] INFO  TaskSetManager - Starting task 3.0 in stage 8.0 (TID 12) (DESKTOP-618L1DH, executor driver, partition 3, NODE_LOCAL, 8988 bytes) 
[2025-10-08 19:52:32] INFO  TaskSetManager - Starting task 4.0 in stage 8.0 (TID 13) (DESKTOP-618L1DH, executor driver, partition 4, NODE_LOCAL, 8988 bytes) 
[2025-10-08 19:52:32] INFO  Executor - Running task 0.0 in stage 8.0 (TID 9)
[2025-10-08 19:52:32] INFO  Executor - Running task 1.0 in stage 8.0 (TID 10)
[2025-10-08 19:52:32] INFO  Executor - Running task 2.0 in stage 8.0 (TID 11)
[2025-10-08 19:52:32] INFO  Executor - Running task 3.0 in stage 8.0 (TID 12)
[2025-10-08 19:52:32] INFO  Executor - Running task 4.0 in stage 8.0 (TID 13)
[2025-10-08 19:52:32] INFO  ShuffleBlockFetcherIterator - Getting 1 (1055.0 KiB) non-empty blocks including 1 (1055.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:32] INFO  ShuffleBlockFetcherIterator - Getting 1 (1639.8 KiB) non-empty blocks including 1 (1639.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:32] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 7 ms
[2025-10-08 19:52:32] INFO  ShuffleBlockFetcherIterator - Getting 1 (1031.9 KiB) non-empty blocks including 1 (1031.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:32] INFO  ShuffleBlockFetcherIterator - Getting 1 (1035.9 KiB) non-empty blocks including 1 (1035.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:32] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 8 ms
[2025-10-08 19:52:32] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 8 ms
[2025-10-08 19:52:32] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 6 ms
[2025-10-08 19:52:32] INFO  ShuffleBlockFetcherIterator - Getting 1 (1053.2 KiB) non-empty blocks including 1 (1053.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:32] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 7 ms
[2025-10-08 19:52:32] INFO  CodeGenerator - Code generated in 172.8925 ms
[2025-10-08 19:52:32] INFO  BlockManagerInfo - Removed broadcast_2_piece0 on DESKTOP-618L1DH:56838 in memory (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-08 19:52:32] INFO  BlockManagerInfo - Removed broadcast_3_piece0 on DESKTOP-618L1DH:56838 in memory (size: 34.8 KiB, free: 2.2 GiB)
[2025-10-08 19:52:32] INFO  BlockManagerInfo - Removed broadcast_0_piece0 on DESKTOP-618L1DH:56838 in memory (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-08 19:52:32] INFO  BlockManagerInfo - Removed broadcast_4_piece0 on DESKTOP-618L1DH:56838 in memory (size: 27.5 KiB, free: 2.2 GiB)
[2025-10-08 19:52:33] INFO  Executor - Finished task 3.0 in stage 8.0 (TID 12). 5466 bytes result sent to driver
[2025-10-08 19:52:33] INFO  TaskSetManager - Finished task 3.0 in stage 8.0 (TID 12) in 659 ms on DESKTOP-618L1DH (executor driver) (1/5)
[2025-10-08 19:52:33] INFO  Executor - Finished task 0.0 in stage 8.0 (TID 9). 5509 bytes result sent to driver
[2025-10-08 19:52:33] INFO  TaskSetManager - Finished task 0.0 in stage 8.0 (TID 9) in 676 ms on DESKTOP-618L1DH (executor driver) (2/5)
[2025-10-08 19:52:33] INFO  Executor - Finished task 1.0 in stage 8.0 (TID 10). 5423 bytes result sent to driver
[2025-10-08 19:52:33] INFO  TaskSetManager - Finished task 1.0 in stage 8.0 (TID 10) in 680 ms on DESKTOP-618L1DH (executor driver) (3/5)
[2025-10-08 19:52:33] INFO  Executor - Finished task 2.0 in stage 8.0 (TID 11). 5466 bytes result sent to driver
[2025-10-08 19:52:33] INFO  TaskSetManager - Finished task 2.0 in stage 8.0 (TID 11) in 695 ms on DESKTOP-618L1DH (executor driver) (4/5)
[2025-10-08 19:52:33] INFO  Executor - Finished task 4.0 in stage 8.0 (TID 13). 5466 bytes result sent to driver
[2025-10-08 19:52:33] INFO  TaskSetManager - Finished task 4.0 in stage 8.0 (TID 13) in 724 ms on DESKTOP-618L1DH (executor driver) (5/5)
[2025-10-08 19:52:33] INFO  TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[2025-10-08 19:52:33] INFO  DAGScheduler - ShuffleMapStage 8 (count at DataCleaning.java:41) finished in 0.753 s
[2025-10-08 19:52:33] INFO  DAGScheduler - looking for newly runnable stages
[2025-10-08 19:52:33] INFO  DAGScheduler - running: Set()
[2025-10-08 19:52:33] INFO  DAGScheduler - waiting: Set()
[2025-10-08 19:52:33] INFO  DAGScheduler - failed: Set()
[2025-10-08 19:52:33] INFO  CodeGenerator - Code generated in 23.3944 ms
[2025-10-08 19:52:33] INFO  SparkContext - Starting job: count at DataCleaning.java:41
[2025-10-08 19:52:33] INFO  DAGScheduler - Got job 6 (count at DataCleaning.java:41) with 1 output partitions
[2025-10-08 19:52:33] INFO  DAGScheduler - Final stage: ResultStage 11 (count at DataCleaning.java:41)
[2025-10-08 19:52:33] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 10)
[2025-10-08 19:52:33] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 19:52:33] INFO  DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[23] at count at DataCleaning.java:41), which has no missing parents
[2025-10-08 19:52:33] INFO  MemoryStore - Block broadcast_6 stored as values in memory (estimated size 12.5 KiB, free 2.2 GiB)
[2025-10-08 19:52:33] INFO  MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
[2025-10-08 19:52:33] INFO  BlockManagerInfo - Added broadcast_6_piece0 in memory on DESKTOP-618L1DH:56838 (size: 5.9 KiB, free: 2.2 GiB)
[2025-10-08 19:52:33] INFO  SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-10-08 19:52:33] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[23] at count at DataCleaning.java:41) (first 15 tasks are for partitions Vector(0))
[2025-10-08 19:52:33] INFO  TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
[2025-10-08 19:52:33] INFO  TaskSetManager - Starting task 0.0 in stage 11.0 (TID 14) (DESKTOP-618L1DH, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
[2025-10-08 19:52:33] INFO  Executor - Running task 0.0 in stage 11.0 (TID 14)
[2025-10-08 19:52:33] INFO  ShuffleBlockFetcherIterator - Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-10-08 19:52:33] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
[2025-10-08 19:52:33] INFO  CodeGenerator - Code generated in 28.4832 ms
[2025-10-08 19:52:33] INFO  Executor - Finished task 0.0 in stage 11.0 (TID 14). 4038 bytes result sent to driver
[2025-10-08 19:52:33] INFO  TaskSetManager - Finished task 0.0 in stage 11.0 (TID 14) in 131 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 19:52:33] INFO  TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
[2025-10-08 19:52:33] INFO  DAGScheduler - ResultStage 11 (count at DataCleaning.java:41) finished in 0.151 s
[2025-10-08 19:52:33] INFO  DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 19:52:33] INFO  TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
[2025-10-08 19:52:33] INFO  DAGScheduler - Job 6 finished: count at DataCleaning.java:41, took 0.172569 s
[2025-10-08 19:52:33] INFO  DataCleaning - Cleaned dataset stored in silver layer. Row count = 54619
[2025-10-08 19:52:33] INFO  DataCleaning - Loading from DB Table: bronze.carrier_lookup
[2025-10-08 19:52:33] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_carrier_lookup
[2025-10-08 19:52:33] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:33] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 19:52:33] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 19:52:33] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:33] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 19:52:33] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 19:52:33] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:33] INFO  CodeGenerator - Code generated in 17.8066 ms
[2025-10-08 19:52:33] INFO  SparkContext - Starting job: save at DataCleaning.java:132
[2025-10-08 19:52:33] INFO  DAGScheduler - Got job 7 (save at DataCleaning.java:132) with 1 output partitions
[2025-10-08 19:52:33] INFO  DAGScheduler - Final stage: ResultStage 12 (save at DataCleaning.java:132)
[2025-10-08 19:52:33] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 19:52:33] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 19:52:33] INFO  DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[27] at save at DataCleaning.java:132), which has no missing parents
[2025-10-08 19:52:34] INFO  MemoryStore - Block broadcast_7 stored as values in memory (estimated size 213.2 KiB, free 2.2 GiB)
[2025-10-08 19:52:34] INFO  MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 77.1 KiB, free 2.2 GiB)
[2025-10-08 19:52:34] INFO  BlockManagerInfo - Added broadcast_7_piece0 in memory on DESKTOP-618L1DH:56838 (size: 77.1 KiB, free: 2.2 GiB)
[2025-10-08 19:52:34] INFO  SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-10-08 19:52:34] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[27] at save at DataCleaning.java:132) (first 15 tasks are for partitions Vector(0))
[2025-10-08 19:52:34] INFO  TaskSchedulerImpl - Adding task set 12.0 with 1 tasks resource profile 0
[2025-10-08 19:52:34] INFO  TaskSetManager - Starting task 0.0 in stage 12.0 (TID 15) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9121 bytes) 
[2025-10-08 19:52:34] INFO  Executor - Running task 0.0 in stage 12.0 (TID 15)
[2025-10-08 19:52:34] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 19:52:34] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 19:52:34] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:34] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 19:52:34] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 19:52:34] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:34] INFO  CodecConfig - Compression: SNAPPY
[2025-10-08 19:52:34] INFO  CodecConfig - Compression: SNAPPY
[2025-10-08 19:52:34] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-08 19:52:34] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "carrier",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "carrier_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary carrier (STRING);
  optional binary carrier_name (STRING);
}

       
[2025-10-08 19:52:34] INFO  BlockManagerInfo - Removed broadcast_5_piece0 on DESKTOP-618L1DH:56838 in memory (size: 29.1 KiB, free: 2.2 GiB)
[2025-10-08 19:52:34] INFO  BlockManagerInfo - Removed broadcast_6_piece0 on DESKTOP-618L1DH:56838 in memory (size: 5.9 KiB, free: 2.2 GiB)
[2025-10-08 19:52:34] INFO  CodeGenerator - Code generated in 23.1653 ms
[2025-10-08 19:52:34] INFO  JDBCRDD - closed connection
[2025-10-08 19:52:34] INFO  FileOutputCommitter - Saved output of task 'attempt_2025100819523390581321103802153_0012_m_000000_15' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/silver/cleaned_carrier_lookup/_temporary/0/task_2025100819523390581321103802153_0012_m_000000
[2025-10-08 19:52:34] INFO  SparkHadoopMapRedUtil - attempt_2025100819523390581321103802153_0012_m_000000_15: Committed. Elapsed time: 8 ms.
[2025-10-08 19:52:34] INFO  Executor - Finished task 0.0 in stage 12.0 (TID 15). 2570 bytes result sent to driver
[2025-10-08 19:52:34] INFO  TaskSetManager - Finished task 0.0 in stage 12.0 (TID 15) in 317 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 19:52:34] INFO  TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool 
[2025-10-08 19:52:34] INFO  DAGScheduler - ResultStage 12 (save at DataCleaning.java:132) finished in 0.492 s
[2025-10-08 19:52:34] INFO  DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 19:52:34] INFO  TaskSchedulerImpl - Killing all running tasks in stage 12: Stage finished
[2025-10-08 19:52:34] INFO  DAGScheduler - Job 7 finished: save at DataCleaning.java:132, took 0.520565 s
[2025-10-08 19:52:34] INFO  FileFormatWriter - Start to commit write Job 2002d9f8-c691-481f-9cb3-62a6ab74170d.
[2025-10-08 19:52:34] INFO  FileFormatWriter - Write Job 2002d9f8-c691-481f-9cb3-62a6ab74170d committed. Elapsed time: 47 ms.
[2025-10-08 19:52:34] INFO  FileFormatWriter - Finished processing stats for write job 2002d9f8-c691-481f-9cb3-62a6ab74170d.
[2025-10-08 19:52:34] INFO  DataCleaning - Overwriting DB Table: silver.cleaned_carrier_lookup
[2025-10-08 19:52:34] INFO  SparkContext - Starting job: save at DataCleaning.java:143
[2025-10-08 19:52:34] INFO  DAGScheduler - Got job 8 (save at DataCleaning.java:143) with 1 output partitions
[2025-10-08 19:52:34] INFO  DAGScheduler - Final stage: ResultStage 13 (save at DataCleaning.java:143)
[2025-10-08 19:52:34] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 19:52:34] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 19:52:34] INFO  DAGScheduler - Submitting ResultStage 13 (MapPartitionsRDD[32] at save at DataCleaning.java:143), which has no missing parents
[2025-10-08 19:52:34] INFO  MemoryStore - Block broadcast_8 stored as values in memory (estimated size 28.1 KiB, free 2.2 GiB)
[2025-10-08 19:52:34] INFO  MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.2 KiB, free 2.2 GiB)
[2025-10-08 19:52:34] INFO  BlockManagerInfo - Added broadcast_8_piece0 in memory on DESKTOP-618L1DH:56838 (size: 13.2 KiB, free: 2.2 GiB)
[2025-10-08 19:52:34] INFO  SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-10-08 19:52:34] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[32] at save at DataCleaning.java:143) (first 15 tasks are for partitions Vector(0))
[2025-10-08 19:52:34] INFO  TaskSchedulerImpl - Adding task set 13.0 with 1 tasks resource profile 0
[2025-10-08 19:52:34] INFO  TaskSetManager - Starting task 0.0 in stage 13.0 (TID 16) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) 
[2025-10-08 19:52:34] INFO  Executor - Running task 0.0 in stage 13.0 (TID 16)
[2025-10-08 19:52:34] INFO  CodeGenerator - Code generated in 23.7329 ms
[2025-10-08 19:52:34] INFO  JDBCRDD - closed connection
[2025-10-08 19:52:35] INFO  Executor - Finished task 0.0 in stage 13.0 (TID 16). 1316 bytes result sent to driver
[2025-10-08 19:52:35] INFO  TaskSetManager - Finished task 0.0 in stage 13.0 (TID 16) in 254 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 19:52:35] INFO  TaskSchedulerImpl - Removed TaskSet 13.0, whose tasks have all completed, from pool 
[2025-10-08 19:52:35] INFO  DAGScheduler - ResultStage 13 (save at DataCleaning.java:143) finished in 0.277 s
[2025-10-08 19:52:35] INFO  DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 19:52:35] INFO  TaskSchedulerImpl - Killing all running tasks in stage 13: Stage finished
[2025-10-08 19:52:35] INFO  DAGScheduler - Job 8 finished: save at DataCleaning.java:143, took 0.289831 s
[2025-10-08 19:52:35] INFO  DataCleaning - Loading from DB Table: bronze.airport_lookup
[2025-10-08 19:52:35] INFO  DataCleaning - Saving parquet: data/output/silver/cleaned_airport_lookup
[2025-10-08 19:52:35] INFO  ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:35] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 19:52:35] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 19:52:35] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:35] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 19:52:35] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 19:52:35] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:35] INFO  CodeGenerator - Code generated in 19.3989 ms
[2025-10-08 19:52:35] INFO  SparkContext - Starting job: save at DataCleaning.java:132
[2025-10-08 19:52:35] INFO  DAGScheduler - Got job 9 (save at DataCleaning.java:132) with 1 output partitions
[2025-10-08 19:52:35] INFO  DAGScheduler - Final stage: ResultStage 14 (save at DataCleaning.java:132)
[2025-10-08 19:52:35] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 19:52:35] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 19:52:35] INFO  DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[36] at save at DataCleaning.java:132), which has no missing parents
[2025-10-08 19:52:35] INFO  MemoryStore - Block broadcast_9 stored as values in memory (estimated size 213.9 KiB, free 2.2 GiB)
[2025-10-08 19:52:35] INFO  MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 2.2 GiB)
[2025-10-08 19:52:35] INFO  BlockManagerInfo - Added broadcast_9_piece0 in memory on DESKTOP-618L1DH:56838 (size: 77.2 KiB, free: 2.2 GiB)
[2025-10-08 19:52:35] INFO  SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-10-08 19:52:35] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[36] at save at DataCleaning.java:132) (first 15 tasks are for partitions Vector(0))
[2025-10-08 19:52:35] INFO  TaskSchedulerImpl - Adding task set 14.0 with 1 tasks resource profile 0
[2025-10-08 19:52:35] INFO  TaskSetManager - Starting task 0.0 in stage 14.0 (TID 17) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 9121 bytes) 
[2025-10-08 19:52:35] INFO  Executor - Running task 0.0 in stage 14.0 (TID 17)
[2025-10-08 19:52:35] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 19:52:35] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 19:52:35] INFO  SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:35] INFO  FileOutputCommitter - File Output Committer Algorithm version is 1
[2025-10-08 19:52:35] INFO  FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-10-08 19:52:35] INFO  SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-10-08 19:52:35] INFO  CodecConfig - Compression: SNAPPY
[2025-10-08 19:52:35] INFO  CodecConfig - Compression: SNAPPY
[2025-10-08 19:52:35] INFO  ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-10-08 19:52:35] INFO  ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "iso_country",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "iata_code",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary iso_country (STRING);
  optional binary name (STRING);
  optional binary iata_code (STRING);
}

       
[2025-10-08 19:52:35] INFO  CodeGenerator - Code generated in 21.4917 ms
[2025-10-08 19:52:35] INFO  JDBCRDD - closed connection
[2025-10-08 19:52:35] INFO  FileOutputCommitter - Saved output of task 'attempt_202510081952353122668973907008979_0014_m_000000_17' to file:/C:/Capstone/batch-2025-capstone/airline-delay-data-analysis/VIBHA/airline-delay-analysis-vibha/data/output/silver/cleaned_airport_lookup/_temporary/0/task_202510081952353122668973907008979_0014_m_000000
[2025-10-08 19:52:35] INFO  SparkHadoopMapRedUtil - attempt_202510081952353122668973907008979_0014_m_000000_17: Committed. Elapsed time: 6 ms.
[2025-10-08 19:52:35] INFO  Executor - Finished task 0.0 in stage 14.0 (TID 17). 2484 bytes result sent to driver
[2025-10-08 19:52:35] INFO  TaskSetManager - Finished task 0.0 in stage 14.0 (TID 17) in 191 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 19:52:35] INFO  TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool 
[2025-10-08 19:52:35] INFO  DAGScheduler - ResultStage 14 (save at DataCleaning.java:132) finished in 0.282 s
[2025-10-08 19:52:35] INFO  DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 19:52:35] INFO  TaskSchedulerImpl - Killing all running tasks in stage 14: Stage finished
[2025-10-08 19:52:35] INFO  DAGScheduler - Job 9 finished: save at DataCleaning.java:132, took 0.289748 s
[2025-10-08 19:52:35] INFO  FileFormatWriter - Start to commit write Job 7a4c0fcb-eae1-42e8-b4ab-6bc7b72b92e3.
[2025-10-08 19:52:35] INFO  FileFormatWriter - Write Job 7a4c0fcb-eae1-42e8-b4ab-6bc7b72b92e3 committed. Elapsed time: 96 ms.
[2025-10-08 19:52:35] INFO  FileFormatWriter - Finished processing stats for write job 7a4c0fcb-eae1-42e8-b4ab-6bc7b72b92e3.
[2025-10-08 19:52:35] INFO  DataCleaning - Overwriting DB Table: silver.cleaned_airport_lookup
[2025-10-08 19:52:36] INFO  SparkContext - Starting job: save at DataCleaning.java:143
[2025-10-08 19:52:36] INFO  DAGScheduler - Got job 10 (save at DataCleaning.java:143) with 1 output partitions
[2025-10-08 19:52:36] INFO  DAGScheduler - Final stage: ResultStage 15 (save at DataCleaning.java:143)
[2025-10-08 19:52:36] INFO  DAGScheduler - Parents of final stage: List()
[2025-10-08 19:52:36] INFO  DAGScheduler - Missing parents: List()
[2025-10-08 19:52:36] INFO  DAGScheduler - Submitting ResultStage 15 (MapPartitionsRDD[41] at save at DataCleaning.java:143), which has no missing parents
[2025-10-08 19:52:36] INFO  MemoryStore - Block broadcast_10 stored as values in memory (estimated size 29.2 KiB, free 2.2 GiB)
[2025-10-08 19:52:36] INFO  MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 2.2 GiB)
[2025-10-08 19:52:36] INFO  BlockManagerInfo - Added broadcast_10_piece0 in memory on DESKTOP-618L1DH:56838 (size: 13.4 KiB, free: 2.2 GiB)
[2025-10-08 19:52:36] INFO  SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1611
[2025-10-08 19:52:36] INFO  DAGScheduler - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[41] at save at DataCleaning.java:143) (first 15 tasks are for partitions Vector(0))
[2025-10-08 19:52:36] INFO  TaskSchedulerImpl - Adding task set 15.0 with 1 tasks resource profile 0
[2025-10-08 19:52:36] INFO  TaskSetManager - Starting task 0.0 in stage 15.0 (TID 18) (DESKTOP-618L1DH, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) 
[2025-10-08 19:52:36] INFO  Executor - Running task 0.0 in stage 15.0 (TID 18)
[2025-10-08 19:52:36] INFO  CodeGenerator - Code generated in 283.6856 ms
[2025-10-08 19:52:38] INFO  JDBCRDD - closed connection
[2025-10-08 19:52:38] INFO  Executor - Finished task 0.0 in stage 15.0 (TID 18). 1230 bytes result sent to driver
[2025-10-08 19:52:38] INFO  TaskSetManager - Finished task 0.0 in stage 15.0 (TID 18) in 2409 ms on DESKTOP-618L1DH (executor driver) (1/1)
[2025-10-08 19:52:38] INFO  TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
[2025-10-08 19:52:38] INFO  DAGScheduler - ResultStage 15 (save at DataCleaning.java:143) finished in 2.449 s
[2025-10-08 19:52:38] INFO  DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-10-08 19:52:38] INFO  TaskSchedulerImpl - Killing all running tasks in stage 15: Stage finished
[2025-10-08 19:52:38] INFO  DAGScheduler - Job 10 finished: save at DataCleaning.java:143, took 2.469021 s
[2025-10-08 19:52:38] INFO  SparkContext - SparkContext is stopping with exitCode 0.
[2025-10-08 19:52:38] INFO  AbstractConnector - Stopped Spark@288f173f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
[2025-10-08 19:52:38] INFO  SparkUI - Stopped Spark web UI at http://DESKTOP-618L1DH:4040
[2025-10-08 19:52:38] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
[2025-10-08 19:52:39] INFO  MemoryStore - MemoryStore cleared
[2025-10-08 19:52:39] INFO  BlockManager - BlockManager stopped
[2025-10-08 19:52:39] INFO  BlockManagerMaster - BlockManagerMaster stopped
[2025-10-08 19:52:39] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
[2025-10-08 19:52:39] INFO  SparkContext - Successfully stopped SparkContext
[2025-10-08 19:52:39] INFO  ShutdownHookManager - Shutdown hook called
[2025-10-08 19:52:39] INFO  ShutdownHookManager - Deleting directory C:\Users\USER\AppData\Local\Temp\spark-479d0aab-c365-4160-8eed-9cfc885b4aa8
